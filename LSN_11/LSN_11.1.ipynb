{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tommaso Peritore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "#from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook our task will be to perform machine learning regression on noisy data with a Neural Network (NN).\n",
    "\n",
    "We will explore how the ability to fit depends on the structure of the NN. The goal is also to build intuition about why prediction is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1\n",
    "\n",
    "In order to make practice with NN, explore how does the previous linear regression depend on the number of epochs, $N_{\\mathrm{epochs}}$, the number of data points $N_{\\mathrm{train}}$ and on the noise $\\sigma$. Try to improve the previous result operating on these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to improve the fitting of the following function:\n",
    "$$\n",
    "f(x)=2x+1\n",
    "$$\n",
    "We want to explore how the linear regression depends on the number of epochs, the number of data points and the noise $\\sigma$. Thus we are interested in seeing how these parameters affect the ability of the NN to fit the data.\n",
    "\n",
    "To explore the effect of all parameters we will define a set of values for each and then loop over all possible combinations of these values. Below I am showing the values for the $3$ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma =  [0.1, 0.2, 0.5, 1]\n",
      "N_epochs =  [10, 15, 30, 50]\n",
      "N_train =  [500, 1000, 1500, 2000]\n"
     ]
    }
   ],
   "source": [
    "# Parameters to vary\n",
    "_sigma = [0.1, 0.2, 0.5, 1] # <<< noise\n",
    "_n_epochs = [10, 15, 30, 50] # <<< epochs\n",
    "_n_train = [500, 1000, 1500, 2000] # <<< train\n",
    "\n",
    "N_valid = 50 # <<< test\n",
    "\n",
    "# target parameters of f(x) = m*x + q\n",
    "m = 2 # slope\n",
    "q = 1 # intersect\n",
    "\n",
    "print('Sigma = ', _sigma)\n",
    "print('N_epochs = ', _n_epochs)\n",
    "print('N_train = ', _n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters to explore were chosen with these criteria in mind:\n",
    "- The values of sigma were chosen to span from very low noise to very high noise so as to explore the ability of the NN model to fit the data in the presence of progressively more noise.\n",
    "- The number of epochs was chosen to span from below to above the value given in the original code, to see if $30$ epochs was already enough to saturate the training or if more epochs would improve the fit, or if less epochs would be enough.\n",
    "- Finally, the number of training data was varied significantly to see if the model would perform better after having been trained on more data.\n",
    "\n",
    "Below I am going to define a function to prepare the data, define the model, compile it and finally train it. This function, `run_model` will be used to fill a `loss` array with the values of the loss function for each combination of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for the NN model\n",
    "def run_model (sigma, n_epochs, train, valid):\n",
    "\t# generate training inputs\n",
    "\tnp.random.seed(0)\n",
    "\tx_train = np.random.uniform(-1, 1, train)\n",
    "\tx_valid = np.random.uniform(-1, 1, valid)\n",
    "\tx_valid.sort()\n",
    "\t# y_target = m * x_valid + q # ideal (target) linear function\n",
    "\n",
    "\t# actual measures from which we want to guess regression parameters\n",
    "\ty_train = np.random.normal(m * x_train + q, sigma) \n",
    "\ty_valid = np.random.normal(m * x_valid + q, sigma)\n",
    "\n",
    "\t# compose the NN model\n",
    "\tmodel = tf.keras.Sequential()\n",
    "\tmodel.add(Dense(1, input_shape = (1,)))\n",
    "\n",
    "\t# compile the model choosing optimizer, loss and metrics objects\n",
    "\tmodel.compile(optimizer = 'sgd', loss = 'mse', metrics = ['mse'])\n",
    "\n",
    "\t# train the model\n",
    "\tmodel.fit(x = x_train, y = y_train, batch_size = 32, epochs = n_epochs,\n",
    "                    shuffle = True, validation_data = (x_valid, y_valid))\n",
    "\tscore = model.evaluate(x_valid, y_valid, batch_size = 32, verbose = 0)\n",
    "\t\n",
    "\treturn score[0]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.8359 - mse: 1.8359 - val_loss: 1.3673 - val_mse: 1.3673\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2737 - mse: 1.2737 - val_loss: 0.9746 - val_mse: 0.9746\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9220 - mse: 0.9220 - val_loss: 0.7198 - val_mse: 0.7198\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6890 - mse: 0.6890 - val_loss: 0.5456 - val_mse: 0.5456\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5260 - mse: 0.5260 - val_loss: 0.4227 - val_mse: 0.4227\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4098 - mse: 0.4098 - val_loss: 0.3310 - val_mse: 0.3310\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3222 - mse: 0.3222 - val_loss: 0.2631 - val_mse: 0.2631\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2569 - mse: 0.2569 - val_loss: 0.2109 - val_mse: 0.2109\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2064 - mse: 0.2064 - val_loss: 0.1699 - val_mse: 0.1699\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1666 - mse: 0.1666 - val_loss: 0.1375 - val_mse: 0.1375\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8303 - mse: 2.8303 - val_loss: 2.1286 - val_mse: 2.1286\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6269 - mse: 1.6269 - val_loss: 1.3210 - val_mse: 1.3210\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0099 - mse: 1.0099 - val_loss: 0.8417 - val_mse: 0.8417\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6388 - mse: 0.6388 - val_loss: 0.5498 - val_mse: 0.5498\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4135 - mse: 0.4135 - val_loss: 0.3612 - val_mse: 0.3612\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2690 - mse: 0.2690 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1779 - mse: 0.1779 - val_loss: 0.1625 - val_mse: 0.1625\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1187 - mse: 0.1187 - val_loss: 0.1101 - val_mse: 0.1101\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0800 - mse: 0.0800 - val_loss: 0.0764 - val_mse: 0.0764\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0552 - mse: 0.0552 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 2.4308 - mse: 2.4308 - val_loss: 1.6916 - val_mse: 1.6916\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0967 - mse: 1.0967 - val_loss: 0.7674 - val_mse: 0.7674\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5485 - mse: 0.5485 - val_loss: 0.3797 - val_mse: 0.3797\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2856 - mse: 0.2856 - val_loss: 0.1975 - val_mse: 0.1975\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1524 - mse: 0.1524 - val_loss: 0.1072 - val_mse: 0.1072\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 0.6009 - mse: 0.6009 - val_loss: 0.1865 - val_mse: 0.1865\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1283 - mse: 0.1283 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 23ms/step - loss: 2.8595 - mse: 2.8595 - val_loss: 2.1746 - val_mse: 2.1746\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1025 - mse: 2.1025 - val_loss: 1.6311 - val_mse: 1.6311\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.5895 - mse: 1.5895 - val_loss: 1.2524 - val_mse: 1.2524\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2261 - mse: 1.2261 - val_loss: 0.9768 - val_mse: 0.9768\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9594 - mse: 0.9594 - val_loss: 0.7714 - val_mse: 0.7714\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7586 - mse: 0.7586 - val_loss: 0.6141 - val_mse: 0.6141\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6042 - mse: 0.6042 - val_loss: 0.4909 - val_mse: 0.4909\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4833 - mse: 0.4833 - val_loss: 0.3939 - val_mse: 0.3939\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3882 - mse: 0.3882 - val_loss: 0.3172 - val_mse: 0.3172\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3128 - mse: 0.3128 - val_loss: 0.2560 - val_mse: 0.2560\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2528 - mse: 0.2528 - val_loss: 0.2072 - val_mse: 0.2072\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2049 - mse: 0.2049 - val_loss: 0.1683 - val_mse: 0.1683\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1665 - mse: 0.1665 - val_loss: 0.1370 - val_mse: 0.1370\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 0.1120 - val_mse: 0.1120\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1112 - mse: 0.1112 - val_loss: 0.0919 - val_mse: 0.0919\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 1s 9ms/step - loss: 3.5976 - mse: 3.5976 - val_loss: 2.7897 - val_mse: 2.7897\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.1420 - mse: 2.1420 - val_loss: 1.7485 - val_mse: 1.7485\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3398 - mse: 1.3398 - val_loss: 1.1211 - val_mse: 1.1211\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8530 - mse: 0.8530 - val_loss: 0.7341 - val_mse: 0.7341\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5537 - mse: 0.5537 - val_loss: 0.4843 - val_mse: 0.4843\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3622 - mse: 0.3622 - val_loss: 0.3215 - val_mse: 0.3215\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2384 - mse: 0.2384 - val_loss: 0.2157 - val_mse: 0.2157\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1583 - mse: 0.1583 - val_loss: 0.1459 - val_mse: 0.1459\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1060 - mse: 0.1060 - val_loss: 0.0993 - val_mse: 0.0993\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0691 - val_mse: 0.0691\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 1s 6ms/step - loss: 0.8733 - mse: 0.8733 - val_loss: 0.5358 - val_mse: 0.5358\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2889 - mse: 0.2889 - val_loss: 0.2018 - val_mse: 0.2018\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1292 - mse: 0.1292 - val_loss: 0.0946 - val_mse: 0.0946\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 0.4387 - mse: 0.4387 - val_loss: 0.1062 - val_mse: 0.1062\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 3.5459 - mse: 3.5459 - val_loss: 2.7229 - val_mse: 2.7229\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.6582 - mse: 2.6582 - val_loss: 2.0748 - val_mse: 2.0748\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.0375 - mse: 2.0375 - val_loss: 1.6154 - val_mse: 1.6154\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5900 - mse: 1.5900 - val_loss: 1.2711 - val_mse: 1.2711\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2527 - mse: 1.2527 - val_loss: 1.0103 - val_mse: 1.0103\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9960 - mse: 0.9960 - val_loss: 0.8062 - val_mse: 0.8062\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7946 - mse: 0.7946 - val_loss: 0.6463 - val_mse: 0.6463\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6368 - mse: 0.6368 - val_loss: 0.5184 - val_mse: 0.5184\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5110 - mse: 0.5110 - val_loss: 0.4172 - val_mse: 0.4172\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4115 - mse: 0.4115 - val_loss: 0.3366 - val_mse: 0.3366\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3322 - mse: 0.3322 - val_loss: 0.2712 - val_mse: 0.2712\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2680 - mse: 0.2680 - val_loss: 0.2193 - val_mse: 0.2193\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2169 - mse: 0.2169 - val_loss: 0.1779 - val_mse: 0.1779\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1763 - mse: 0.1763 - val_loss: 0.1450 - val_mse: 0.1450\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1440 - mse: 0.1440 - val_loss: 0.1183 - val_mse: 0.1183\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1177 - mse: 0.1177 - val_loss: 0.0968 - val_mse: 0.0968\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 0.0795 - val_mse: 0.0795\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0793 - mse: 0.0793 - val_loss: 0.0657 - val_mse: 0.0657\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 10ms/step - loss: 1.1451 - mse: 1.1451 - val_loss: 0.7333 - val_mse: 0.7333\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5383 - mse: 0.5383 - val_loss: 0.3871 - val_mse: 0.3871\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2910 - mse: 0.2910 - val_loss: 0.2339 - val_mse: 0.2339\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1758 - mse: 0.1758 - val_loss: 0.1516 - val_mse: 0.1516\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1129 - mse: 0.1129 - val_loss: 0.1022 - val_mse: 0.1022\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0753 - mse: 0.0753 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0504 - val_mse: 0.0504\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4901 - mse: 0.4901 - val_loss: 0.1936 - val_mse: 0.1936\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0900 - mse: 0.0900 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1201 - mse: 1.1201 - val_loss: 0.4663 - val_mse: 0.4663\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3417 - mse: 0.3417 - val_loss: 0.1900 - val_mse: 0.1900\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.1377 - mse: 0.1377 - val_loss: 0.0863 - val_mse: 0.0863\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 3.1993 - mse: 3.1993 - val_loss: 2.4495 - val_mse: 2.4495\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.3802 - mse: 2.3802 - val_loss: 1.8482 - val_mse: 1.8482\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8072 - mse: 1.8072 - val_loss: 1.4258 - val_mse: 1.4258\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4006 - mse: 1.4006 - val_loss: 1.1191 - val_mse: 1.1191\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1014 - mse: 1.1014 - val_loss: 0.8837 - val_mse: 0.8837\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8701 - mse: 0.8701 - val_loss: 0.7030 - val_mse: 0.7030\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6926 - mse: 0.6926 - val_loss: 0.5628 - val_mse: 0.5628\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5545 - mse: 0.5545 - val_loss: 0.4528 - val_mse: 0.4528\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4465 - mse: 0.4465 - val_loss: 0.3643 - val_mse: 0.3643\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3592 - mse: 0.3592 - val_loss: 0.2935 - val_mse: 0.2935\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2897 - mse: 0.2897 - val_loss: 0.2373 - val_mse: 0.2373\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2346 - mse: 0.2346 - val_loss: 0.1923 - val_mse: 0.1923\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1560 - val_mse: 0.1560\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1547 - mse: 0.1547 - val_loss: 0.1271 - val_mse: 0.1271\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1262 - mse: 0.1262 - val_loss: 0.1039 - val_mse: 0.1039\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1034 - mse: 0.1034 - val_loss: 0.0854 - val_mse: 0.0854\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0851 - mse: 0.0851 - val_loss: 0.0705 - val_mse: 0.0705\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0703 - mse: 0.0703 - val_loss: 0.0584 - val_mse: 0.0584\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 4.3585 - mse: 4.3585 - val_loss: 3.4047 - val_mse: 3.4047\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.6205 - mse: 2.6205 - val_loss: 2.1594 - val_mse: 2.1594\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.6580 - mse: 1.6580 - val_loss: 1.3859 - val_mse: 1.3859\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0567 - mse: 1.0567 - val_loss: 0.9062 - val_mse: 0.9062\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6853 - mse: 0.6853 - val_loss: 0.5972 - val_mse: 0.5972\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4476 - mse: 0.4476 - val_loss: 0.3912 - val_mse: 0.3912\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2903 - mse: 0.2903 - val_loss: 0.2599 - val_mse: 0.2599\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1913 - mse: 0.1913 - val_loss: 0.1747 - val_mse: 0.1747\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1276 - mse: 0.1276 - val_loss: 0.1187 - val_mse: 0.1187\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0818 - val_mse: 0.0818\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0576 - val_mse: 0.0576\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.9546 - mse: 1.9546 - val_loss: 1.3480 - val_mse: 1.3480\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.8486 - mse: 0.8486 - val_loss: 0.5976 - val_mse: 0.5976\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4203 - mse: 0.4203 - val_loss: 0.2941 - val_mse: 0.2941\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2191 - mse: 0.2191 - val_loss: 0.1537 - val_mse: 0.1537\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.0841 - val_mse: 0.0841\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0657 - mse: 0.0657 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 0.4018 - mse: 0.4018 - val_loss: 0.0905 - val_mse: 0.0905\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6000 - mse: 1.6000 - val_loss: 1.2646 - val_mse: 1.2646\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1028 - mse: 1.1028 - val_loss: 0.8897 - val_mse: 0.8897\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7906 - mse: 0.7906 - val_loss: 0.6532 - val_mse: 0.6532\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5899 - mse: 0.5899 - val_loss: 0.4935 - val_mse: 0.4935\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4520 - mse: 0.4520 - val_loss: 0.3837 - val_mse: 0.3837\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3559 - mse: 0.3559 - val_loss: 0.3064 - val_mse: 0.3064\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2865 - mse: 0.2865 - val_loss: 0.2482 - val_mse: 0.2482\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2340 - mse: 0.2340 - val_loss: 0.2040 - val_mse: 0.2040\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1935 - mse: 0.1935 - val_loss: 0.1698 - val_mse: 0.1698\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1622 - mse: 0.1622 - val_loss: 0.1433 - val_mse: 0.1433\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9301 - mse: 2.9301 - val_loss: 2.2593 - val_mse: 2.2593\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.7103 - mse: 1.7103 - val_loss: 1.4166 - val_mse: 1.4166\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0672 - mse: 1.0672 - val_loss: 0.9238 - val_mse: 0.9238\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6886 - mse: 0.6886 - val_loss: 0.6206 - val_mse: 0.6206\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4574 - mse: 0.4574 - val_loss: 0.4222 - val_mse: 0.4222\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3090 - mse: 0.3090 - val_loss: 0.2930 - val_mse: 0.2930\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2081 - val_mse: 0.2081\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1519 - mse: 0.1519 - val_loss: 0.1511 - val_mse: 0.1511\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1114 - mse: 0.1114 - val_loss: 0.1135 - val_mse: 0.1135\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0856 - mse: 0.0856 - val_loss: 0.0889 - val_mse: 0.0889\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5769 - mse: 0.5769 - val_loss: 0.2791 - val_mse: 0.2791\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.1492 - mse: 0.1492 - val_loss: 0.1003 - val_mse: 0.1003\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0608 - val_mse: 0.0608\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0489 - val_mse: 0.0489\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0417 - val_mse: 0.0417\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 2.8994 - mse: 2.8994 - val_loss: 1.4967 - val_mse: 1.4967\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.0924 - mse: 1.0924 - val_loss: 0.6509 - val_mse: 0.6509\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4649 - mse: 0.4649 - val_loss: 0.3002 - val_mse: 0.3002\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2145 - mse: 0.2145 - val_loss: 0.1507 - val_mse: 0.1507\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1113 - mse: 0.1113 - val_loss: 0.0870 - val_mse: 0.0870\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.7828 - mse: 1.7828 - val_loss: 1.3952 - val_mse: 1.3952\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2443 - mse: 1.2443 - val_loss: 1.0000 - val_mse: 1.0000\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9071 - mse: 0.9071 - val_loss: 0.7435 - val_mse: 0.7435\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6843 - mse: 0.6843 - val_loss: 0.5696 - val_mse: 0.5696\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5295 - mse: 0.5295 - val_loss: 0.4450 - val_mse: 0.4450\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4181 - mse: 0.4181 - val_loss: 0.3547 - val_mse: 0.3547\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3359 - mse: 0.3359 - val_loss: 0.2874 - val_mse: 0.2874\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2739 - mse: 0.2739 - val_loss: 0.2353 - val_mse: 0.2353\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2258 - mse: 0.2258 - val_loss: 0.1951 - val_mse: 0.1951\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1880 - mse: 0.1880 - val_loss: 0.1633 - val_mse: 0.1633\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1582 - mse: 0.1582 - val_loss: 0.1387 - val_mse: 0.1387\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1346 - mse: 0.1346 - val_loss: 0.1190 - val_mse: 0.1190\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 0.1036 - val_mse: 0.1036\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1005 - mse: 0.1005 - val_loss: 0.0911 - val_mse: 0.0911\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 3.6807 - mse: 3.6807 - val_loss: 2.8967 - val_mse: 2.8967\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.2014 - mse: 2.2014 - val_loss: 1.8395 - val_mse: 1.8395\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3881 - mse: 1.3881 - val_loss: 1.2033 - val_mse: 1.2033\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8986 - mse: 0.8986 - val_loss: 0.7997 - val_mse: 0.7997\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5904 - mse: 0.5904 - val_loss: 0.5406 - val_mse: 0.5406\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3956 - mse: 0.3956 - val_loss: 0.3714 - val_mse: 0.3714\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2699 - mse: 0.2699 - val_loss: 0.2600 - val_mse: 0.2600\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1886 - mse: 0.1886 - val_loss: 0.1850 - val_mse: 0.1850\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.1350 - val_loss: 0.1361 - val_mse: 0.1361\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 0.1033 - val_mse: 0.1033\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0815 - val_mse: 0.0815\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 0.0669 - val_mse: 0.0669\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0504 - val_mse: 0.0504\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 1s 7ms/step - loss: 0.8148 - mse: 0.8148 - val_loss: 0.4891 - val_mse: 0.4891\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2723 - mse: 0.2723 - val_loss: 0.1978 - val_mse: 0.1978\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1345 - mse: 0.1345 - val_loss: 0.1088 - val_mse: 0.1088\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0615 - mse: 0.0615 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 1.9030 - mse: 1.9030 - val_loss: 0.9306 - val_mse: 0.9306\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6821 - mse: 0.6821 - val_loss: 0.4090 - val_mse: 0.4090\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2954 - mse: 0.2954 - val_loss: 0.1977 - val_mse: 0.1977\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1444 - mse: 0.1444 - val_loss: 0.1073 - val_mse: 0.1073\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0825 - mse: 0.0825 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0568 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.7935 - mse: 0.7935 - val_loss: 0.6817 - val_mse: 0.6817\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4448 - mse: 0.4448 - val_loss: 0.4090 - val_mse: 0.4090\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2595 - mse: 0.2595 - val_loss: 0.2572 - val_mse: 0.2572\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1603 - mse: 0.1603 - val_loss: 0.1724 - val_mse: 0.1724\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1074 - mse: 0.1074 - val_loss: 0.1237 - val_mse: 0.1237\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 0.0948 - val_mse: 0.0948\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0630 - mse: 0.0630 - val_loss: 0.0778 - val_mse: 0.0778\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0668 - val_mse: 0.0668\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 10ms/step - loss: 0.9112 - mse: 0.9112 - val_loss: 0.5335 - val_mse: 0.5335\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3908 - mse: 0.3908 - val_loss: 0.2718 - val_mse: 0.2718\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2077 - mse: 0.2077 - val_loss: 0.1705 - val_mse: 0.1705\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1325 - mse: 0.1325 - val_loss: 0.1197 - val_mse: 0.1197\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 0.0915 - val_mse: 0.0915\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0737 - val_mse: 0.0737\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0535 - val_mse: 0.0535\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0481 - val_mse: 0.0481\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 10ms/step - loss: 1.5730 - mse: 1.5730 - val_loss: 1.0776 - val_mse: 1.0776\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.6655 - mse: 0.6655 - val_loss: 0.4830 - val_mse: 0.4830\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3380 - mse: 0.3380 - val_loss: 0.2521 - val_mse: 0.2521\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1473 - val_mse: 0.1473\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.1164 - mse: 0.1164 - val_loss: 0.0954 - val_mse: 0.0954\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0692 - val_mse: 0.0692\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0554 - val_mse: 0.0554\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.4373 - mse: 0.4373 - val_loss: 0.1251 - val_mse: 0.1251\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0795 - mse: 0.0795 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.8943 - mse: 0.8943 - val_loss: 0.7406 - val_mse: 0.7406\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5271 - mse: 0.5271 - val_loss: 0.4618 - val_mse: 0.4618\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3280 - mse: 0.3280 - val_loss: 0.3027 - val_mse: 0.3027\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2104 - val_mse: 0.2104\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1528 - mse: 0.1528 - val_loss: 0.1545 - val_mse: 0.1545\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1152 - mse: 0.1152 - val_loss: 0.1205 - val_mse: 0.1205\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 0.0982 - val_mse: 0.0982\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 0.0835 - val_mse: 0.0835\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0683 - mse: 0.0683 - val_loss: 0.0731 - val_mse: 0.0731\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0614 - mse: 0.0614 - val_loss: 0.0656 - val_mse: 0.0656\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0565 - val_mse: 0.0565\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0501 - val_mse: 0.0501\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0449 - val_mse: 0.0449\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2871 - mse: 1.2871 - val_loss: 0.8508 - val_mse: 0.8508\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6321 - mse: 0.6321 - val_loss: 0.4883 - val_mse: 0.4883\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3678 - mse: 0.3678 - val_loss: 0.3165 - val_mse: 0.3165\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2378 - mse: 0.2378 - val_loss: 0.2182 - val_mse: 0.2182\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1634 - mse: 0.1634 - val_loss: 0.1564 - val_mse: 0.1564\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 0.1167 - val_mse: 0.1167\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0887 - mse: 0.0887 - val_loss: 0.0906 - val_mse: 0.0906\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0732 - val_mse: 0.0732\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0592 - mse: 0.0592 - val_loss: 0.0613 - val_mse: 0.0613\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 7ms/step - loss: 2.7188 - mse: 2.7188 - val_loss: 1.9067 - val_mse: 1.9067\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.2579 - mse: 1.2579 - val_loss: 0.8957 - val_mse: 0.8957\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6468 - mse: 0.6468 - val_loss: 0.4628 - val_mse: 0.4628\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3507 - mse: 0.3507 - val_loss: 0.2568 - val_mse: 0.2568\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2000 - mse: 0.2000 - val_loss: 0.1526 - val_mse: 0.1526\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.1221 - mse: 0.1221 - val_loss: 0.0990 - val_mse: 0.0990\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0816 - mse: 0.0816 - val_loss: 0.0713 - val_mse: 0.0713\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.6244 - mse: 1.6244 - val_loss: 0.7688 - val_mse: 0.7688\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5650 - mse: 0.5650 - val_loss: 0.3379 - val_mse: 0.3379\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2466 - mse: 0.2466 - val_loss: 0.1665 - val_mse: 0.1665\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1235 - mse: 0.1235 - val_loss: 0.0939 - val_mse: 0.0939\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0735 - mse: 0.0735 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0490 - val_mse: 0.0490\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.0205 - mse: 2.0205 - val_loss: 1.8096 - val_mse: 1.8096\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4902 - mse: 1.4902 - val_loss: 1.3686 - val_mse: 1.3686\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1504 - mse: 1.1504 - val_loss: 1.0778 - val_mse: 1.0778\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9245 - mse: 0.9245 - val_loss: 0.8717 - val_mse: 0.8717\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7625 - mse: 0.7625 - val_loss: 0.7300 - val_mse: 0.7300\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6485 - mse: 0.6485 - val_loss: 0.6256 - val_mse: 0.6256\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5627 - mse: 0.5627 - val_loss: 0.5449 - val_mse: 0.5449\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4961 - mse: 0.4961 - val_loss: 0.4852 - val_mse: 0.4852\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4449 - mse: 0.4449 - val_loss: 0.4393 - val_mse: 0.4393\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4046 - mse: 0.4046 - val_loss: 0.4042 - val_mse: 0.4042\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.9564 - mse: 0.9564 - val_loss: 0.5441 - val_mse: 0.5441\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4810 - mse: 0.4810 - val_loss: 0.3466 - val_mse: 0.3466\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.3332 - mse: 0.3332 - val_loss: 0.2869 - val_mse: 0.2869\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.2834 - mse: 0.2834 - val_loss: 0.2630 - val_mse: 0.2630\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2629 - mse: 0.2629 - val_loss: 0.2488 - val_mse: 0.2488\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2520 - mse: 0.2520 - val_loss: 0.2393 - val_mse: 0.2393\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2463 - mse: 0.2463 - val_loss: 0.2322 - val_mse: 0.2322\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2426 - mse: 0.2426 - val_loss: 0.2281 - val_mse: 0.2281\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2406 - mse: 0.2406 - val_loss: 0.2228 - val_mse: 0.2228\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2393 - mse: 0.2393 - val_loss: 0.2203 - val_mse: 0.2203\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 1s 9ms/step - loss: 2.4567 - mse: 2.4567 - val_loss: 1.7928 - val_mse: 1.7928\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.2191 - mse: 1.2191 - val_loss: 0.9487 - val_mse: 0.9487\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7208 - mse: 0.7208 - val_loss: 0.5968 - val_mse: 0.5968\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.4848 - mse: 0.4848 - val_loss: 0.4293 - val_mse: 0.4293\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.3435 - val_mse: 0.3435\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.3034 - mse: 0.3034 - val_loss: 0.2981 - val_mse: 0.2981\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2712 - mse: 0.2712 - val_loss: 0.2736 - val_mse: 0.2736\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2544 - mse: 0.2544 - val_loss: 0.2600 - val_mse: 0.2600\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2458 - mse: 0.2458 - val_loss: 0.2527 - val_mse: 0.2527\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2413 - mse: 0.2413 - val_loss: 0.2480 - val_mse: 0.2480\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 1s 6ms/step - loss: 2.0003 - mse: 2.0003 - val_loss: 1.1062 - val_mse: 1.1062\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.8390 - mse: 0.8390 - val_loss: 0.6040 - val_mse: 0.6040\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4775 - mse: 0.4775 - val_loss: 0.4008 - val_mse: 0.4008\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3378 - mse: 0.3378 - val_loss: 0.3113 - val_mse: 0.3113\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2804 - mse: 0.2804 - val_loss: 0.2716 - val_mse: 0.2716\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2566 - mse: 0.2566 - val_loss: 0.2542 - val_mse: 0.2542\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2468 - mse: 0.2468 - val_loss: 0.2460 - val_mse: 0.2460\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2428 - mse: 0.2428 - val_loss: 0.2421 - val_mse: 0.2421\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.2401 - val_mse: 0.2401\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2405 - mse: 0.2405 - val_loss: 0.2390 - val_mse: 0.2390\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.4599 - mse: 3.4599 - val_loss: 2.9160 - val_mse: 2.9160\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.6521 - mse: 2.6521 - val_loss: 2.2710 - val_mse: 2.2710\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0918 - mse: 2.0918 - val_loss: 1.8110 - val_mse: 1.8110\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.6828 - mse: 1.6828 - val_loss: 1.4647 - val_mse: 1.4647\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3747 - mse: 1.3747 - val_loss: 1.2036 - val_mse: 1.2036\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1392 - mse: 1.1392 - val_loss: 1.0047 - val_mse: 1.0047\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9568 - mse: 0.9568 - val_loss: 0.8520 - val_mse: 0.8520\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8142 - mse: 0.8142 - val_loss: 0.7304 - val_mse: 0.7304\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7005 - mse: 0.7005 - val_loss: 0.6348 - val_mse: 0.6348\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6105 - mse: 0.6105 - val_loss: 0.5581 - val_mse: 0.5581\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5377 - mse: 0.5377 - val_loss: 0.4992 - val_mse: 0.4992\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4800 - mse: 0.4800 - val_loss: 0.4527 - val_mse: 0.4527\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4335 - mse: 0.4335 - val_loss: 0.4158 - val_mse: 0.4158\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3964 - mse: 0.3964 - val_loss: 0.3863 - val_mse: 0.3863\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3668 - mse: 0.3668 - val_loss: 0.3627 - val_mse: 0.3627\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 0.9378 - mse: 0.9378 - val_loss: 0.5307 - val_mse: 0.5307\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4728 - mse: 0.4728 - val_loss: 0.3359 - val_mse: 0.3359\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3275 - mse: 0.3275 - val_loss: 0.2786 - val_mse: 0.2786\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2796 - mse: 0.2796 - val_loss: 0.2564 - val_mse: 0.2564\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2599 - mse: 0.2599 - val_loss: 0.2454 - val_mse: 0.2454\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2373 - val_mse: 0.2373\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2450 - mse: 0.2450 - val_loss: 0.2303 - val_mse: 0.2303\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2418 - mse: 0.2418 - val_loss: 0.2251 - val_mse: 0.2251\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2398 - mse: 0.2398 - val_loss: 0.2224 - val_mse: 0.2224\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2385 - mse: 0.2385 - val_loss: 0.2206 - val_mse: 0.2206\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2378 - mse: 0.2378 - val_loss: 0.2181 - val_mse: 0.2181\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2374 - mse: 0.2374 - val_loss: 0.2154 - val_mse: 0.2154\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2369 - mse: 0.2369 - val_loss: 0.2154 - val_mse: 0.2154\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.2139 - val_mse: 0.2139\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2140 - val_mse: 0.2140\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 1s 8ms/step - loss: 2.0561 - mse: 2.0561 - val_loss: 1.4961 - val_mse: 1.4961\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0124 - mse: 1.0124 - val_loss: 0.8026 - val_mse: 0.8026\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6139 - mse: 0.6139 - val_loss: 0.5220 - val_mse: 0.5220\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.4295 - mse: 0.4295 - val_loss: 0.3898 - val_mse: 0.3898\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3361 - mse: 0.3361 - val_loss: 0.3221 - val_mse: 0.3221\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2880 - mse: 0.2880 - val_loss: 0.2864 - val_mse: 0.2864\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2632 - mse: 0.2632 - val_loss: 0.2673 - val_mse: 0.2673\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2561 - val_mse: 0.2561\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2435 - mse: 0.2435 - val_loss: 0.2507 - val_mse: 0.2507\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2471 - val_mse: 0.2471\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2382 - mse: 0.2382 - val_loss: 0.2449 - val_mse: 0.2449\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2373 - mse: 0.2373 - val_loss: 0.2436 - val_mse: 0.2436\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2369 - mse: 0.2369 - val_loss: 0.2430 - val_mse: 0.2430\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2426 - val_mse: 0.2426\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2424 - val_mse: 0.2424\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7002 - mse: 0.7002 - val_loss: 0.3638 - val_mse: 0.3638\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3067 - mse: 0.3067 - val_loss: 0.2728 - val_mse: 0.2728\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2581 - mse: 0.2581 - val_loss: 0.2536 - val_mse: 0.2536\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2469 - mse: 0.2469 - val_loss: 0.2460 - val_mse: 0.2460\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2429 - mse: 0.2429 - val_loss: 0.2421 - val_mse: 0.2421\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.2402 - val_mse: 0.2402\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2405 - mse: 0.2405 - val_loss: 0.2391 - val_mse: 0.2391\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 0.2385 - val_mse: 0.2385\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2382 - val_mse: 0.2382\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2379 - val_mse: 0.2379\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 19ms/step - loss: 2.4403 - mse: 2.4403 - val_loss: 2.1177 - val_mse: 2.1177\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8232 - mse: 1.8232 - val_loss: 1.6244 - val_mse: 1.6244\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.4229 - mse: 1.4229 - val_loss: 1.2829 - val_mse: 1.2829\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1415 - mse: 1.1415 - val_loss: 1.0419 - val_mse: 1.0419\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9407 - mse: 0.9407 - val_loss: 0.8669 - val_mse: 0.8669\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7913 - mse: 0.7913 - val_loss: 0.7324 - val_mse: 0.7324\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6758 - mse: 0.6758 - val_loss: 0.6325 - val_mse: 0.6325\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5882 - mse: 0.5882 - val_loss: 0.5558 - val_mse: 0.5558\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5194 - mse: 0.5194 - val_loss: 0.4947 - val_mse: 0.4947\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4643 - mse: 0.4643 - val_loss: 0.4477 - val_mse: 0.4477\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4205 - mse: 0.4205 - val_loss: 0.4096 - val_mse: 0.4096\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3851 - mse: 0.3851 - val_loss: 0.3805 - val_mse: 0.3805\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3575 - mse: 0.3575 - val_loss: 0.3581 - val_mse: 0.3581\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3353 - mse: 0.3353 - val_loss: 0.3399 - val_mse: 0.3399\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3172 - mse: 0.3172 - val_loss: 0.3259 - val_mse: 0.3259\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3027 - mse: 0.3027 - val_loss: 0.3148 - val_mse: 0.3148\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2914 - mse: 0.2914 - val_loss: 0.3048 - val_mse: 0.3048\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2819 - mse: 0.2819 - val_loss: 0.2995 - val_mse: 0.2995\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2744 - mse: 0.2744 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2685 - mse: 0.2685 - val_loss: 0.2910 - val_mse: 0.2910\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2640 - mse: 0.2640 - val_loss: 0.2876 - val_mse: 0.2876\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2602 - mse: 0.2602 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2572 - mse: 0.2572 - val_loss: 0.2830 - val_mse: 0.2830\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2548 - mse: 0.2548 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2527 - mse: 0.2527 - val_loss: 0.2806 - val_mse: 0.2806\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2511 - mse: 0.2511 - val_loss: 0.2799 - val_mse: 0.2799\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2782 - val_mse: 0.2782\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2488 - mse: 0.2488 - val_loss: 0.2785 - val_mse: 0.2785\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2480 - mse: 0.2480 - val_loss: 0.2782 - val_mse: 0.2782\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2475 - mse: 0.2475 - val_loss: 0.2778 - val_mse: 0.2778\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9258 - mse: 0.9258 - val_loss: 0.5137 - val_mse: 0.5137\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4629 - mse: 0.4629 - val_loss: 0.3264 - val_mse: 0.3264\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3228 - mse: 0.3228 - val_loss: 0.2722 - val_mse: 0.2722\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2769 - mse: 0.2769 - val_loss: 0.2515 - val_mse: 0.2515\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2580 - mse: 0.2580 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2489 - mse: 0.2489 - val_loss: 0.2349 - val_mse: 0.2349\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2441 - mse: 0.2441 - val_loss: 0.2296 - val_mse: 0.2296\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2413 - mse: 0.2413 - val_loss: 0.2256 - val_mse: 0.2256\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2395 - mse: 0.2395 - val_loss: 0.2227 - val_mse: 0.2227\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2385 - mse: 0.2385 - val_loss: 0.2197 - val_mse: 0.2197\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2377 - mse: 0.2377 - val_loss: 0.2182 - val_mse: 0.2182\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2373 - mse: 0.2373 - val_loss: 0.2160 - val_mse: 0.2160\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2370 - mse: 0.2370 - val_loss: 0.2139 - val_mse: 0.2139\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2368 - mse: 0.2368 - val_loss: 0.2131 - val_mse: 0.2131\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2125 - val_mse: 0.2125\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2115 - val_mse: 0.2115\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2112 - val_mse: 0.2112\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2119 - val_mse: 0.2119\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2117 - val_mse: 0.2117\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2110 - val_mse: 0.2110\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2105 - val_mse: 0.2105\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2109 - val_mse: 0.2109\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2102 - val_mse: 0.2102\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2096 - val_mse: 0.2096\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2092 - val_mse: 0.2092\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2106 - val_mse: 0.2106\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2108 - val_mse: 0.2108\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2119 - val_mse: 0.2119\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2116 - val_mse: 0.2116\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 8ms/step - loss: 1.7631 - mse: 1.7631 - val_loss: 1.2752 - val_mse: 1.2752\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.8614 - mse: 0.8614 - val_loss: 0.6946 - val_mse: 0.6946\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5358 - mse: 0.5358 - val_loss: 0.4665 - val_mse: 0.4665\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 0.3593 - val_mse: 0.3593\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.3143 - mse: 0.3143 - val_loss: 0.3058 - val_mse: 0.3058\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2766 - mse: 0.2766 - val_loss: 0.2777 - val_mse: 0.2777\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.2572 - mse: 0.2572 - val_loss: 0.2624 - val_mse: 0.2624\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2471 - mse: 0.2471 - val_loss: 0.2541 - val_mse: 0.2541\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2420 - mse: 0.2420 - val_loss: 0.2491 - val_mse: 0.2491\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2393 - mse: 0.2393 - val_loss: 0.2458 - val_mse: 0.2458\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 0.2445 - val_mse: 0.2445\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2431 - val_mse: 0.2431\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2368 - mse: 0.2368 - val_loss: 0.2429 - val_mse: 0.2429\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2422 - val_mse: 0.2422\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2421 - val_mse: 0.2421\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2422 - val_mse: 0.2422\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2411 - val_mse: 0.2411\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 3.9209 - mse: 3.9209 - val_loss: 2.2323 - val_mse: 2.2323\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6350 - mse: 1.6350 - val_loss: 1.0908 - val_mse: 1.0908\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8080 - mse: 0.8080 - val_loss: 0.6082 - val_mse: 0.6082\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4748 - mse: 0.4748 - val_loss: 0.4021 - val_mse: 0.4021\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3371 - mse: 0.3371 - val_loss: 0.3112 - val_mse: 0.3112\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2805 - mse: 0.2805 - val_loss: 0.2719 - val_mse: 0.2719\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2570 - mse: 0.2570 - val_loss: 0.2544 - val_mse: 0.2544\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2471 - mse: 0.2471 - val_loss: 0.2462 - val_mse: 0.2462\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2430 - mse: 0.2430 - val_loss: 0.2424 - val_mse: 0.2424\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2413 - mse: 0.2413 - val_loss: 0.2403 - val_mse: 0.2403\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2405 - mse: 0.2405 - val_loss: 0.2391 - val_mse: 0.2391\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 0.2384 - val_mse: 0.2384\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2382 - val_mse: 0.2382\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2379 - val_mse: 0.2379\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 13ms/step - loss: 3.6069 - mse: 3.6069 - val_loss: 3.0279 - val_mse: 3.0279\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.7682 - mse: 2.7682 - val_loss: 2.3583 - val_mse: 2.3583\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.1810 - mse: 2.1810 - val_loss: 1.8759 - val_mse: 1.8759\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7525 - mse: 1.7525 - val_loss: 1.5165 - val_mse: 1.5165\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4305 - mse: 1.4305 - val_loss: 1.2485 - val_mse: 1.2485\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1851 - mse: 1.1851 - val_loss: 1.0387 - val_mse: 1.0387\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9920 - mse: 0.9920 - val_loss: 0.8785 - val_mse: 0.8785\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.8430 - mse: 0.8430 - val_loss: 0.7508 - val_mse: 0.7508\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.7236 - mse: 0.7236 - val_loss: 0.6523 - val_mse: 0.6523\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6294 - mse: 0.6294 - val_loss: 0.5754 - val_mse: 0.5754\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5535 - mse: 0.5535 - val_loss: 0.5111 - val_mse: 0.5111\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4921 - mse: 0.4921 - val_loss: 0.4622 - val_mse: 0.4622\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4434 - mse: 0.4434 - val_loss: 0.4234 - val_mse: 0.4234\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4048 - mse: 0.4048 - val_loss: 0.3918 - val_mse: 0.3918\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3735 - mse: 0.3735 - val_loss: 0.3671 - val_mse: 0.3671\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3485 - mse: 0.3485 - val_loss: 0.3480 - val_mse: 0.3480\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3280 - mse: 0.3280 - val_loss: 0.3326 - val_mse: 0.3326\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3117 - mse: 0.3117 - val_loss: 0.3209 - val_mse: 0.3209\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2986 - mse: 0.2986 - val_loss: 0.3122 - val_mse: 0.3122\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2881 - mse: 0.2881 - val_loss: 0.3038 - val_mse: 0.3038\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2795 - mse: 0.2795 - val_loss: 0.2989 - val_mse: 0.2989\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2727 - mse: 0.2727 - val_loss: 0.2931 - val_mse: 0.2931\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2671 - mse: 0.2671 - val_loss: 0.2890 - val_mse: 0.2890\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2628 - mse: 0.2628 - val_loss: 0.2862 - val_mse: 0.2862\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2591 - mse: 0.2591 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2563 - mse: 0.2563 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2541 - mse: 0.2541 - val_loss: 0.2814 - val_mse: 0.2814\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2521 - mse: 0.2521 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2507 - mse: 0.2507 - val_loss: 0.2787 - val_mse: 0.2787\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2496 - mse: 0.2496 - val_loss: 0.2786 - val_mse: 0.2786\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2486 - mse: 0.2486 - val_loss: 0.2787 - val_mse: 0.2787\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2479 - mse: 0.2479 - val_loss: 0.2785 - val_mse: 0.2785\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2471 - mse: 0.2471 - val_loss: 0.2787 - val_mse: 0.2787\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2467 - mse: 0.2467 - val_loss: 0.2788 - val_mse: 0.2788\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2464 - mse: 0.2464 - val_loss: 0.2792 - val_mse: 0.2792\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2461 - mse: 0.2461 - val_loss: 0.2781 - val_mse: 0.2781\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2457 - mse: 0.2457 - val_loss: 0.2785 - val_mse: 0.2785\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2454 - mse: 0.2454 - val_loss: 0.2784 - val_mse: 0.2784\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2453 - mse: 0.2453 - val_loss: 0.2787 - val_mse: 0.2787\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2452 - mse: 0.2452 - val_loss: 0.2788 - val_mse: 0.2788\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2450 - mse: 0.2450 - val_loss: 0.2782 - val_mse: 0.2782\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2450 - mse: 0.2450 - val_loss: 0.2780 - val_mse: 0.2780\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2449 - mse: 0.2449 - val_loss: 0.2778 - val_mse: 0.2778\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2449 - mse: 0.2449 - val_loss: 0.2784 - val_mse: 0.2784\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2788 - val_mse: 0.2788\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2792 - val_mse: 0.2792\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2792 - val_mse: 0.2792\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2789 - val_mse: 0.2789\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2788 - val_mse: 0.2788\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2789 - val_mse: 0.2789\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 3.2979 - mse: 3.2979 - val_loss: 2.6944 - val_mse: 2.6944\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.0276 - mse: 2.0276 - val_loss: 1.7813 - val_mse: 1.7813\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3320 - mse: 1.3320 - val_loss: 1.2513 - val_mse: 1.2513\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9320 - mse: 0.9320 - val_loss: 0.9081 - val_mse: 0.9081\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6813 - mse: 0.6813 - val_loss: 0.6827 - val_mse: 0.6827\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5228 - mse: 0.5228 - val_loss: 0.5376 - val_mse: 0.5376\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4230 - mse: 0.4230 - val_loss: 0.4362 - val_mse: 0.4362\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3559 - mse: 0.3559 - val_loss: 0.3694 - val_mse: 0.3694\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3141 - mse: 0.3141 - val_loss: 0.3223 - val_mse: 0.3223\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2862 - mse: 0.2862 - val_loss: 0.2904 - val_mse: 0.2904\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2687 - mse: 0.2687 - val_loss: 0.2697 - val_mse: 0.2697\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2574 - mse: 0.2574 - val_loss: 0.2532 - val_mse: 0.2532\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2499 - mse: 0.2499 - val_loss: 0.2421 - val_mse: 0.2421\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2453 - mse: 0.2453 - val_loss: 0.2329 - val_mse: 0.2329\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2418 - mse: 0.2418 - val_loss: 0.2267 - val_mse: 0.2267\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2399 - mse: 0.2399 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2385 - mse: 0.2385 - val_loss: 0.2211 - val_mse: 0.2211\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2379 - mse: 0.2379 - val_loss: 0.2194 - val_mse: 0.2194\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2374 - mse: 0.2374 - val_loss: 0.2172 - val_mse: 0.2172\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2370 - mse: 0.2370 - val_loss: 0.2155 - val_mse: 0.2155\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2368 - mse: 0.2368 - val_loss: 0.2141 - val_mse: 0.2141\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2132 - val_mse: 0.2132\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2114 - val_mse: 0.2114\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2124 - val_mse: 0.2124\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2125 - val_mse: 0.2125\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2108 - val_mse: 0.2108\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2103 - val_mse: 0.2103\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2106 - val_mse: 0.2106\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2109 - val_mse: 0.2109\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2113 - val_mse: 0.2113\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2113 - val_mse: 0.2113\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2106 - val_mse: 0.2106\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2108 - val_mse: 0.2108\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2102 - val_mse: 0.2102\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2099 - val_mse: 0.2099\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2100 - val_mse: 0.2100\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2100 - val_mse: 0.2100\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2110 - val_mse: 0.2110\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2103 - val_mse: 0.2103\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2108 - val_mse: 0.2108\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2110 - val_mse: 0.2110\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2098 - val_mse: 0.2098\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2096 - val_mse: 0.2096\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2094 - val_mse: 0.2094\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2096 - val_mse: 0.2096\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2104 - val_mse: 0.2104\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2100 - val_mse: 0.2100\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2099 - val_mse: 0.2099\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 9ms/step - loss: 0.7693 - mse: 0.7693 - val_loss: 0.4566 - val_mse: 0.4566\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.3456 - mse: 0.3456 - val_loss: 0.2948 - val_mse: 0.2948\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2682 - mse: 0.2682 - val_loss: 0.2627 - val_mse: 0.2627\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2491 - mse: 0.2491 - val_loss: 0.2527 - val_mse: 0.2527\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.2423 - mse: 0.2423 - val_loss: 0.2479 - val_mse: 0.2479\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2393 - mse: 0.2393 - val_loss: 0.2458 - val_mse: 0.2458\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2378 - mse: 0.2378 - val_loss: 0.2447 - val_mse: 0.2447\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2431 - val_mse: 0.2431\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.2421 - val_mse: 0.2421\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2420 - val_mse: 0.2420\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2421 - val_mse: 0.2421\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2420 - val_mse: 0.2420\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2362 - mse: 0.2362 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2407 - val_mse: 0.2407\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2411 - val_mse: 0.2411\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2411 - val_mse: 0.2411\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2411 - val_mse: 0.2411\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2411 - val_mse: 0.2411\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 0.6302 - mse: 0.6302 - val_loss: 0.3284 - val_mse: 0.3284\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2798 - mse: 0.2798 - val_loss: 0.2541 - val_mse: 0.2541\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2466 - mse: 0.2466 - val_loss: 0.2439 - val_mse: 0.2439\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2420 - mse: 0.2420 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.2394 - val_mse: 0.2394\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2403 - mse: 0.2403 - val_loss: 0.2386 - val_mse: 0.2386\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2383 - val_mse: 0.2383\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2379 - val_mse: 0.2379\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2375 - val_mse: 0.2375\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2379 - val_mse: 0.2379\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2399 - mse: 0.2399 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2399 - mse: 0.2399 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 2.1575 - mse: 2.1575 - val_loss: 2.4435 - val_mse: 2.4435\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.7624 - mse: 1.7624 - val_loss: 2.0290 - val_mse: 2.0290\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5239 - mse: 1.5239 - val_loss: 1.7531 - val_mse: 1.7531\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3716 - mse: 1.3716 - val_loss: 1.5647 - val_mse: 1.5647\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.2696 - mse: 1.2696 - val_loss: 1.4402 - val_mse: 1.4402\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2008 - mse: 1.2008 - val_loss: 1.3539 - val_mse: 1.3539\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1514 - mse: 1.1514 - val_loss: 1.2850 - val_mse: 1.2850\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.1135 - mse: 1.1135 - val_loss: 1.2396 - val_mse: 1.2396\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0857 - mse: 1.0857 - val_loss: 1.2079 - val_mse: 1.2079\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0641 - mse: 1.0641 - val_loss: 1.1797 - val_mse: 1.1797\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 7ms/step - loss: 3.0442 - mse: 3.0442 - val_loss: 2.5632 - val_mse: 2.5632\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.0898 - mse: 2.0898 - val_loss: 1.9625 - val_mse: 1.9625\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6317 - mse: 1.6317 - val_loss: 1.6064 - val_mse: 1.6064\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3727 - mse: 1.3727 - val_loss: 1.3842 - val_mse: 1.3842\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2221 - mse: 1.2221 - val_loss: 1.2284 - val_mse: 1.2284\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1220 - mse: 1.1220 - val_loss: 1.1160 - val_mse: 1.1160\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0565 - mse: 1.0565 - val_loss: 1.0457 - val_mse: 1.0457\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0169 - mse: 1.0169 - val_loss: 0.9867 - val_mse: 0.9867\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9908 - mse: 0.9908 - val_loss: 0.9555 - val_mse: 0.9555\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.9246 - val_mse: 0.9246\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 2s 11ms/step - loss: 3.8361 - mse: 3.8361 - val_loss: 3.0328 - val_mse: 3.0328\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 2.2849 - mse: 2.2849 - val_loss: 1.9658 - val_mse: 1.9658\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.6188 - mse: 1.6188 - val_loss: 1.4875 - val_mse: 1.4875\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.2913 - mse: 1.2913 - val_loss: 1.2486 - val_mse: 1.2486\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.1246 - mse: 1.1246 - val_loss: 1.1250 - val_mse: 1.1250\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0383 - mse: 1.0383 - val_loss: 1.0571 - val_mse: 1.0571\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9934 - mse: 0.9934 - val_loss: 1.0195 - val_mse: 1.0195\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9704 - mse: 0.9704 - val_loss: 0.9981 - val_mse: 0.9981\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9584 - mse: 0.9584 - val_loss: 0.9857 - val_mse: 0.9857\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9520 - mse: 0.9520 - val_loss: 0.9774 - val_mse: 0.9774\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 2.8940 - mse: 2.8940 - val_loss: 1.9959 - val_mse: 1.9959\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.6376 - mse: 1.6376 - val_loss: 1.4059 - val_mse: 1.4059\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2315 - mse: 1.2315 - val_loss: 1.1610 - val_mse: 1.1610\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0716 - mse: 1.0716 - val_loss: 1.0508 - val_mse: 1.0508\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0070 - mse: 1.0070 - val_loss: 1.0021 - val_mse: 1.0021\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9800 - mse: 0.9800 - val_loss: 0.9778 - val_mse: 0.9778\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9688 - mse: 0.9688 - val_loss: 0.9656 - val_mse: 0.9656\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9637 - mse: 0.9637 - val_loss: 0.9586 - val_mse: 0.9586\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9618 - mse: 0.9618 - val_loss: 0.9554 - val_mse: 0.9554\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.9534 - val_mse: 0.9534\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 22ms/step - loss: 5.1006 - mse: 5.1006 - val_loss: 4.6474 - val_mse: 4.6474\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.1394 - mse: 4.1394 - val_loss: 3.8039 - val_mse: 3.8039\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3.4386 - mse: 3.4386 - val_loss: 3.1896 - val_mse: 3.1896\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9153 - mse: 2.9153 - val_loss: 2.7216 - val_mse: 2.7216\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5095 - mse: 2.5095 - val_loss: 2.3668 - val_mse: 2.3668\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2.1981 - mse: 2.1981 - val_loss: 2.0930 - val_mse: 2.0930\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9543 - mse: 1.9543 - val_loss: 1.8784 - val_mse: 1.8784\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.7604 - mse: 1.7604 - val_loss: 1.7117 - val_mse: 1.7117\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6052 - mse: 1.6052 - val_loss: 1.5774 - val_mse: 1.5774\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4814 - mse: 1.4814 - val_loss: 1.4794 - val_mse: 1.4794\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3831 - mse: 1.3831 - val_loss: 1.3984 - val_mse: 1.3984\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3039 - mse: 1.3039 - val_loss: 1.3327 - val_mse: 1.3327\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.2392 - mse: 1.2392 - val_loss: 1.2784 - val_mse: 1.2784\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1882 - mse: 1.1882 - val_loss: 1.2407 - val_mse: 1.2407\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1477 - mse: 1.1477 - val_loss: 1.2116 - val_mse: 1.2116\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 1.7590 - mse: 1.7590 - val_loss: 1.2362 - val_mse: 1.2362\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2447 - mse: 1.2447 - val_loss: 1.0470 - val_mse: 1.0470\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0812 - mse: 1.0812 - val_loss: 0.9793 - val_mse: 0.9793\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9444 - val_mse: 0.9444\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9849 - mse: 0.9849 - val_loss: 0.9217 - val_mse: 0.9217\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9693 - mse: 0.9693 - val_loss: 0.9015 - val_mse: 0.9015\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9607 - mse: 0.9607 - val_loss: 0.8911 - val_mse: 0.8911\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9554 - mse: 0.9554 - val_loss: 0.8810 - val_mse: 0.8810\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9516 - mse: 0.9516 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9498 - mse: 0.9498 - val_loss: 0.8584 - val_mse: 0.8584\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9480 - mse: 0.9480 - val_loss: 0.8539 - val_mse: 0.8539\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9470 - mse: 0.9470 - val_loss: 0.8461 - val_mse: 0.8461\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9464 - mse: 0.9464 - val_loss: 0.8473 - val_mse: 0.8473\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9460 - mse: 0.9460 - val_loss: 0.8460 - val_mse: 0.8460\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9461 - mse: 0.9461 - val_loss: 0.8471 - val_mse: 0.8471\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 4.7929 - mse: 4.7929 - val_loss: 3.7394 - val_mse: 3.7394\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.7793 - mse: 2.7793 - val_loss: 2.3216 - val_mse: 2.3216\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 1.8710 - mse: 1.8710 - val_loss: 1.6671 - val_mse: 1.6671\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.4202 - mse: 1.4202 - val_loss: 1.3411 - val_mse: 1.3411\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 1.1906 - mse: 1.1906 - val_loss: 1.1751 - val_mse: 1.1751\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0731 - mse: 1.0731 - val_loss: 1.0839 - val_mse: 1.0839\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.0114 - mse: 1.0114 - val_loss: 1.0359 - val_mse: 1.0359\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9797 - mse: 0.9797 - val_loss: 1.0081 - val_mse: 1.0081\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9632 - mse: 0.9632 - val_loss: 0.9934 - val_mse: 0.9934\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9548 - mse: 0.9548 - val_loss: 0.9826 - val_mse: 0.9826\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9506 - mse: 0.9506 - val_loss: 0.9774 - val_mse: 0.9774\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9481 - mse: 0.9481 - val_loss: 0.9731 - val_mse: 0.9731\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9468 - mse: 0.9468 - val_loss: 0.9706 - val_mse: 0.9706\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9461 - mse: 0.9461 - val_loss: 0.9707 - val_mse: 0.9707\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.9689 - val_mse: 0.9689\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 2.5310 - mse: 2.5310 - val_loss: 1.7740 - val_mse: 1.7740\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4848 - mse: 1.4848 - val_loss: 1.3080 - val_mse: 1.3080\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1663 - mse: 1.1663 - val_loss: 1.1172 - val_mse: 1.1172\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.0450 - mse: 1.0450 - val_loss: 1.0312 - val_mse: 1.0312\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9951 - mse: 0.9951 - val_loss: 0.9893 - val_mse: 0.9893\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9741 - mse: 0.9741 - val_loss: 0.9708 - val_mse: 0.9708\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9657 - mse: 0.9657 - val_loss: 0.9617 - val_mse: 0.9617\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9621 - mse: 0.9621 - val_loss: 0.9566 - val_mse: 0.9566\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9609 - mse: 0.9609 - val_loss: 0.9546 - val_mse: 0.9546\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9605 - mse: 0.9605 - val_loss: 0.9528 - val_mse: 0.9528\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9520 - val_mse: 0.9520\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9515 - val_mse: 0.9515\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9513 - val_mse: 0.9513\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9510 - val_mse: 0.9510\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.9505 - val_mse: 0.9505\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 3.6590 - mse: 3.6590 - val_loss: 3.5396 - val_mse: 3.5396\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2.9739 - mse: 2.9739 - val_loss: 2.9047 - val_mse: 2.9047\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2.4978 - mse: 2.4978 - val_loss: 2.4680 - val_mse: 2.4680\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.1592 - mse: 2.1592 - val_loss: 2.1490 - val_mse: 2.1490\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9090 - mse: 1.9090 - val_loss: 1.9087 - val_mse: 1.9087\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7164 - mse: 1.7164 - val_loss: 1.7296 - val_mse: 1.7296\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.5663 - mse: 1.5663 - val_loss: 1.5859 - val_mse: 1.5859\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4468 - mse: 1.4468 - val_loss: 1.4834 - val_mse: 1.4834\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.3520 - mse: 1.3520 - val_loss: 1.3940 - val_mse: 1.3940\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2776 - mse: 1.2776 - val_loss: 1.3228 - val_mse: 1.3228\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2167 - mse: 1.2167 - val_loss: 1.2701 - val_mse: 1.2701\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.1687 - mse: 1.1687 - val_loss: 1.2320 - val_mse: 1.2320\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1315 - mse: 1.1315 - val_loss: 1.2031 - val_mse: 1.2031\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.1024 - mse: 1.1024 - val_loss: 1.1811 - val_mse: 1.1811\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.0775 - mse: 1.0775 - val_loss: 1.1656 - val_mse: 1.1656\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0586 - mse: 1.0586 - val_loss: 1.1538 - val_mse: 1.1538\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.0429 - mse: 1.0429 - val_loss: 1.1421 - val_mse: 1.1421\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 1.0305 - mse: 1.0305 - val_loss: 1.1340 - val_mse: 1.1340\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.0203 - mse: 1.0203 - val_loss: 1.1325 - val_mse: 1.1325\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.0125 - mse: 1.0125 - val_loss: 1.1224 - val_mse: 1.1224\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.0060 - mse: 1.0060 - val_loss: 1.1183 - val_mse: 1.1183\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0003 - mse: 1.0003 - val_loss: 1.1182 - val_mse: 1.1182\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9963 - mse: 0.9963 - val_loss: 1.1172 - val_mse: 1.1172\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.9927 - mse: 0.9927 - val_loss: 1.1199 - val_mse: 1.1199\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.9901 - mse: 0.9901 - val_loss: 1.1190 - val_mse: 1.1190\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9878 - mse: 0.9878 - val_loss: 1.1192 - val_mse: 1.1192\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.9859 - mse: 0.9859 - val_loss: 1.1213 - val_mse: 1.1213\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.9846 - mse: 0.9846 - val_loss: 1.1195 - val_mse: 1.1195\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9841 - mse: 0.9841 - val_loss: 1.1147 - val_mse: 1.1147\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9822 - mse: 0.9822 - val_loss: 1.1134 - val_mse: 1.1134\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 14ms/step - loss: 2.1994 - mse: 2.1994 - val_loss: 1.7211 - val_mse: 1.7211\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.5380 - mse: 1.5380 - val_loss: 1.3792 - val_mse: 1.3792\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.2649 - mse: 1.2649 - val_loss: 1.2098 - val_mse: 1.2098\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.1366 - mse: 1.1366 - val_loss: 1.1044 - val_mse: 1.1044\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0612 - mse: 1.0612 - val_loss: 1.0387 - val_mse: 1.0387\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.0202 - mse: 1.0202 - val_loss: 0.9846 - val_mse: 0.9846\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9922 - mse: 0.9922 - val_loss: 0.9533 - val_mse: 0.9533\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9761 - mse: 0.9761 - val_loss: 0.9259 - val_mse: 0.9259\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9653 - mse: 0.9653 - val_loss: 0.9023 - val_mse: 0.9023\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9585 - mse: 0.9585 - val_loss: 0.8878 - val_mse: 0.8878\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9536 - mse: 0.9536 - val_loss: 0.8778 - val_mse: 0.8778\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9504 - mse: 0.9504 - val_loss: 0.8671 - val_mse: 0.8671\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9490 - mse: 0.9490 - val_loss: 0.8600 - val_mse: 0.8600\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9477 - mse: 0.9477 - val_loss: 0.8559 - val_mse: 0.8559\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9469 - mse: 0.9469 - val_loss: 0.8527 - val_mse: 0.8527\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9460 - mse: 0.9460 - val_loss: 0.8508 - val_mse: 0.8508\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9460 - mse: 0.9460 - val_loss: 0.8503 - val_mse: 0.8503\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9458 - mse: 0.9458 - val_loss: 0.8483 - val_mse: 0.8483\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.8492 - val_mse: 0.8492\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8481 - val_mse: 0.8481\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8468 - val_mse: 0.8468\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8472 - val_mse: 0.8472\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.8457 - val_mse: 0.8457\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8431 - val_mse: 0.8431\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8421 - val_mse: 0.8421\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8387 - val_mse: 0.8387\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8389 - val_mse: 0.8389\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8366 - val_mse: 0.8366\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8345 - val_mse: 0.8345\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.8413 - val_mse: 0.8413\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 1s 7ms/step - loss: 3.6958 - mse: 3.6958 - val_loss: 2.9332 - val_mse: 2.9332\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 2.2104 - mse: 2.2104 - val_loss: 1.9098 - val_mse: 1.9098\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.5782 - mse: 1.5782 - val_loss: 1.4591 - val_mse: 1.4591\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.2718 - mse: 1.2718 - val_loss: 1.2345 - val_mse: 1.2345\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.1150 - mse: 1.1150 - val_loss: 1.1163 - val_mse: 1.1163\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0331 - mse: 1.0331 - val_loss: 1.0514 - val_mse: 1.0514\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9908 - mse: 0.9908 - val_loss: 1.0159 - val_mse: 1.0159\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9687 - mse: 0.9687 - val_loss: 0.9963 - val_mse: 0.9963\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9575 - mse: 0.9575 - val_loss: 0.9846 - val_mse: 0.9846\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9517 - mse: 0.9517 - val_loss: 0.9767 - val_mse: 0.9767\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9485 - mse: 0.9485 - val_loss: 0.9739 - val_mse: 0.9739\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9470 - mse: 0.9470 - val_loss: 0.9714 - val_mse: 0.9714\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9464 - mse: 0.9464 - val_loss: 0.9695 - val_mse: 0.9695\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.9680 - val_mse: 0.9680\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9687 - val_mse: 0.9687\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9660 - val_mse: 0.9660\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9664 - val_mse: 0.9664\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9635 - val_mse: 0.9635\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9657 - val_mse: 0.9657\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9650 - val_mse: 0.9650\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9656 - val_mse: 0.9656\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9668 - val_mse: 0.9668\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9651 - val_mse: 0.9651\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.9651 - val_mse: 0.9651\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9654 - val_mse: 0.9654\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9665 - val_mse: 0.9665\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9651 - val_mse: 0.9651\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9654 - val_mse: 0.9654\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9659 - val_mse: 0.9659\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9643 - val_mse: 0.9643\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 1s 6ms/step - loss: 3.9498 - mse: 3.9498 - val_loss: 2.6260 - val_mse: 2.6260\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0706 - mse: 2.0706 - val_loss: 1.6857 - val_mse: 1.6857\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4117 - mse: 1.4117 - val_loss: 1.2838 - val_mse: 1.2838\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.1461 - mse: 1.1461 - val_loss: 1.1055 - val_mse: 1.1055\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0377 - mse: 1.0377 - val_loss: 1.0261 - val_mse: 1.0261\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9927 - mse: 0.9927 - val_loss: 0.9880 - val_mse: 0.9880\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9738 - mse: 0.9738 - val_loss: 0.9711 - val_mse: 0.9711\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9658 - mse: 0.9658 - val_loss: 0.9619 - val_mse: 0.9619\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9623 - mse: 0.9623 - val_loss: 0.9571 - val_mse: 0.9571\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9610 - mse: 0.9610 - val_loss: 0.9541 - val_mse: 0.9541\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9605 - mse: 0.9605 - val_loss: 0.9527 - val_mse: 0.9527\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9516 - val_mse: 0.9516\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9513 - val_mse: 0.9513\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9510 - val_mse: 0.9510\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9598 - mse: 0.9598 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9597 - mse: 0.9597 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9598 - mse: 0.9598 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9598 - mse: 0.9598 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9511 - val_mse: 0.9511\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 25ms/step - loss: 3.7952 - mse: 3.7952 - val_loss: 3.6538 - val_mse: 3.6538\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0896 - mse: 3.0896 - val_loss: 3.0051 - val_mse: 3.0051\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.5937 - mse: 2.5937 - val_loss: 2.5409 - val_mse: 2.5409\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2.2327 - mse: 2.2327 - val_loss: 2.1942 - val_mse: 2.1942\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.9593 - mse: 1.9593 - val_loss: 1.9415 - val_mse: 1.9415\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.7559 - mse: 1.7559 - val_loss: 1.7565 - val_mse: 1.7565\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5969 - mse: 1.5969 - val_loss: 1.6050 - val_mse: 1.6050\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.4704 - mse: 1.4704 - val_loss: 1.4894 - val_mse: 1.4894\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3720 - mse: 1.3720 - val_loss: 1.4043 - val_mse: 1.4043\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.2924 - mse: 1.2924 - val_loss: 1.3360 - val_mse: 1.3360\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.2310 - mse: 1.2310 - val_loss: 1.2872 - val_mse: 1.2872\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.1806 - mse: 1.1806 - val_loss: 1.2451 - val_mse: 1.2451\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1413 - mse: 1.1413 - val_loss: 1.2131 - val_mse: 1.2131\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1096 - mse: 1.1096 - val_loss: 1.1901 - val_mse: 1.1901\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0834 - mse: 1.0834 - val_loss: 1.1758 - val_mse: 1.1758\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0636 - mse: 1.0636 - val_loss: 1.1600 - val_mse: 1.1600\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.0465 - mse: 1.0465 - val_loss: 1.1441 - val_mse: 1.1441\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0335 - mse: 1.0335 - val_loss: 1.1388 - val_mse: 1.1388\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0233 - mse: 1.0233 - val_loss: 1.1362 - val_mse: 1.1362\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.0144 - mse: 1.0144 - val_loss: 1.1312 - val_mse: 1.1312\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.0076 - mse: 1.0076 - val_loss: 1.1262 - val_mse: 1.1262\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0017 - mse: 1.0017 - val_loss: 1.1228 - val_mse: 1.1228\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9970 - mse: 0.9970 - val_loss: 1.1205 - val_mse: 1.1205\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.9939 - mse: 0.9939 - val_loss: 1.1186 - val_mse: 1.1186\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9915 - mse: 0.9915 - val_loss: 1.1119 - val_mse: 1.1119\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9882 - mse: 0.9882 - val_loss: 1.1133 - val_mse: 1.1133\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9866 - mse: 0.9866 - val_loss: 1.1142 - val_mse: 1.1142\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9848 - mse: 0.9848 - val_loss: 1.1121 - val_mse: 1.1121\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.9834 - mse: 0.9834 - val_loss: 1.1082 - val_mse: 1.1082\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9829 - mse: 0.9829 - val_loss: 1.1118 - val_mse: 1.1118\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9820 - mse: 0.9820 - val_loss: 1.1176 - val_mse: 1.1176\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9812 - mse: 0.9812 - val_loss: 1.1129 - val_mse: 1.1129\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9808 - mse: 0.9808 - val_loss: 1.1119 - val_mse: 1.1119\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9801 - mse: 0.9801 - val_loss: 1.1137 - val_mse: 1.1137\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9799 - mse: 0.9799 - val_loss: 1.1139 - val_mse: 1.1139\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9801 - mse: 0.9801 - val_loss: 1.1164 - val_mse: 1.1164\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9798 - mse: 0.9798 - val_loss: 1.1163 - val_mse: 1.1163\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9792 - mse: 0.9792 - val_loss: 1.1167 - val_mse: 1.1167\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9788 - mse: 0.9788 - val_loss: 1.1157 - val_mse: 1.1157\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9790 - mse: 0.9790 - val_loss: 1.1147 - val_mse: 1.1147\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9788 - mse: 0.9788 - val_loss: 1.1181 - val_mse: 1.1181\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9787 - mse: 0.9787 - val_loss: 1.1199 - val_mse: 1.1199\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9786 - mse: 0.9786 - val_loss: 1.1201 - val_mse: 1.1201\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 1.1178 - val_mse: 1.1178\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.9789 - mse: 0.9789 - val_loss: 1.1178 - val_mse: 1.1178\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 1.1200 - val_mse: 1.1200\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9788 - mse: 0.9788 - val_loss: 1.1174 - val_mse: 1.1174\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9788 - mse: 0.9788 - val_loss: 1.1158 - val_mse: 1.1158\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9790 - mse: 0.9790 - val_loss: 1.1164 - val_mse: 1.1164\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 1.1152 - val_mse: 1.1152\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.8684 - mse: 1.8684 - val_loss: 1.3659 - val_mse: 1.3659\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3203 - mse: 1.3203 - val_loss: 1.1293 - val_mse: 1.1293\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1221 - mse: 1.1221 - val_loss: 1.0407 - val_mse: 1.0407\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0442 - mse: 1.0442 - val_loss: 0.9873 - val_mse: 0.9873\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0049 - mse: 1.0049 - val_loss: 0.9532 - val_mse: 0.9532\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9829 - mse: 0.9829 - val_loss: 0.9328 - val_mse: 0.9328\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9699 - mse: 0.9699 - val_loss: 0.9162 - val_mse: 0.9162\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9622 - mse: 0.9622 - val_loss: 0.8984 - val_mse: 0.8984\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9565 - mse: 0.9565 - val_loss: 0.8855 - val_mse: 0.8855\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9526 - mse: 0.9526 - val_loss: 0.8797 - val_mse: 0.8797\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9501 - mse: 0.9501 - val_loss: 0.8691 - val_mse: 0.8691\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9482 - mse: 0.9482 - val_loss: 0.8630 - val_mse: 0.8630\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9470 - mse: 0.9470 - val_loss: 0.8565 - val_mse: 0.8565\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9463 - mse: 0.9463 - val_loss: 0.8531 - val_mse: 0.8531\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.8538 - val_mse: 0.8538\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.8521 - val_mse: 0.8521\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.8453 - val_mse: 0.8453\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8487 - val_mse: 0.8487\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8429 - val_mse: 0.8429\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8446 - val_mse: 0.8446\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8474 - val_mse: 0.8474\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8457 - val_mse: 0.8457\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8455 - val_mse: 0.8455\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8458 - val_mse: 0.8458\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.8395 - val_mse: 0.8395\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8405 - val_mse: 0.8405\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8443 - val_mse: 0.8443\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8438 - val_mse: 0.8438\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8439 - val_mse: 0.8439\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8436 - val_mse: 0.8436\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8459 - val_mse: 0.8459\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8430 - val_mse: 0.8430\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8373 - val_mse: 0.8373\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8372 - val_mse: 0.8372\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8421 - val_mse: 0.8421\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8401 - val_mse: 0.8401\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8367 - val_mse: 0.8367\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8368 - val_mse: 0.8368\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8376 - val_mse: 0.8376\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8386 - val_mse: 0.8386\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8374 - val_mse: 0.8374\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8374 - val_mse: 0.8374\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8368 - val_mse: 0.8368\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8358 - val_mse: 0.8358\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8396 - val_mse: 0.8396\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8381 - val_mse: 0.8381\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8425 - val_mse: 0.8425\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8352 - val_mse: 0.8352\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9458 - mse: 0.9458 - val_loss: 0.8364 - val_mse: 0.8364\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8383 - val_mse: 0.8383\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 4.8251 - mse: 4.8251 - val_loss: 3.7490 - val_mse: 3.7490\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.7973 - mse: 2.7973 - val_loss: 2.3310 - val_mse: 2.3310\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.8844 - mse: 1.8844 - val_loss: 1.6770 - val_mse: 1.6770\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.4284 - mse: 1.4284 - val_loss: 1.3480 - val_mse: 1.3480\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.1961 - mse: 1.1961 - val_loss: 1.1789 - val_mse: 1.1789\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.0757 - mse: 1.0757 - val_loss: 1.0871 - val_mse: 1.0871\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0135 - mse: 1.0135 - val_loss: 1.0368 - val_mse: 1.0368\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9812 - mse: 0.9812 - val_loss: 1.0080 - val_mse: 1.0080\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.9642 - mse: 0.9642 - val_loss: 0.9921 - val_mse: 0.9921\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9552 - mse: 0.9552 - val_loss: 0.9838 - val_mse: 0.9838\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9504 - mse: 0.9504 - val_loss: 0.9777 - val_mse: 0.9777\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9480 - mse: 0.9480 - val_loss: 0.9736 - val_mse: 0.9736\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9468 - mse: 0.9468 - val_loss: 0.9727 - val_mse: 0.9727\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9460 - mse: 0.9460 - val_loss: 0.9689 - val_mse: 0.9689\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9674 - val_mse: 0.9674\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9672 - val_mse: 0.9672\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.9680 - val_mse: 0.9680\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.9689 - val_mse: 0.9689\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9673 - val_mse: 0.9673\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9639 - val_mse: 0.9639\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9647 - val_mse: 0.9647\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9660 - val_mse: 0.9660\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9665 - val_mse: 0.9665\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9666 - val_mse: 0.9666\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9675 - val_mse: 0.9675\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9674 - val_mse: 0.9674\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9640 - val_mse: 0.9640\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9652 - val_mse: 0.9652\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9662 - val_mse: 0.9662\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.9448 - mse: 0.9448 - val_loss: 0.9622 - val_mse: 0.9622\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9647 - val_mse: 0.9647\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9661 - val_mse: 0.9661\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.9666 - val_mse: 0.9666\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9665 - val_mse: 0.9665\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9665 - val_mse: 0.9665\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9690 - val_mse: 0.9690\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9657 - val_mse: 0.9657\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9655 - val_mse: 0.9655\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 7ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9673 - val_mse: 0.9673\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9663 - val_mse: 0.9663\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9673 - val_mse: 0.9673\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9449 - mse: 0.9449 - val_loss: 0.9636 - val_mse: 0.9636\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9668 - val_mse: 0.9668\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9654 - val_mse: 0.9654\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9641 - val_mse: 0.9641\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9652 - val_mse: 0.9652\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9674 - val_mse: 0.9674\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9658 - val_mse: 0.9658\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.9643 - val_mse: 0.9643\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9661 - val_mse: 0.9661\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 4.4464 - mse: 4.4464 - val_loss: 2.9270 - val_mse: 2.9270\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.2742 - mse: 2.2742 - val_loss: 1.8175 - val_mse: 1.8175\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4966 - mse: 1.4966 - val_loss: 1.3416 - val_mse: 1.3416\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1810 - mse: 1.1810 - val_loss: 1.1289 - val_mse: 1.1289\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0522 - mse: 1.0522 - val_loss: 1.0368 - val_mse: 1.0368\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9985 - mse: 0.9985 - val_loss: 0.9941 - val_mse: 0.9941\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9761 - mse: 0.9761 - val_loss: 0.9745 - val_mse: 0.9745\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9670 - mse: 0.9670 - val_loss: 0.9631 - val_mse: 0.9631\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9630 - mse: 0.9630 - val_loss: 0.9581 - val_mse: 0.9581\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9613 - mse: 0.9613 - val_loss: 0.9553 - val_mse: 0.9553\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9608 - mse: 0.9608 - val_loss: 0.9534 - val_mse: 0.9534\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9605 - mse: 0.9605 - val_loss: 0.9528 - val_mse: 0.9528\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9520 - val_mse: 0.9520\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9516 - val_mse: 0.9516\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9517 - val_mse: 0.9517\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9511 - val_mse: 0.9511\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9513 - val_mse: 0.9513\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9505 - val_mse: 0.9505\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9502 - val_mse: 0.9502\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9505 - val_mse: 0.9505\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9597 - mse: 0.9597 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9510 - val_mse: 0.9510\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9510 - val_mse: 0.9510\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9509 - val_mse: 0.9509\n"
     ]
    }
   ],
   "source": [
    "# Iterate model over all combinations of parameters\n",
    "param_combinations = list(itertools.product(_sigma, _n_epochs, _n_train))\n",
    "\n",
    "loss = []\n",
    "\n",
    "for combination in param_combinations:\n",
    "\tloss.append(run_model (combination[0], combination[1], combination[2], N_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally now that we have the loss array, we are going to visualize the data obtained. I am using heatmaps to visualize the loss obtained from the model as a function of the number of epochs, the number of training data and the noise $\\sigma$. With fixed number of `N_train`, each heatmap gives the values of the loss with respect to the number of epochs (on the x-axis) and the noise $\\sigma$ (on the y-axis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot heatmaps\n",
    "def plot_heatmaps(loss, param_combinations, sigma_values, n_epochs_values, n_train_values):\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    gs = GridSpec(1, len(n_train_values), width_ratios=[1]*len(n_train_values), wspace=0.05)\n",
    "    \n",
    "    # Calculate the min and max of the loss values\n",
    "    vmin = min(loss)\n",
    "    vmax = max(loss)\n",
    "    \n",
    "    axes = []\n",
    "    for i, n_train in enumerate(n_train_values):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        axes.append(ax)\n",
    "        \n",
    "        # Filter the loss values for the current n_train\n",
    "        filtered_loss = [loss[j] for j in range(len(loss)) if param_combinations[j][2] == n_train]\n",
    "        \n",
    "        # Reshape the filtered loss into a matrix\n",
    "        loss_matrix = np.array(filtered_loss).reshape(len(sigma_values), len(n_epochs_values))\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sns.heatmap(\n",
    "            loss_matrix, annot=True, fmt='.2f', ax=ax, cmap='viridis', vmin=vmin, vmax=vmax,\n",
    "            cbar=False,  # Disable individual colorbars\n",
    "            xticklabels=n_epochs_values, yticklabels=sigma_values\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f'# of training data = {n_train}', fontsize=14)\n",
    "        ax.set_xlabel('Epochs', fontsize=12)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Sigma $\\sigma$', fontsize=12)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "            ax.tick_params(labelleft=False)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.05, right=0.9, top=0.9, bottom=0.1, wspace=0.2)\n",
    "    cbar_ax = fig.add_axes([0.91, 0.15, 0.02, 0.7])\n",
    "    plt.colorbar(axes[0].collections[0], cax=cbar_ax).set_label('Loss')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plot the heatmaps\n",
    "plot_heatmaps(loss, param_combinations, _sigma, _n_epochs, _n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite being not too easy to read as a data visualization method, these heatmaps actually contain a lot of information about the performance of the model. Let us draw some conclusions from the heatmaps.\n",
    "\n",
    "First off, looking at the difference of the same point in the heatmaps (fixed sigma and epochs) throughout the difference plots, i.e. different number of traning data, we can see how the loss function does not decrease directly with the increase of training data: it saw an improvement when going from $500$ to $1000$, but after that the loss got worse. We can interpret this as an overfitting of the model where more training data resulted in a worse prediction of the test data.\n",
    "\n",
    "The second observation is that with fixed sigma and number of training data, the loss did not vary significantly with the number of epochs (horizontally within a heatmap) especially for higher training data. This shows how the number of epochs does not affect the loss function significantly, and that the model saturates after a certain number of epochs. This number can be seen varying with training data, but we can affirm that after $15$ epochs, the loss does not get much better.\n",
    "\n",
    "Finally, we can see that the loss function increases with the noise $\\sigma$, as expected.\n",
    "\n",
    "In conclusion, the ideal number of training data was evidently $1000$. With this training data $30$ epochs were enough to saturate the model, and the noise $\\sigma$ should be kept as low as possible to have a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here is an alternate visualization that I tried, with a 3D plot rather than a heatmap. Not particularly clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           0.1374727487564087,
           0.05387556180357933,
           0.01390466932207346,
           0.00964627880603075,
           0.0919443815946579,
           0.017304908484220505,
           0.009770098142325878,
           0.00951233971863985,
           0.014430089853703976,
           0.008506488986313343,
           0.009663387201726437,
           0.009504759684205055,
           0.011124415323138237,
           0.00836271047592163,
           0.009638648480176926,
           0.009503677487373352,
           0.1432519555091858,
           0.08886174857616425,
           0.038996171206235886,
           0.03920729085803032,
           0.08131562918424606,
           0.04565000534057617,
           0.038750361651182175,
           0.03808854892849922,
           0.044404078274965286,
           0.0337478406727314,
           0.03856434300541878,
           0.038021281361579895,
           0.04479285329580307,
           0.0336712971329689,
           0.03860732167959213,
           0.038032397627830505,
           0.40419822931289673,
           0.22029060125350952,
           0.24802321195602417,
           0.2390303760766983,
           0.3627486824989319,
           0.21398349106311798,
           0.2423727810382843,
           0.23768304288387299,
           0.27778521180152893,
           0.2116362452507019,
           0.24134758114814758,
           0.237659752368927,
           0.27885445952415466,
           0.20989345014095306,
           0.2413073033094406,
           0.23771290481090546,
           1.1796609163284302,
           0.9246264696121216,
           0.977388858795166,
           0.9534252882003784,
           1.2115983963012695,
           0.84712815284729,
           0.9689128398895264,
           0.9505423903465271,
           1.1134498119354248,
           0.8413376808166504,
           0.9642989635467529,
           0.9505757093429565,
           1.1151540279388428,
           0.8382542133331299,
           0.9660676717758179,
           0.9509013295173645
          ],
          "colorbar": {
           "title": {
            "text": "Log(Loss)"
           }
          },
          "colorscale": [
           [
            0,
            "#440154"
           ],
           [
            0.1111111111111111,
            "#482878"
           ],
           [
            0.2222222222222222,
            "#3e4989"
           ],
           [
            0.3333333333333333,
            "#31688e"
           ],
           [
            0.4444444444444444,
            "#26828e"
           ],
           [
            0.5555555555555556,
            "#1f9e89"
           ],
           [
            0.6666666666666666,
            "#35b779"
           ],
           [
            0.7777777777777778,
            "#6ece58"
           ],
           [
            0.8888888888888888,
            "#b5de2b"
           ],
           [
            1,
            "#fde725"
           ]
          ],
          "opacity": 0.9,
          "size": 4
         },
         "mode": "markers",
         "text": [
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 500<br>Loss: 0.1375",
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.0539",
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.0139",
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.0096",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 500<br>Loss: 0.0919",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.0173",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.0098",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.0095",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 500<br>Loss: 0.0144",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.0085",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.0097",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.0095",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 500<br>Loss: 0.0111",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.0084",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.0096",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.0095",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 500<br>Loss: 0.1433",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.0889",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.0390",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.0392",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 500<br>Loss: 0.0813",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.0457",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.0388",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.0381",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 500<br>Loss: 0.0444",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.0337",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.0386",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.0380",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 500<br>Loss: 0.0448",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.0337",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.0386",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.0380",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 500<br>Loss: 0.4042",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.2203",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.2480",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.2390",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 500<br>Loss: 0.3627",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.2140",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.2424",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.2377",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 500<br>Loss: 0.2778",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.2116",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.2413",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.2377",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 500<br>Loss: 0.2789",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.2099",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.2413",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.2377",
          "Sigma: 1<br>Train data: 10<br>Epochs: 500<br>Loss: 1.1797",
          "Sigma: 1<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.9246",
          "Sigma: 1<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.9774",
          "Sigma: 1<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.9534",
          "Sigma: 1<br>Train data: 15<br>Epochs: 500<br>Loss: 1.2116",
          "Sigma: 1<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.8471",
          "Sigma: 1<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.9689",
          "Sigma: 1<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.9505",
          "Sigma: 1<br>Train data: 30<br>Epochs: 500<br>Loss: 1.1134",
          "Sigma: 1<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.8413",
          "Sigma: 1<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.9643",
          "Sigma: 1<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.9506",
          "Sigma: 1<br>Train data: 50<br>Epochs: 500<br>Loss: 1.1152",
          "Sigma: 1<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.8383",
          "Sigma: 1<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.9661",
          "Sigma: 1<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.9509"
         ],
         "type": "scatter3d",
         "x": [
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50,
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50,
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50,
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50
         ],
         "z": [
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000
         ]
        }
       ],
       "layout": {
        "height": 700,
        "scene": {
         "xaxis": {
          "title": {
           "font": {
            "size": 12
           },
           "text": "sigma"
          }
         },
         "yaxis": {
          "title": {
           "font": {
            "size": 12
           },
           "text": "train data"
          }
         },
         "zaxis": {
          "title": {
           "font": {
            "size": 12
           },
           "text": "epochs"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Scatter Plot of Loss with Different Parameters"
        },
        "width": 900
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate the parameters and losses into individual arrays\n",
    "sigma, n_train, n_epochs = zip(*param_combinations)\n",
    "loss = np.array(loss)\n",
    "\n",
    "# Create a trace for the 3D plot\n",
    "trace = go.Scatter3d(\n",
    "    x=sigma,\n",
    "    y=n_train,\n",
    "    z=n_epochs,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=loss,  # Use the log-transformed loss for coloring\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Log(Loss)'),\n",
    "        opacity=0.9\n",
    "    ),\n",
    "    text=[f'Sigma: {s}<br>Train data: {t}<br>Epochs: {e}<br>Loss: {l:.4f}'\n",
    "          for s, t, e, l in zip(sigma, n_train, n_epochs, loss)],\n",
    "    hoverinfo='text'\n",
    ")\n",
    "\n",
    "# Create the layout\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot of Loss with Different Parameters',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=f'sigma', titlefont=dict(size=12)),\n",
    "        yaxis=dict(title='train data', titlefont=dict(size=12)),\n",
    "        zaxis=dict(title='epochs', titlefont=dict(size=12))\n",
    "    ),\n",
    "    width=900,  # Increase the width of the plot\n",
    "    height=700,  # Increase the height of the plot\n",
    ")\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
