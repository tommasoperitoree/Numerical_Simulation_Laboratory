{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tommaso Peritore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "#from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "import itertools\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook our task will be to perform machine learning regression on noisy data with a Neural Network (NN).\n",
    "\n",
    "We will explore how the ability to fit depends on the structure of the NN. The goal is also to build intuition about why prediction is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Prediction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider a probabilistic process that gives rise to labeled data $(x,y)$. The data is generated by drawing samples from the equation\n",
    "\n",
    "$$\n",
    "    y_i= f(x_i) + \\eta_i,\n",
    "$$\n",
    "\n",
    "where $f(x_i)$ is some fixed, but (possibly unknown) function, and $\\eta_i$ is a Gaussian, uncorrelate noise variable such that\n",
    "\n",
    "$$\n",
    "\\langle \\eta_i \\rangle=0 \\\\\n",
    "\\langle \\eta_i \\eta_j \\rangle = \\delta_{ij} \\sigma\n",
    "$$\n",
    "\n",
    "We will refer to the $f(x_i)$ as the **true features** used to generate the data. \n",
    "\n",
    "To make predictions, we will consider a NN that depends on its parameters, weights and biases. The functions that the NN can model respresent the **model class** that we are using to try to model the data and make predictions.\n",
    "\n",
    "To learn the parameters of the NN, we will train our models on a **training data set** and then test the effectiveness of the NN on a *different* dataset, the **validation data set**. The reason we must divide our data into a training and test dataset is that the point of machine learning is to make accurate predictions about new data we have not seen.\n",
    "\n",
    "To measure our ability to predict, we will learn our parameters by fitting our training dataset and then making predictions on our test data set. One common measure of predictive  performance of our algorithm is to compare the predictions,$\\{y_j^\\mathrm{pred}\\}$, to the true values $\\{y_j\\}$. A commonly employed measure for this is the sum of the mean square-error (MSE) on the test set:\n",
    "$$\n",
    "MSE= \\frac{1}{N_\\mathrm{test}}\\sum_{j=1}^{N_\\mathrm{test}} (y_j^\\mathrm{pred}-y_j)^2\n",
    "$$\n",
    "\n",
    "We will try to get a qualitative picture by examining plots on validation and training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We start by considering the very simple case:\n",
    "$$\n",
    "f(x)=2x+1\n",
    "$$\n",
    "\n",
    "Let's start defining the parameters of an ideal linear function which we are going to predict through a neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target parameters of f(x) = m*x + b\n",
    "m = 2 # slope\n",
    "b = 1 # intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a set of input data which will slightly deviate from our ideal behaviour using a random noise (that actually is set to zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training inputs\n",
    "np.random.seed(0)\n",
    "x_train = np.random.uniform(-1, 1, 500)\n",
    "x_valid = np.random.uniform(-1, 1, 50)\n",
    "x_valid.sort()\n",
    "y_target = m * x_valid + b # ideal (target) linear function\n",
    "\n",
    "sigma = 1 # noise standard deviation, for the moment it is absent\n",
    "y_train = np.random.normal(m * x_train + b, sigma) # actual measures from which we want to guess regression parameters\n",
    "y_valid = np.random.normal(m * x_valid + b, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation and target dataset\n",
    "plt.plot(x_valid, y_target, label='target')\n",
    "plt.scatter(x_valid, y_valid, color='r', label='validation data')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember how a single node of a neural network works, you can easily spot that **just a single neuron can make the job**. So let's start using a simple Sequential model with just one layer on one neuron only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose the NN model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(1, input_shape=(1,)))\n",
    "\n",
    "# compile the model choosing optimizer, loss and metrics objects\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of our composed model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to train our model, that is we feed the neuron with the set of training pair x, y_train from which the optimizer will find the best weights to minimize the Mean Square Error loss function (out linear regression function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using training dataset\n",
    "# over 10 epochs of 32 batch size each\n",
    "# report training progress against validation data\n",
    "history = model.fit(x=x_train, y=y_train, \n",
    "          batch_size=32, epochs=30,\n",
    "          shuffle=True, # a good idea is to shuffle input before at each epoch\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at weights and biases we can see if the linear fit was successfull: $w_1$ represents the angular coefficient, $b$ the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return weights and biases\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_valid, y_valid, batch_size=32, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with the exact curve\n",
    "score = model.evaluate(x_valid, y_target, batch_size=32, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into training history\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predicted = np.random.uniform(-1, 1, 100)\n",
    "y_predicted = model.predict(x_predicted)\n",
    "plt.scatter(x_predicted, y_predicted, color='r')\n",
    "plt.plot(x_valid, y_target)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1\n",
    "\n",
    "In order to make practice with NN, explore how does the previous linear regression depend on the number of epochs, $N_{\\mathrm{epochs}}$, the number of data points $N_{\\mathrm{train}}$ and on the noise $\\sigma$. Try to improve the previous result operating on these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to explore how the linear regression depends on the number of epochs, the number of data points and the noise $\\sigma$. We are interested in seeing how these parameters affect the ability of the NN to fit the data.\n",
    "\n",
    "To explore the effect of all parameters we will define a set of values for each and then loop over all possible combinations of these values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma =  [0.1, 0.2, 0.5, 1]\n",
      "N_epochs =  [10, 15, 30, 50]\n",
      "N_train =  [500, 1000, 1500, 2000]\n"
     ]
    }
   ],
   "source": [
    "# Parameters to vary\n",
    "_sigma = [0.1, 0.2, 0.5, 1] # <<< noise\n",
    "_n_epochs = [10, 15, 30, 50] # <<< epochs\n",
    "_n_train = [500, 1000, 1500, 2000] # <<< train\n",
    "\n",
    "N_valid = 50 # <<< test\n",
    "\n",
    "# target parameters of f(x) = m*x + q\n",
    "m = 2 # slope\n",
    "q = 1 # intersect\n",
    "\n",
    "print('Sigma = ', _sigma)\n",
    "print('N_epochs = ', _n_epochs)\n",
    "print('N_train = ', _n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters were chosen with these criteria in mind:\n",
    "- The values of sigma were chosen to span from very low noise to very high noise so as to explore the ability of the NN model to fit the data in the presence of noise.\n",
    "- The number of epochs was chosen to span from below to above the value given in the original code to a lot more epochs, to see if $30$ epochs was already enough to saturate the training or if more epochs would improve the fit, and if less epochs would be enough to fit the data.\n",
    "- Finally, the number of training data was varied significantly to see if the model would perform better after having been trained on more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I am going to define a function to prepare the data, define the model, compile it and finally train it. This function will be used to fill a `loss` array with the values of the loss function for each combination of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for the NN model\n",
    "def run_model (sigma, n_epochs, train, valid):\n",
    "\t# generate training inputs\n",
    "\tnp.random.seed(0)\n",
    "\tx_train = np.random.uniform(-1, 1, train)\n",
    "\tx_valid = np.random.uniform(-1, 1, valid)\n",
    "\tx_valid.sort()\n",
    "\t# y_target = m * x_valid + q # ideal (target) linear function\n",
    "\n",
    "\t# actual measures from which we want to guess regression parameters\n",
    "\ty_train = np.random.normal(m * x_train + q, sigma) \n",
    "\ty_valid = np.random.normal(m * x_valid + q, sigma)\n",
    "\n",
    "\t# compose the NN model\n",
    "\tmodel = tf.keras.Sequential()\n",
    "\tmodel.add(Dense(1, input_shape = (1,)))\n",
    "\n",
    "\t# compile the model choosing optimizer, loss and metrics objects\n",
    "\tmodel.compile(optimizer = 'sgd', loss = 'mse', metrics = ['mse'])\n",
    "\n",
    "\t# train the model\n",
    "\tmodel.fit(x = x_train, y = y_train, batch_size = 32, epochs = n_epochs,\n",
    "                    shuffle = True, validation_data = (x_valid, y_valid))\n",
    "\tscore = model.evaluate(x_valid, y_valid, batch_size = 32, verbose = 0)\n",
    "\t\n",
    "\treturn score[0]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9663 - mse: 0.9663 - val_loss: 0.7162 - val_mse: 0.7162\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5750 - mse: 0.5750 - val_loss: 0.4390 - val_mse: 0.4390\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3578 - mse: 0.3578 - val_loss: 0.2823 - val_mse: 0.2823\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2339 - mse: 0.2339 - val_loss: 0.1895 - val_mse: 0.1895\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1599 - mse: 0.1599 - val_loss: 0.1335 - val_mse: 0.1335\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1149 - mse: 0.1149 - val_loss: 0.0985 - val_mse: 0.0985\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0593 - val_mse: 0.0593\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7965 - mse: 0.7965 - val_loss: 0.4362 - val_mse: 0.4362\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.3059 - mse: 0.3059 - val_loss: 0.1942 - val_mse: 0.1942\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1432 - mse: 0.1432 - val_loss: 0.1049 - val_mse: 0.1049\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0792 - mse: 0.0792 - val_loss: 0.0670 - val_mse: 0.0670\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6672 - mse: 0.6672 - val_loss: 0.3655 - val_mse: 0.3655\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 683us/step - loss: 0.1821 - mse: 0.1821 - val_loss: 0.1220 - val_mse: 0.1220\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.0739 - mse: 0.0739 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 615us/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 646us/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 643us/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 617us/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 625us/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5444 - mse: 0.5444 - val_loss: 0.1571 - val_mse: 0.1571\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 565us/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.0520 - val_mse: 0.0520\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 534us/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 528us/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 933us/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 555us/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 543us/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 540us/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1204 - mse: 4.1204 - val_loss: 3.1783 - val_mse: 3.1783\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1190 - mse: 3.1190 - val_loss: 2.4439 - val_mse: 2.4439\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.4070 - mse: 2.4070 - val_loss: 1.9095 - val_mse: 1.9095\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.8840 - mse: 1.8840 - val_loss: 1.5122 - val_mse: 1.5122\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4919 - mse: 1.4919 - val_loss: 1.2037 - val_mse: 1.2037\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1874 - mse: 1.1874 - val_loss: 0.9624 - val_mse: 0.9624\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9489 - mse: 0.9489 - val_loss: 0.7708 - val_mse: 0.7708\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7597 - mse: 0.7597 - val_loss: 0.6196 - val_mse: 0.6196\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6109 - mse: 0.6109 - val_loss: 0.4979 - val_mse: 0.4979\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4910 - mse: 0.4910 - val_loss: 0.4010 - val_mse: 0.4010\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3958 - mse: 0.3958 - val_loss: 0.3239 - val_mse: 0.3239\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3200 - mse: 0.3200 - val_loss: 0.2622 - val_mse: 0.2622\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2593 - mse: 0.2593 - val_loss: 0.2120 - val_mse: 0.2120\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2100 - mse: 0.2100 - val_loss: 0.1722 - val_mse: 0.1722\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1708 - mse: 0.1708 - val_loss: 0.1402 - val_mse: 0.1402\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7312 - mse: 0.7312 - val_loss: 0.3810 - val_mse: 0.3810\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.2630 - mse: 0.2630 - val_loss: 0.1571 - val_mse: 0.1571\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.1152 - mse: 0.1152 - val_loss: 0.0817 - val_mse: 0.0817\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6789 - mse: 1.6789 - val_loss: 1.1449 - val_mse: 1.1449\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 646us/step - loss: 0.7057 - mse: 0.7057 - val_loss: 0.4982 - val_mse: 0.4982\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 612us/step - loss: 0.3458 - mse: 0.3458 - val_loss: 0.2434 - val_mse: 0.2434\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 616us/step - loss: 0.1805 - mse: 0.1805 - val_loss: 0.1277 - val_mse: 0.1277\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.0978 - mse: 0.0978 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 605us/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 608us/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 636us/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 843us/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 651us/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 626us/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.6721 - mse: 1.6721 - val_loss: 0.7734 - val_mse: 0.7734\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 553us/step - loss: 0.5682 - mse: 0.5682 - val_loss: 0.3231 - val_mse: 0.3231\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.2315 - mse: 0.2315 - val_loss: 0.1435 - val_mse: 0.1435\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 529us/step - loss: 0.1013 - mse: 0.1013 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 545us/step - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 577us/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 506us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1448 - mse: 4.1448 - val_loss: 3.2035 - val_mse: 3.2035\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1435 - mse: 3.1435 - val_loss: 2.4655 - val_mse: 2.4655\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.4277 - mse: 2.4277 - val_loss: 1.9300 - val_mse: 1.9300\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9029 - mse: 1.9029 - val_loss: 1.5234 - val_mse: 1.5234\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5032 - mse: 1.5032 - val_loss: 1.2112 - val_mse: 1.2112\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1945 - mse: 1.1945 - val_loss: 0.9683 - val_mse: 0.9683\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9549 - mse: 0.9549 - val_loss: 0.7776 - val_mse: 0.7776\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7665 - mse: 0.7665 - val_loss: 0.6233 - val_mse: 0.6233\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6144 - mse: 0.6144 - val_loss: 0.5014 - val_mse: 0.5014\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4947 - mse: 0.4947 - val_loss: 0.4040 - val_mse: 0.4040\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3988 - mse: 0.3988 - val_loss: 0.3265 - val_mse: 0.3265\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3226 - mse: 0.3226 - val_loss: 0.2636 - val_mse: 0.2636\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2608 - mse: 0.2608 - val_loss: 0.2138 - val_mse: 0.2138\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2119 - mse: 0.2119 - val_loss: 0.1735 - val_mse: 0.1735\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1722 - mse: 0.1722 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1403 - mse: 0.1403 - val_loss: 0.1152 - val_mse: 0.1152\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1147 - mse: 0.1147 - val_loss: 0.0945 - val_mse: 0.0945\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.0777 - val_mse: 0.0777\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0775 - mse: 0.0775 - val_loss: 0.0644 - val_mse: 0.0644\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.3798 - mse: 2.3798 - val_loss: 1.7723 - val_mse: 1.7723\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 789us/step - loss: 1.3469 - mse: 1.3469 - val_loss: 1.0736 - val_mse: 1.0736\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.8192 - mse: 0.8192 - val_loss: 0.6859 - val_mse: 0.6859\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.5199 - mse: 0.5199 - val_loss: 0.4474 - val_mse: 0.4474\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3360 - mse: 0.3360 - val_loss: 0.2955 - val_mse: 0.2955\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.2194 - mse: 0.2194 - val_loss: 0.1976 - val_mse: 0.1976\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.1451 - mse: 0.1451 - val_loss: 0.1340 - val_mse: 0.1340\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0975 - mse: 0.0975 - val_loss: 0.0920 - val_mse: 0.0920\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0644 - val_mse: 0.0644\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.5051 - mse: 3.5051 - val_loss: 2.4512 - val_mse: 2.4512\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 646us/step - loss: 1.6567 - mse: 1.6567 - val_loss: 1.1534 - val_mse: 1.1534\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.8402 - mse: 0.8402 - val_loss: 0.5762 - val_mse: 0.5762\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 612us/step - loss: 0.4373 - mse: 0.4373 - val_loss: 0.2984 - val_mse: 0.2984\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 614us/step - loss: 0.2312 - mse: 0.2312 - val_loss: 0.1593 - val_mse: 0.1593\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.1246 - mse: 0.1246 - val_loss: 0.0879 - val_mse: 0.0879\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 622us/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 616us/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 618us/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 602us/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 599us/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 592us/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 611us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 619us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 641us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 613us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 612us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 628us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 579us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 623us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 616us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 602us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 602us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.5484 - mse: 3.5484 - val_loss: 1.8417 - val_mse: 1.8417\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 562us/step - loss: 1.3454 - mse: 1.3454 - val_loss: 0.7765 - val_mse: 0.7765\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 536us/step - loss: 0.5530 - mse: 0.5530 - val_loss: 0.3345 - val_mse: 0.3345\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.2340 - mse: 0.2340 - val_loss: 0.1467 - val_mse: 0.1467\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.1026 - mse: 0.1026 - val_loss: 0.0678 - val_mse: 0.0678\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 511us/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 509us/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 504us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 520us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 521us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 509us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 521us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 504us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 506us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 500us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3875 - mse: 1.3875 - val_loss: 1.0286 - val_mse: 1.0286\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9168 - mse: 0.9168 - val_loss: 0.6985 - val_mse: 0.6985\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6352 - mse: 0.6352 - val_loss: 0.4918 - val_mse: 0.4918\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4551 - mse: 0.4551 - val_loss: 0.3618 - val_mse: 0.3618\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3393 - mse: 0.3393 - val_loss: 0.2744 - val_mse: 0.2744\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2598 - mse: 0.2598 - val_loss: 0.2123 - val_mse: 0.2123\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2027 - mse: 0.2027 - val_loss: 0.1670 - val_mse: 0.1670\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1605 - mse: 0.1605 - val_loss: 0.1334 - val_mse: 0.1334\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 0.1077 - val_mse: 0.1077\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1044 - mse: 0.1044 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0717 - val_mse: 0.0717\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0700 - mse: 0.0700 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.6332 - mse: 1.6332 - val_loss: 1.1400 - val_mse: 1.1400\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.8553 - mse: 0.8553 - val_loss: 0.6623 - val_mse: 0.6623\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.5021 - mse: 0.5021 - val_loss: 0.4103 - val_mse: 0.4103\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.3096 - mse: 0.3096 - val_loss: 0.2675 - val_mse: 0.2675\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1997 - mse: 0.1997 - val_loss: 0.1773 - val_mse: 0.1773\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1310 - mse: 0.1310 - val_loss: 0.1193 - val_mse: 0.1193\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0873 - mse: 0.0873 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.9724 - mse: 1.9724 - val_loss: 1.3605 - val_mse: 1.3605\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 644us/step - loss: 0.8592 - mse: 0.8592 - val_loss: 0.6045 - val_mse: 0.6045\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4256 - mse: 0.4256 - val_loss: 0.2981 - val_mse: 0.2981\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 649us/step - loss: 0.2219 - mse: 0.2219 - val_loss: 0.1557 - val_mse: 0.1557\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 839us/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 619us/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 618us/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 610us/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 599us/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 612us/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 595us/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 580us/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 599us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 615us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 598us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 597us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 611us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 591us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 593us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 590us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 587us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 577us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 593us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 595us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 591us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 593us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 598us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 591us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 600us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 615us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 605us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 593us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 593us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2666 - mse: 1.2666 - val_loss: 0.5465 - val_mse: 0.5465\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 537us/step - loss: 0.4010 - mse: 0.4010 - val_loss: 0.2235 - val_mse: 0.2235\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.1615 - mse: 0.1615 - val_loss: 0.1006 - val_mse: 0.1006\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 509us/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 510us/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 522us/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 529us/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 533us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 535us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 517us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 520us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 521us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 520us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 492us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 507us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 515us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 536us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 534us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 533us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 577us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 510us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 533us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4462 - mse: 4.4462 - val_loss: 3.4947 - val_mse: 3.4947\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.3938 - mse: 3.3938 - val_loss: 2.6984 - val_mse: 2.6984\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.6327 - mse: 2.6327 - val_loss: 2.1195 - val_mse: 2.1195\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0735 - mse: 2.0735 - val_loss: 1.6799 - val_mse: 1.6799\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.6472 - mse: 1.6472 - val_loss: 1.3440 - val_mse: 1.3440\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3188 - mse: 1.3188 - val_loss: 1.0784 - val_mse: 1.0784\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0601 - mse: 1.0601 - val_loss: 0.8674 - val_mse: 0.8674\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8540 - mse: 0.8540 - val_loss: 0.7031 - val_mse: 0.7031\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6934 - mse: 0.6934 - val_loss: 0.5710 - val_mse: 0.5710\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5640 - mse: 0.5640 - val_loss: 0.4653 - val_mse: 0.4653\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.2245 - mse: 1.2245 - val_loss: 0.8020 - val_mse: 0.8020\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.5946 - mse: 0.5946 - val_loss: 0.4491 - val_mse: 0.4491\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.3384 - mse: 0.3384 - val_loss: 0.2891 - val_mse: 0.2891\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.2176 - mse: 0.2176 - val_loss: 0.1989 - val_mse: 0.1989\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 725us/step - loss: 0.1493 - mse: 0.1493 - val_loss: 0.1446 - val_mse: 0.1446\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.1090 - mse: 0.1090 - val_loss: 0.1091 - val_mse: 0.1091\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0700 - val_mse: 0.0700\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0591 - val_mse: 0.0591\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.6896 - mse: 1.6896 - val_loss: 1.1651 - val_mse: 1.1651\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 621us/step - loss: 0.7266 - mse: 0.7266 - val_loss: 0.5269 - val_mse: 0.5269\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.3696 - mse: 0.3696 - val_loss: 0.2741 - val_mse: 0.2741\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 574us/step - loss: 0.2064 - mse: 0.2064 - val_loss: 0.1586 - val_mse: 0.1586\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 575us/step - loss: 0.1249 - mse: 0.1249 - val_loss: 0.1016 - val_mse: 0.1016\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 592us/step - loss: 0.0830 - mse: 0.0830 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 579us/step - loss: 0.0613 - mse: 0.0613 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 575us/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 579us/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 586us/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.5687 - mse: 1.5687 - val_loss: 0.7393 - val_mse: 0.7393\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 546us/step - loss: 0.5427 - mse: 0.5427 - val_loss: 0.3257 - val_mse: 0.3257\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 530us/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.1618 - val_mse: 0.1618\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1201 - mse: 0.1201 - val_loss: 0.0920 - val_mse: 0.0920\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0621 - val_mse: 0.0621\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 522us/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0405 - val_mse: 0.0405\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8609 - mse: 0.8609 - val_loss: 0.7164 - val_mse: 0.7164\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4978 - mse: 0.4978 - val_loss: 0.4394 - val_mse: 0.4394\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3026 - mse: 0.3026 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1962 - mse: 0.1962 - val_loss: 0.1958 - val_mse: 0.1958\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1368 - mse: 0.1368 - val_loss: 0.1432 - val_mse: 0.1432\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1028 - mse: 0.1028 - val_loss: 0.1115 - val_mse: 0.1115\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0827 - mse: 0.0827 - val_loss: 0.0914 - val_mse: 0.0914\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0777 - val_mse: 0.0777\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.0623 - val_mse: 0.0623\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0576 - val_mse: 0.0576\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0543 - val_mse: 0.0543\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0499 - val_mse: 0.0499\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.1267 - mse: 4.1267 - val_loss: 3.2676 - val_mse: 3.2676\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 810us/step - loss: 2.4859 - mse: 2.4859 - val_loss: 2.0810 - val_mse: 2.0810\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 758us/step - loss: 1.5725 - mse: 1.5725 - val_loss: 1.3648 - val_mse: 1.3648\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 750us/step - loss: 1.0205 - mse: 1.0205 - val_loss: 0.9073 - val_mse: 0.9073\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.6710 - mse: 0.6710 - val_loss: 0.6106 - val_mse: 0.6106\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.4471 - mse: 0.4471 - val_loss: 0.4152 - val_mse: 0.4152\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.3021 - mse: 0.3021 - val_loss: 0.2871 - val_mse: 0.2871\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.2086 - mse: 0.2086 - val_loss: 0.2037 - val_mse: 0.2037\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.1481 - mse: 0.1481 - val_loss: 0.1478 - val_mse: 0.1478\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.1090 - mse: 0.1090 - val_loss: 0.1112 - val_mse: 0.1112\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0840 - mse: 0.0840 - val_loss: 0.0866 - val_mse: 0.0866\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0705 - val_mse: 0.0705\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.4931 - mse: 2.4931 - val_loss: 1.7513 - val_mse: 1.7513\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 648us/step - loss: 1.1412 - mse: 1.1412 - val_loss: 0.8137 - val_mse: 0.8137\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 587us/step - loss: 0.5856 - mse: 0.5856 - val_loss: 0.4229 - val_mse: 0.4229\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.3188 - mse: 0.3188 - val_loss: 0.2343 - val_mse: 0.2343\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 610us/step - loss: 0.1831 - mse: 0.1831 - val_loss: 0.1413 - val_mse: 0.1413\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 606us/step - loss: 0.1132 - mse: 0.1132 - val_loss: 0.0932 - val_mse: 0.0932\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.0770 - mse: 0.0770 - val_loss: 0.0681 - val_mse: 0.0681\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 586us/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 611us/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 599us/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0437 - val_mse: 0.0437\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0403 - val_mse: 0.0403\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 624us/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 602us/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5781 - mse: 0.5781 - val_loss: 0.1923 - val_mse: 0.1923\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 543us/step - loss: 0.1360 - mse: 0.1360 - val_loss: 0.0849 - val_mse: 0.0849\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 528us/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0471 - val_mse: 0.0471\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 534us/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 534us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 505us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0918 - mse: 4.0918 - val_loss: 3.2150 - val_mse: 3.2150\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.1105 - mse: 3.1105 - val_loss: 2.4755 - val_mse: 2.4755\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.4070 - mse: 2.4070 - val_loss: 1.9341 - val_mse: 1.9341\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.8885 - mse: 1.8885 - val_loss: 1.5311 - val_mse: 1.5311\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4997 - mse: 1.4997 - val_loss: 1.2217 - val_mse: 1.2217\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1984 - mse: 1.1984 - val_loss: 0.9810 - val_mse: 0.9810\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9633 - mse: 0.9633 - val_loss: 0.7918 - val_mse: 0.7918\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7791 - mse: 0.7791 - val_loss: 0.6416 - val_mse: 0.6416\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6321 - mse: 0.6321 - val_loss: 0.5218 - val_mse: 0.5218\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5152 - mse: 0.5152 - val_loss: 0.4258 - val_mse: 0.4258\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4210 - mse: 0.4210 - val_loss: 0.3491 - val_mse: 0.3491\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3460 - mse: 0.3460 - val_loss: 0.2883 - val_mse: 0.2883\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2860 - mse: 0.2860 - val_loss: 0.2383 - val_mse: 0.2383\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2368 - mse: 0.2368 - val_loss: 0.1991 - val_mse: 0.1991\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1979 - mse: 0.1979 - val_loss: 0.1679 - val_mse: 0.1679\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1669 - mse: 0.1669 - val_loss: 0.1428 - val_mse: 0.1428\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1419 - mse: 0.1419 - val_loss: 0.1228 - val_mse: 0.1228\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1215 - mse: 0.1215 - val_loss: 0.1066 - val_mse: 0.1066\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1053 - mse: 0.1053 - val_loss: 0.0938 - val_mse: 0.0938\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0734 - mse: 0.0734 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0635 - val_mse: 0.0635\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0561 - val_mse: 0.0561\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0537 - val_mse: 0.0537\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0936 - mse: 1.0936 - val_loss: 0.6932 - val_mse: 0.6932\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.5116 - mse: 0.5116 - val_loss: 0.3752 - val_mse: 0.3752\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.2836 - mse: 0.2836 - val_loss: 0.2365 - val_mse: 0.2365\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.1795 - mse: 0.1795 - val_loss: 0.1654 - val_mse: 0.1654\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.1257 - mse: 0.1257 - val_loss: 0.1216 - val_mse: 0.1216\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.0936 - val_mse: 0.0936\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.0749 - val_mse: 0.0749\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0605 - mse: 0.0605 - val_loss: 0.0628 - val_mse: 0.0628\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0543 - val_mse: 0.0543\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0442 - val_mse: 0.0442\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0414 - val_mse: 0.0414\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 725us/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.8726 - mse: 1.8726 - val_loss: 1.2964 - val_mse: 1.2964\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 708us/step - loss: 0.8208 - mse: 0.8208 - val_loss: 0.5909 - val_mse: 0.5909\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 622us/step - loss: 0.4188 - mse: 0.4188 - val_loss: 0.3065 - val_mse: 0.3065\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.2323 - mse: 0.2323 - val_loss: 0.1760 - val_mse: 0.1760\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.1385 - mse: 0.1385 - val_loss: 0.1109 - val_mse: 0.1109\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 602us/step - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.0650 - mse: 0.0650 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 600us/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0502 - val_mse: 0.0502\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0451 - val_mse: 0.0451\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 597us/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 619us/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 588us/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 595us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 606us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 591us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 624us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 603us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 606us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 613us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 593us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 614us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 614us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 615us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 611us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 593us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5370 - mse: 0.5370 - val_loss: 0.1726 - val_mse: 0.1726\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 536us/step - loss: 0.1192 - mse: 0.1192 - val_loss: 0.0746 - val_mse: 0.0746\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 503us/step - loss: 0.0618 - mse: 0.0618 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 510us/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.0452 - val_mse: 0.0452\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 520us/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 488us/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 500us/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 497us/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 498us/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 511us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 505us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 496us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 504us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 507us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 495us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 499us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 511us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 501us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 507us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 499us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 499us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 494us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 509us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 511us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 488us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 499us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4095 - mse: 2.4095 - val_loss: 1.8858 - val_mse: 1.8858\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.7541 - mse: 1.7541 - val_loss: 1.4040 - val_mse: 1.4040\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3223 - mse: 1.3223 - val_loss: 1.0709 - val_mse: 1.0709\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0174 - mse: 1.0174 - val_loss: 0.8330 - val_mse: 0.8330\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7975 - mse: 0.7975 - val_loss: 0.6580 - val_mse: 0.6580\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6335 - mse: 0.6335 - val_loss: 0.5270 - val_mse: 0.5270\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5097 - mse: 0.5097 - val_loss: 0.4259 - val_mse: 0.4259\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4138 - mse: 0.4138 - val_loss: 0.3467 - val_mse: 0.3467\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3382 - mse: 0.3382 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2787 - mse: 0.2787 - val_loss: 0.2361 - val_mse: 0.2361\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 0.1971 - val_mse: 0.1971\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1935 - mse: 0.1935 - val_loss: 0.1655 - val_mse: 0.1655\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1627 - mse: 0.1627 - val_loss: 0.1409 - val_mse: 0.1409\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1386 - mse: 0.1386 - val_loss: 0.1213 - val_mse: 0.1213\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1192 - mse: 0.1192 - val_loss: 0.1055 - val_mse: 0.1055\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1035 - mse: 0.1035 - val_loss: 0.0927 - val_mse: 0.0927\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 0.0827 - val_mse: 0.0827\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0745 - val_mse: 0.0745\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0682 - val_mse: 0.0682\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0633 - val_mse: 0.0633\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0592 - val_mse: 0.0592\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0563 - val_mse: 0.0563\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0536 - val_mse: 0.0536\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0516 - val_mse: 0.0516\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0454 - val_mse: 0.0454\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0447 - val_mse: 0.0447\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0444 - val_mse: 0.0444\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.7216 - mse: 2.7216 - val_loss: 2.0906 - val_mse: 2.0906\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 791us/step - loss: 1.5804 - mse: 1.5804 - val_loss: 1.2921 - val_mse: 1.2921\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.9731 - mse: 0.9731 - val_loss: 0.8427 - val_mse: 0.8427\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.6279 - mse: 0.6279 - val_loss: 0.5648 - val_mse: 0.5648\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.4158 - mse: 0.4158 - val_loss: 0.3870 - val_mse: 0.3870\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.2824 - mse: 0.2824 - val_loss: 0.2704 - val_mse: 0.2704\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1964 - mse: 0.1964 - val_loss: 0.1927 - val_mse: 0.1927\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.1403 - mse: 0.1403 - val_loss: 0.1408 - val_mse: 0.1408\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1043 - mse: 0.1043 - val_loss: 0.1066 - val_mse: 0.1066\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0834 - val_mse: 0.0834\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0655 - mse: 0.0655 - val_loss: 0.0683 - val_mse: 0.0683\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0580 - val_mse: 0.0580\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 706us/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.0399 - mse: 0.0399 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0350 - val_mse: 0.0350\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.7631 - mse: 3.7631 - val_loss: 2.6599 - val_mse: 2.6599\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 626us/step - loss: 1.8001 - mse: 1.8001 - val_loss: 1.2698 - val_mse: 1.2698\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 602us/step - loss: 0.9275 - mse: 0.9275 - val_loss: 0.6536 - val_mse: 0.6536\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 606us/step - loss: 0.4962 - mse: 0.4962 - val_loss: 0.3541 - val_mse: 0.3541\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.2754 - mse: 0.2754 - val_loss: 0.2027 - val_mse: 0.2027\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 580us/step - loss: 0.1613 - mse: 0.1613 - val_loss: 0.1260 - val_mse: 0.1260\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 617us/step - loss: 0.1019 - mse: 0.1019 - val_loss: 0.0852 - val_mse: 0.0852\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0711 - mse: 0.0711 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0464 - val_mse: 0.0464\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 584us/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 597us/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 592us/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0401 - val_mse: 0.0401\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 596us/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 600us/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 571us/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 584us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 608us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 599us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 580us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 595us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 622us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 620us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 592us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 588us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 620us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 691us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 644us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 928us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 627us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 585us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 589us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 595us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 686us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 888us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 629us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 607us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 605us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 674us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 731us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 608us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 599us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 606us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1363 - mse: 3.1363 - val_loss: 1.6325 - val_mse: 1.6325\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 602us/step - loss: 1.1900 - mse: 1.1900 - val_loss: 0.7083 - val_mse: 0.7083\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 536us/step - loss: 0.5054 - mse: 0.5054 - val_loss: 0.3243 - val_mse: 0.3243\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2315 - mse: 0.2315 - val_loss: 0.1612 - val_mse: 0.1612\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 520us/step - loss: 0.1185 - mse: 0.1185 - val_loss: 0.0913 - val_mse: 0.0913\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.0716 - mse: 0.0716 - val_loss: 0.0614 - val_mse: 0.0614\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 576us/step - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0429 - val_mse: 0.0429\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0404 - val_mse: 0.0404\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0393 - val_mse: 0.0393\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 510us/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 517us/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 505us/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 641us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 512us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 522us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 504us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 515us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 713us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 898us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 551us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 637us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 513us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 506us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 515us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 521us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 515us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 509us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 509us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 517us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 518us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 517us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 522us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 508us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 517us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 510us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 553us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 582us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0253 - mse: 1.0253 - val_loss: 1.0983 - val_mse: 1.0983\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6847 - mse: 0.6847 - val_loss: 0.7890 - val_mse: 0.7890\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5022 - mse: 0.5022 - val_loss: 0.6067 - val_mse: 0.6067\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4018 - mse: 0.4018 - val_loss: 0.4939 - val_mse: 0.4939\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3430 - mse: 0.3430 - val_loss: 0.4223 - val_mse: 0.4223\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3092 - mse: 0.3092 - val_loss: 0.3764 - val_mse: 0.3764\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2891 - mse: 0.2891 - val_loss: 0.3471 - val_mse: 0.3471\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2766 - mse: 0.2766 - val_loss: 0.3274 - val_mse: 0.3274\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2682 - mse: 0.2682 - val_loss: 0.3128 - val_mse: 0.3128\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2626 - mse: 0.2626 - val_loss: 0.3022 - val_mse: 0.3022\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9543 - mse: 0.9543 - val_loss: 0.5486 - val_mse: 0.5486\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.4846 - mse: 0.4846 - val_loss: 0.3489 - val_mse: 0.3489\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.3349 - mse: 0.3349 - val_loss: 0.2878 - val_mse: 0.2878\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.2842 - mse: 0.2842 - val_loss: 0.2637 - val_mse: 0.2637\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.2632 - mse: 0.2632 - val_loss: 0.2493 - val_mse: 0.2493\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.2524 - mse: 0.2524 - val_loss: 0.2404 - val_mse: 0.2404\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.2460 - mse: 0.2460 - val_loss: 0.2337 - val_mse: 0.2337\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.2425 - mse: 0.2425 - val_loss: 0.2287 - val_mse: 0.2287\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2244 - val_mse: 0.2244\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.2388 - mse: 0.2388 - val_loss: 0.2213 - val_mse: 0.2213\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 2.9187 - mse: 2.9187 - val_loss: 2.1210 - val_mse: 2.1210\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 631us/step - loss: 1.4613 - mse: 1.4613 - val_loss: 1.1210 - val_mse: 1.1210\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 597us/step - loss: 0.8481 - mse: 0.8481 - val_loss: 0.6852 - val_mse: 0.6852\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 592us/step - loss: 0.5507 - mse: 0.5507 - val_loss: 0.4755 - val_mse: 0.4755\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 583us/step - loss: 0.3992 - mse: 0.3992 - val_loss: 0.3681 - val_mse: 0.3681\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 595us/step - loss: 0.3209 - mse: 0.3209 - val_loss: 0.3108 - val_mse: 0.3108\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 597us/step - loss: 0.2801 - mse: 0.2801 - val_loss: 0.2802 - val_mse: 0.2802\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 607us/step - loss: 0.2591 - mse: 0.2591 - val_loss: 0.2640 - val_mse: 0.2640\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 588us/step - loss: 0.2482 - mse: 0.2482 - val_loss: 0.2544 - val_mse: 0.2544\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2424 - mse: 0.2424 - val_loss: 0.2495 - val_mse: 0.2495\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.8197 - mse: 0.8197 - val_loss: 0.4326 - val_mse: 0.4326\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 537us/step - loss: 0.3572 - mse: 0.3572 - val_loss: 0.3059 - val_mse: 0.3059\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.2786 - mse: 0.2786 - val_loss: 0.2689 - val_mse: 0.2689\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 510us/step - loss: 0.2554 - mse: 0.2554 - val_loss: 0.2532 - val_mse: 0.2532\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 501us/step - loss: 0.2465 - mse: 0.2465 - val_loss: 0.2457 - val_mse: 0.2457\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 515us/step - loss: 0.2427 - mse: 0.2427 - val_loss: 0.2420 - val_mse: 0.2420\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.2400 - val_mse: 0.2400\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 517us/step - loss: 0.2405 - mse: 0.2405 - val_loss: 0.2390 - val_mse: 0.2390\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2385 - val_mse: 0.2385\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2382 - val_mse: 0.2382\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8122 - mse: 1.8122 - val_loss: 1.6551 - val_mse: 1.6551\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3243 - mse: 1.3243 - val_loss: 1.2413 - val_mse: 1.2413\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0166 - mse: 1.0166 - val_loss: 0.9767 - val_mse: 0.9767\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8170 - mse: 0.8170 - val_loss: 0.7936 - val_mse: 0.7936\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6778 - mse: 0.6778 - val_loss: 0.6643 - val_mse: 0.6643\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5784 - mse: 0.5784 - val_loss: 0.5699 - val_mse: 0.5699\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5056 - mse: 0.5056 - val_loss: 0.5034 - val_mse: 0.5034\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4507 - mse: 0.4507 - val_loss: 0.4511 - val_mse: 0.4511\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4081 - mse: 0.4081 - val_loss: 0.4125 - val_mse: 0.4125\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3752 - mse: 0.3752 - val_loss: 0.3827 - val_mse: 0.3827\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3491 - mse: 0.3491 - val_loss: 0.3582 - val_mse: 0.3582\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3281 - mse: 0.3281 - val_loss: 0.3393 - val_mse: 0.3393\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3117 - mse: 0.3117 - val_loss: 0.3246 - val_mse: 0.3246\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2985 - mse: 0.2985 - val_loss: 0.3136 - val_mse: 0.3136\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2882 - mse: 0.2882 - val_loss: 0.3058 - val_mse: 0.3058\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.3925 - mse: 3.3925 - val_loss: 2.7570 - val_mse: 2.7570\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.0729 - mse: 2.0729 - val_loss: 1.8314 - val_mse: 1.8314\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 766us/step - loss: 1.3675 - mse: 1.3675 - val_loss: 1.2787 - val_mse: 1.2787\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9498 - mse: 0.9498 - val_loss: 0.9271 - val_mse: 0.9271\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6935 - mse: 0.6935 - val_loss: 0.6958 - val_mse: 0.6958\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.5301 - mse: 0.5301 - val_loss: 0.5459 - val_mse: 0.5459\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.4271 - mse: 0.4271 - val_loss: 0.4436 - val_mse: 0.4436\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.3591 - mse: 0.3591 - val_loss: 0.3750 - val_mse: 0.3750\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.3164 - mse: 0.3164 - val_loss: 0.3269 - val_mse: 0.3269\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.2880 - mse: 0.2880 - val_loss: 0.2927 - val_mse: 0.2927\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.2698 - mse: 0.2698 - val_loss: 0.2698 - val_mse: 0.2698\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.2581 - mse: 0.2581 - val_loss: 0.2534 - val_mse: 0.2534\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.2502 - mse: 0.2502 - val_loss: 0.2422 - val_mse: 0.2422\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.2453 - mse: 0.2453 - val_loss: 0.2335 - val_mse: 0.2335\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2419 - mse: 0.2419 - val_loss: 0.2267 - val_mse: 0.2267\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.2337 - mse: 3.2337 - val_loss: 2.3561 - val_mse: 2.3561\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 629us/step - loss: 1.6254 - mse: 1.6254 - val_loss: 1.2372 - val_mse: 1.2372\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 613us/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.7467 - val_mse: 0.7467\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 663us/step - loss: 0.5951 - mse: 0.5951 - val_loss: 0.5064 - val_mse: 0.5064\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 617us/step - loss: 0.4224 - mse: 0.4224 - val_loss: 0.3845 - val_mse: 0.3845\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.3331 - mse: 0.3331 - val_loss: 0.3198 - val_mse: 0.3198\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 611us/step - loss: 0.2865 - mse: 0.2865 - val_loss: 0.2851 - val_mse: 0.2851\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 624us/step - loss: 0.2623 - mse: 0.2623 - val_loss: 0.2665 - val_mse: 0.2665\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 620us/step - loss: 0.2498 - mse: 0.2498 - val_loss: 0.2562 - val_mse: 0.2562\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2433 - mse: 0.2433 - val_loss: 0.2506 - val_mse: 0.2506\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 620us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2469 - val_mse: 0.2469\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 602us/step - loss: 0.2382 - mse: 0.2382 - val_loss: 0.2450 - val_mse: 0.2450\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 615us/step - loss: 0.2374 - mse: 0.2374 - val_loss: 0.2440 - val_mse: 0.2440\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.2368 - mse: 0.2368 - val_loss: 0.2432 - val_mse: 0.2432\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 594us/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2428 - val_mse: 0.2428\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7686 - mse: 0.7686 - val_loss: 0.4071 - val_mse: 0.4071\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 554us/step - loss: 0.3369 - mse: 0.3369 - val_loss: 0.2914 - val_mse: 0.2914\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.2698 - mse: 0.2698 - val_loss: 0.2621 - val_mse: 0.2621\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.2516 - mse: 0.2516 - val_loss: 0.2502 - val_mse: 0.2502\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2450 - mse: 0.2450 - val_loss: 0.2444 - val_mse: 0.2444\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 528us/step - loss: 0.2422 - mse: 0.2422 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.2410 - mse: 0.2410 - val_loss: 0.2397 - val_mse: 0.2397\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.2404 - mse: 0.2404 - val_loss: 0.2387 - val_mse: 0.2387\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 547us/step - loss: 0.2402 - mse: 0.2402 - val_loss: 0.2383 - val_mse: 0.2383\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2380 - val_mse: 0.2380\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 529us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 1s 4ms/step - loss: 1.4065 - mse: 1.4065 - val_loss: 1.3563 - val_mse: 1.3563\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9950 - mse: 0.9950 - val_loss: 1.0016 - val_mse: 1.0016\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7533 - mse: 0.7533 - val_loss: 0.7766 - val_mse: 0.7766\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6022 - mse: 0.6022 - val_loss: 0.6323 - val_mse: 0.6323\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5059 - mse: 0.5059 - val_loss: 0.5370 - val_mse: 0.5370\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4413 - mse: 0.4413 - val_loss: 0.4692 - val_mse: 0.4692\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3955 - mse: 0.3955 - val_loss: 0.4194 - val_mse: 0.4194\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3614 - mse: 0.3614 - val_loss: 0.3853 - val_mse: 0.3853\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3366 - mse: 0.3366 - val_loss: 0.3602 - val_mse: 0.3602\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3176 - mse: 0.3176 - val_loss: 0.3406 - val_mse: 0.3406\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3029 - mse: 0.3029 - val_loss: 0.3259 - val_mse: 0.3259\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2909 - mse: 0.2909 - val_loss: 0.3147 - val_mse: 0.3147\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2817 - mse: 0.2817 - val_loss: 0.3059 - val_mse: 0.3059\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2745 - mse: 0.2745 - val_loss: 0.2988 - val_mse: 0.2988\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2686 - mse: 0.2686 - val_loss: 0.2936 - val_mse: 0.2936\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2638 - mse: 0.2638 - val_loss: 0.2903 - val_mse: 0.2903\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2599 - mse: 0.2599 - val_loss: 0.2871 - val_mse: 0.2871\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2569 - mse: 0.2569 - val_loss: 0.2847 - val_mse: 0.2847\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2544 - mse: 0.2544 - val_loss: 0.2826 - val_mse: 0.2826\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2524 - mse: 0.2524 - val_loss: 0.2807 - val_mse: 0.2807\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2509 - mse: 0.2509 - val_loss: 0.2797 - val_mse: 0.2797\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2496 - mse: 0.2496 - val_loss: 0.2795 - val_mse: 0.2795\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2486 - mse: 0.2486 - val_loss: 0.2790 - val_mse: 0.2790\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2479 - mse: 0.2479 - val_loss: 0.2781 - val_mse: 0.2781\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2472 - mse: 0.2472 - val_loss: 0.2780 - val_mse: 0.2780\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2467 - mse: 0.2467 - val_loss: 0.2785 - val_mse: 0.2785\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2464 - mse: 0.2464 - val_loss: 0.2783 - val_mse: 0.2783\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2461 - mse: 0.2461 - val_loss: 0.2783 - val_mse: 0.2783\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2457 - mse: 0.2457 - val_loss: 0.2777 - val_mse: 0.2777\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2455 - mse: 0.2455 - val_loss: 0.2784 - val_mse: 0.2784\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7821 - mse: 3.7821 - val_loss: 3.0986 - val_mse: 3.0986\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 832us/step - loss: 2.3252 - mse: 2.3252 - val_loss: 2.0585 - val_mse: 2.0585\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.5321 - mse: 1.5321 - val_loss: 1.4369 - val_mse: 1.4369\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 806us/step - loss: 1.0629 - mse: 1.0629 - val_loss: 1.0381 - val_mse: 1.0381\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.7688 - mse: 0.7688 - val_loss: 0.7740 - val_mse: 0.7740\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.5813 - mse: 0.5813 - val_loss: 0.5976 - val_mse: 0.5976\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.4607 - mse: 0.4607 - val_loss: 0.4776 - val_mse: 0.4776\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.3813 - mse: 0.3813 - val_loss: 0.3946 - val_mse: 0.3946\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.3289 - mse: 0.3289 - val_loss: 0.3399 - val_mse: 0.3399\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.2966 - mse: 0.2966 - val_loss: 0.3028 - val_mse: 0.3028\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2755 - mse: 0.2755 - val_loss: 0.2767 - val_mse: 0.2767\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.2617 - mse: 0.2617 - val_loss: 0.2585 - val_mse: 0.2585\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.2529 - mse: 0.2529 - val_loss: 0.2460 - val_mse: 0.2460\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2470 - mse: 0.2470 - val_loss: 0.2371 - val_mse: 0.2371\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.2436 - mse: 0.2436 - val_loss: 0.2297 - val_mse: 0.2297\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.2408 - mse: 0.2408 - val_loss: 0.2253 - val_mse: 0.2253\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.2391 - mse: 0.2391 - val_loss: 0.2225 - val_mse: 0.2225\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.2382 - mse: 0.2382 - val_loss: 0.2193 - val_mse: 0.2193\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.2375 - mse: 0.2375 - val_loss: 0.2166 - val_mse: 0.2166\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.2370 - mse: 0.2370 - val_loss: 0.2138 - val_mse: 0.2138\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.2369 - mse: 0.2369 - val_loss: 0.2135 - val_mse: 0.2135\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.2139 - val_mse: 0.2139\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2142 - val_mse: 0.2142\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2132 - val_mse: 0.2132\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2120 - val_mse: 0.2120\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2115 - val_mse: 0.2115\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2105 - val_mse: 0.2105\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2099 - val_mse: 0.2099\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2106 - val_mse: 0.2106\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2115 - val_mse: 0.2115\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.0205 - mse: 1.0205 - val_loss: 0.6865 - val_mse: 0.6865\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 688us/step - loss: 0.4767 - mse: 0.4767 - val_loss: 0.4056 - val_mse: 0.4056\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 659us/step - loss: 0.3366 - mse: 0.3366 - val_loss: 0.3190 - val_mse: 0.3190\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2847 - mse: 0.2847 - val_loss: 0.2826 - val_mse: 0.2826\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2610 - mse: 0.2610 - val_loss: 0.2649 - val_mse: 0.2649\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2491 - mse: 0.2491 - val_loss: 0.2552 - val_mse: 0.2552\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 649us/step - loss: 0.2430 - mse: 0.2430 - val_loss: 0.2495 - val_mse: 0.2495\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 643us/step - loss: 0.2397 - mse: 0.2397 - val_loss: 0.2467 - val_mse: 0.2467\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 669us/step - loss: 0.2381 - mse: 0.2381 - val_loss: 0.2447 - val_mse: 0.2447\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 656us/step - loss: 0.2373 - mse: 0.2373 - val_loss: 0.2435 - val_mse: 0.2435\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 656us/step - loss: 0.2368 - mse: 0.2368 - val_loss: 0.2433 - val_mse: 0.2433\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 637us/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2427 - val_mse: 0.2427\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 650us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2427 - val_mse: 0.2427\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2425 - val_mse: 0.2425\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 698us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 635us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 667us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 631us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 647us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 670us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2420 - val_mse: 0.2420\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 663us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 637us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 643us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 0s 642us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 643us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 656us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 3.8939 - mse: 3.8939 - val_loss: 2.2145 - val_mse: 2.2145\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 565us/step - loss: 1.6243 - mse: 1.6243 - val_loss: 1.0863 - val_mse: 1.0863\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 555us/step - loss: 0.8050 - mse: 0.8050 - val_loss: 0.6062 - val_mse: 0.6062\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 552us/step - loss: 0.4734 - mse: 0.4734 - val_loss: 0.4013 - val_mse: 0.4013\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 552us/step - loss: 0.3370 - mse: 0.3370 - val_loss: 0.3112 - val_mse: 0.3112\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2800 - mse: 0.2800 - val_loss: 0.2714 - val_mse: 0.2714\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 566us/step - loss: 0.2567 - mse: 0.2567 - val_loss: 0.2543 - val_mse: 0.2543\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 549us/step - loss: 0.2470 - mse: 0.2470 - val_loss: 0.2460 - val_mse: 0.2460\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 554us/step - loss: 0.2428 - mse: 0.2428 - val_loss: 0.2420 - val_mse: 0.2420\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 555us/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.2400 - val_mse: 0.2400\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 561us/step - loss: 0.2405 - mse: 0.2405 - val_loss: 0.2390 - val_mse: 0.2390\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 551us/step - loss: 0.2403 - mse: 0.2403 - val_loss: 0.2385 - val_mse: 0.2385\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 562us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2382 - val_mse: 0.2382\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 554us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2381 - val_mse: 0.2381\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2380 - val_mse: 0.2380\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 564us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 560us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 559us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 558us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 563us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 547us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 544us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 529us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 554us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 540us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 538us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 546us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0280 - mse: 1.0280 - val_loss: 1.0980 - val_mse: 1.0980\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6850 - mse: 0.6850 - val_loss: 0.7872 - val_mse: 0.7872\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5019 - mse: 0.5019 - val_loss: 0.6049 - val_mse: 0.6049\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4009 - mse: 0.4009 - val_loss: 0.4916 - val_mse: 0.4916\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3428 - mse: 0.3428 - val_loss: 0.4225 - val_mse: 0.4225\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3097 - mse: 0.3097 - val_loss: 0.3768 - val_mse: 0.3768\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2894 - mse: 0.2894 - val_loss: 0.3459 - val_mse: 0.3459\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2763 - mse: 0.2763 - val_loss: 0.3263 - val_mse: 0.3263\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2682 - mse: 0.2682 - val_loss: 0.3123 - val_mse: 0.3123\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2625 - mse: 0.2625 - val_loss: 0.3024 - val_mse: 0.3024\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2584 - mse: 0.2584 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2554 - mse: 0.2554 - val_loss: 0.2892 - val_mse: 0.2892\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2531 - mse: 0.2531 - val_loss: 0.2852 - val_mse: 0.2852\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2513 - mse: 0.2513 - val_loss: 0.2827 - val_mse: 0.2827\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2810 - val_mse: 0.2810\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2488 - mse: 0.2488 - val_loss: 0.2805 - val_mse: 0.2805\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2481 - mse: 0.2481 - val_loss: 0.2800 - val_mse: 0.2800\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2473 - mse: 0.2473 - val_loss: 0.2793 - val_mse: 0.2793\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2470 - mse: 0.2470 - val_loss: 0.2793 - val_mse: 0.2793\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2464 - mse: 0.2464 - val_loss: 0.2783 - val_mse: 0.2783\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2461 - mse: 0.2461 - val_loss: 0.2789 - val_mse: 0.2789\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2458 - mse: 0.2458 - val_loss: 0.2801 - val_mse: 0.2801\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2455 - mse: 0.2455 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2455 - mse: 0.2455 - val_loss: 0.2804 - val_mse: 0.2804\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2452 - mse: 0.2452 - val_loss: 0.2793 - val_mse: 0.2793\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2452 - mse: 0.2452 - val_loss: 0.2791 - val_mse: 0.2791\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2450 - mse: 0.2450 - val_loss: 0.2790 - val_mse: 0.2790\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2450 - mse: 0.2450 - val_loss: 0.2786 - val_mse: 0.2786\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2449 - mse: 0.2449 - val_loss: 0.2779 - val_mse: 0.2779\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2783 - val_mse: 0.2783\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2775 - val_mse: 0.2775\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2773 - val_mse: 0.2773\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2769 - val_mse: 0.2769\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2777 - val_mse: 0.2777\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2786 - val_mse: 0.2786\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.2780 - val_mse: 0.2780\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2785 - val_mse: 0.2785\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2782 - val_mse: 0.2782\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2779 - val_mse: 0.2779\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2780 - val_mse: 0.2780\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.2781 - val_mse: 0.2781\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2785 - val_mse: 0.2785\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2789 - val_mse: 0.2789\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2795 - val_mse: 0.2795\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2447 - mse: 0.2447 - val_loss: 0.2799 - val_mse: 0.2799\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.2794 - val_mse: 0.2794\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.2798 - val_mse: 0.2798\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.2799 - val_mse: 0.2799\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.2788 - val_mse: 0.2788\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.2784 - val_mse: 0.2784\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.8631 - mse: 2.8631 - val_loss: 2.3087 - val_mse: 2.3087\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 834us/step - loss: 1.7416 - mse: 1.7416 - val_loss: 1.5255 - val_mse: 1.5255\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 829us/step - loss: 1.1474 - mse: 1.1474 - val_loss: 1.0752 - val_mse: 1.0752\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.8081 - mse: 0.8081 - val_loss: 0.7984 - val_mse: 0.7984\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.6051 - mse: 0.6051 - val_loss: 0.6097 - val_mse: 0.6097\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.4724 - mse: 0.4724 - val_loss: 0.4859 - val_mse: 0.4859\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.3893 - mse: 0.3893 - val_loss: 0.4026 - val_mse: 0.4026\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.3360 - mse: 0.3360 - val_loss: 0.3462 - val_mse: 0.3462\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.3008 - mse: 0.3008 - val_loss: 0.3068 - val_mse: 0.3068\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.2782 - mse: 0.2782 - val_loss: 0.2799 - val_mse: 0.2799\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.2635 - mse: 0.2635 - val_loss: 0.2615 - val_mse: 0.2615\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2542 - mse: 0.2542 - val_loss: 0.2487 - val_mse: 0.2487\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2481 - mse: 0.2481 - val_loss: 0.2392 - val_mse: 0.2392\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.2439 - mse: 0.2439 - val_loss: 0.2319 - val_mse: 0.2319\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.2413 - mse: 0.2413 - val_loss: 0.2279 - val_mse: 0.2279\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.2396 - mse: 0.2396 - val_loss: 0.2244 - val_mse: 0.2244\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2384 - mse: 0.2384 - val_loss: 0.2216 - val_mse: 0.2216\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.2376 - mse: 0.2376 - val_loss: 0.2191 - val_mse: 0.2191\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2182 - val_mse: 0.2182\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.2370 - mse: 0.2370 - val_loss: 0.2161 - val_mse: 0.2161\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.2150 - val_mse: 0.2150\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2142 - val_mse: 0.2142\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.2365 - mse: 0.2365 - val_loss: 0.2119 - val_mse: 0.2119\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2122 - val_mse: 0.2122\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2108 - val_mse: 0.2108\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2102 - val_mse: 0.2102\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2114 - val_mse: 0.2114\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2111 - val_mse: 0.2111\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2108 - val_mse: 0.2108\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2110 - val_mse: 0.2110\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2102 - val_mse: 0.2102\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2103 - val_mse: 0.2103\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2104 - val_mse: 0.2104\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2103 - val_mse: 0.2103\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2103 - val_mse: 0.2103\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2098 - val_mse: 0.2098\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2098 - val_mse: 0.2098\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2101 - val_mse: 0.2101\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2107 - val_mse: 0.2107\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2099 - val_mse: 0.2099\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2097 - val_mse: 0.2097\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2104 - val_mse: 0.2104\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2112 - val_mse: 0.2112\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2111 - val_mse: 0.2111\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2105 - val_mse: 0.2105\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2097 - val_mse: 0.2097\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.8372 - mse: 0.8372 - val_loss: 0.5247 - val_mse: 0.5247\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 653us/step - loss: 0.3813 - mse: 0.3813 - val_loss: 0.3268 - val_mse: 0.3268\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2869 - mse: 0.2869 - val_loss: 0.2788 - val_mse: 0.2788\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 679us/step - loss: 0.2590 - mse: 0.2590 - val_loss: 0.2614 - val_mse: 0.2614\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2476 - mse: 0.2476 - val_loss: 0.2530 - val_mse: 0.2530\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2419 - mse: 0.2419 - val_loss: 0.2492 - val_mse: 0.2492\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 608us/step - loss: 0.2393 - mse: 0.2393 - val_loss: 0.2460 - val_mse: 0.2460\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 625us/step - loss: 0.2378 - mse: 0.2378 - val_loss: 0.2445 - val_mse: 0.2445\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 650us/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2436 - val_mse: 0.2436\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 635us/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.2429 - val_mse: 0.2429\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 643us/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2426 - val_mse: 0.2426\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 654us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2424 - val_mse: 0.2424\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 636us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 640us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 701us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 655us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 616us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 650us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2422 - val_mse: 0.2422\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 636us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 640us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 647us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2410 - val_mse: 0.2410\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 641us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 622us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 634us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2416 - val_mse: 0.2416\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 669us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 646us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 658us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2419 - val_mse: 0.2419\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 657us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 632us/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 622us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2411 - val_mse: 0.2411\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 623us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 645us/step - loss: 0.2362 - mse: 0.2362 - val_loss: 0.2407 - val_mse: 0.2407\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2410 - val_mse: 0.2410\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 660us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 618us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 637us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 644us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2422 - val_mse: 0.2422\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 708us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 645us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2415 - val_mse: 0.2415\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2364 - mse: 0.2364 - val_loss: 0.2413 - val_mse: 0.2413\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2414 - val_mse: 0.2414\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 635us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 652us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 648us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 634us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2412 - val_mse: 0.2412\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 637us/step - loss: 0.2363 - mse: 0.2363 - val_loss: 0.2410 - val_mse: 0.2410\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0978 - mse: 1.0978 - val_loss: 0.5900 - val_mse: 0.5900\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 563us/step - loss: 0.4707 - mse: 0.4707 - val_loss: 0.3778 - val_mse: 0.3778\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3263 - mse: 0.3263 - val_loss: 0.3014 - val_mse: 0.3014\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 548us/step - loss: 0.2750 - mse: 0.2750 - val_loss: 0.2682 - val_mse: 0.2682\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.2546 - mse: 0.2546 - val_loss: 0.2530 - val_mse: 0.2530\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 596us/step - loss: 0.2462 - mse: 0.2462 - val_loss: 0.2456 - val_mse: 0.2456\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 540us/step - loss: 0.2426 - mse: 0.2426 - val_loss: 0.2420 - val_mse: 0.2420\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.2412 - mse: 0.2412 - val_loss: 0.2401 - val_mse: 0.2401\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.2405 - mse: 0.2405 - val_loss: 0.2391 - val_mse: 0.2391\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 550us/step - loss: 0.2402 - mse: 0.2402 - val_loss: 0.2385 - val_mse: 0.2385\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 548us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2382 - val_mse: 0.2382\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2380 - val_mse: 0.2380\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 546us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2379 - val_mse: 0.2379\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 545us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 558us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 550us/step - loss: 0.2399 - mse: 0.2399 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 542us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 559us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 552us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 581us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 558us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 546us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 552us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 544us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 538us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 551us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 557us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 552us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 561us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 544us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 560us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 540us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 542us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 564us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 535us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 549us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 548us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 556us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2376 - val_mse: 0.2376\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 567us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 535us/step - loss: 0.2400 - mse: 0.2400 - val_loss: 0.2377 - val_mse: 0.2377\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1110 - mse: 2.1110 - val_loss: 2.4100 - val_mse: 2.4100\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.7245 - mse: 1.7245 - val_loss: 1.9948 - val_mse: 1.9948\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4909 - mse: 1.4909 - val_loss: 1.7275 - val_mse: 1.7275\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3474 - mse: 1.3474 - val_loss: 1.5526 - val_mse: 1.5526\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2533 - mse: 1.2533 - val_loss: 1.4288 - val_mse: 1.4288\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1873 - mse: 1.1873 - val_loss: 1.3431 - val_mse: 1.3431\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1403 - mse: 1.1403 - val_loss: 1.2855 - val_mse: 1.2855\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1058 - mse: 1.1058 - val_loss: 1.2392 - val_mse: 1.2392\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0791 - mse: 1.0791 - val_loss: 1.2049 - val_mse: 1.2049\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0585 - mse: 1.0585 - val_loss: 1.1782 - val_mse: 1.1782\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.8204 - mse: 4.8204 - val_loss: 4.2385 - val_mse: 4.2385\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 793us/step - loss: 3.2554 - mse: 3.2554 - val_loss: 3.0732 - val_mse: 3.0732\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 806us/step - loss: 2.3800 - mse: 2.3800 - val_loss: 2.3594 - val_mse: 2.3594\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 768us/step - loss: 1.8587 - mse: 1.8587 - val_loss: 1.8959 - val_mse: 1.8959\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 773us/step - loss: 1.5363 - mse: 1.5363 - val_loss: 1.5858 - val_mse: 1.5858\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3313 - mse: 1.3313 - val_loss: 1.3637 - val_mse: 1.3637\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 767us/step - loss: 1.1928 - mse: 1.1928 - val_loss: 1.2134 - val_mse: 1.2134\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 780us/step - loss: 1.1059 - mse: 1.1059 - val_loss: 1.1151 - val_mse: 1.1151\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 765us/step - loss: 1.0507 - mse: 1.0507 - val_loss: 1.0431 - val_mse: 1.0431\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 795us/step - loss: 1.0117 - mse: 1.0117 - val_loss: 0.9821 - val_mse: 0.9821\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.5884 - mse: 1.5884 - val_loss: 1.2638 - val_mse: 1.2638\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 649us/step - loss: 1.1134 - mse: 1.1134 - val_loss: 1.0691 - val_mse: 1.0691\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 626us/step - loss: 1.0087 - mse: 1.0087 - val_loss: 1.0184 - val_mse: 1.0184\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 619us/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.9984 - val_mse: 0.9984\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 608us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9861 - val_mse: 0.9861\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9530 - mse: 0.9530 - val_loss: 0.9773 - val_mse: 0.9773\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 640us/step - loss: 0.9494 - mse: 0.9494 - val_loss: 0.9737 - val_mse: 0.9737\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.9472 - mse: 0.9472 - val_loss: 0.9703 - val_mse: 0.9703\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 636us/step - loss: 0.9462 - mse: 0.9462 - val_loss: 0.9678 - val_mse: 0.9678\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 615us/step - loss: 0.9459 - mse: 0.9459 - val_loss: 0.9684 - val_mse: 0.9684\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.9892 - mse: 2.9892 - val_loss: 2.0536 - val_mse: 2.0536\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 556us/step - loss: 1.6751 - mse: 1.6751 - val_loss: 1.4308 - val_mse: 1.4308\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2447 - mse: 1.2447 - val_loss: 1.1732 - val_mse: 1.1732\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 543us/step - loss: 1.0780 - mse: 1.0780 - val_loss: 1.0552 - val_mse: 1.0552\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 562us/step - loss: 1.0091 - mse: 1.0091 - val_loss: 1.0032 - val_mse: 1.0032\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 543us/step - loss: 0.9810 - mse: 0.9810 - val_loss: 0.9777 - val_mse: 0.9777\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 544us/step - loss: 0.9686 - mse: 0.9686 - val_loss: 0.9650 - val_mse: 0.9650\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 535us/step - loss: 0.9630 - mse: 0.9630 - val_loss: 0.9585 - val_mse: 0.9585\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 533us/step - loss: 0.9612 - mse: 0.9612 - val_loss: 0.9550 - val_mse: 0.9550\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 537us/step - loss: 0.9607 - mse: 0.9607 - val_loss: 0.9532 - val_mse: 0.9532\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.0864 - mse: 2.0864 - val_loss: 2.4010 - val_mse: 2.4010\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.7080 - mse: 1.7080 - val_loss: 1.9910 - val_mse: 1.9910\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4780 - mse: 1.4780 - val_loss: 1.7261 - val_mse: 1.7261\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3357 - mse: 1.3357 - val_loss: 1.5504 - val_mse: 1.5504\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2427 - mse: 1.2427 - val_loss: 1.4292 - val_mse: 1.4292\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1785 - mse: 1.1785 - val_loss: 1.3422 - val_mse: 1.3422\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1331 - mse: 1.1331 - val_loss: 1.2815 - val_mse: 1.2815\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1002 - mse: 1.1002 - val_loss: 1.2354 - val_mse: 1.2354\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0735 - mse: 1.0735 - val_loss: 1.2021 - val_mse: 1.2021\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0538 - mse: 1.0538 - val_loss: 1.1758 - val_mse: 1.1758\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0390 - mse: 1.0390 - val_loss: 1.1594 - val_mse: 1.1594\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0260 - mse: 1.0260 - val_loss: 1.1465 - val_mse: 1.1465\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0163 - mse: 1.0163 - val_loss: 1.1340 - val_mse: 1.1340\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0092 - mse: 1.0092 - val_loss: 1.1278 - val_mse: 1.1278\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0033 - mse: 1.0033 - val_loss: 1.1247 - val_mse: 1.1247\n",
      "Epoch 1/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7293 - mse: 4.7293 - val_loss: 4.1510 - val_mse: 4.1510\n",
      "Epoch 2/15\n",
      "32/32 [==============================] - 0s 825us/step - loss: 3.1949 - mse: 3.1949 - val_loss: 3.0328 - val_mse: 3.0328\n",
      "Epoch 3/15\n",
      "32/32 [==============================] - 0s 790us/step - loss: 2.3476 - mse: 2.3476 - val_loss: 2.3220 - val_mse: 2.3220\n",
      "Epoch 4/15\n",
      "32/32 [==============================] - 0s 775us/step - loss: 1.8302 - mse: 1.8302 - val_loss: 1.8618 - val_mse: 1.8618\n",
      "Epoch 5/15\n",
      "32/32 [==============================] - 0s 791us/step - loss: 1.5106 - mse: 1.5106 - val_loss: 1.5611 - val_mse: 1.5611\n",
      "Epoch 6/15\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3147 - mse: 1.3147 - val_loss: 1.3513 - val_mse: 1.3513\n",
      "Epoch 7/15\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1860 - mse: 1.1860 - val_loss: 1.2066 - val_mse: 1.2066\n",
      "Epoch 8/15\n",
      "32/32 [==============================] - 0s 761us/step - loss: 1.1019 - mse: 1.1019 - val_loss: 1.1054 - val_mse: 1.1054\n",
      "Epoch 9/15\n",
      "32/32 [==============================] - 0s 774us/step - loss: 1.0475 - mse: 1.0475 - val_loss: 1.0354 - val_mse: 1.0354\n",
      "Epoch 10/15\n",
      "32/32 [==============================] - 0s 766us/step - loss: 1.0123 - mse: 1.0123 - val_loss: 0.9881 - val_mse: 0.9881\n",
      "Epoch 11/15\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.9898 - mse: 0.9898 - val_loss: 0.9525 - val_mse: 0.9525\n",
      "Epoch 12/15\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.9741 - mse: 0.9741 - val_loss: 0.9234 - val_mse: 0.9234\n",
      "Epoch 13/15\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.9645 - mse: 0.9645 - val_loss: 0.9056 - val_mse: 0.9056\n",
      "Epoch 14/15\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.9573 - mse: 0.9573 - val_loss: 0.8931 - val_mse: 0.8931\n",
      "Epoch 15/15\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.9532 - mse: 0.9532 - val_loss: 0.8788 - val_mse: 0.8788\n",
      "Epoch 1/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4539 - mse: 1.4539 - val_loss: 1.1243 - val_mse: 1.1243\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 0s 661us/step - loss: 1.0470 - mse: 1.0470 - val_loss: 1.0027 - val_mse: 1.0027\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 0s 640us/step - loss: 0.9730 - mse: 0.9730 - val_loss: 0.9831 - val_mse: 0.9831\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 0s 635us/step - loss: 0.9558 - mse: 0.9558 - val_loss: 0.9777 - val_mse: 0.9777\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 0s 632us/step - loss: 0.9502 - mse: 0.9502 - val_loss: 0.9749 - val_mse: 0.9749\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 0s 627us/step - loss: 0.9478 - mse: 0.9478 - val_loss: 0.9720 - val_mse: 0.9720\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 0s 640us/step - loss: 0.9465 - mse: 0.9465 - val_loss: 0.9712 - val_mse: 0.9712\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 0s 635us/step - loss: 0.9458 - mse: 0.9458 - val_loss: 0.9678 - val_mse: 0.9678\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 0s 638us/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.9683 - val_mse: 0.9683\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 0s 689us/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.9683 - val_mse: 0.9683\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9699 - val_mse: 0.9699\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 0s 634us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9668 - val_mse: 0.9668\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 0s 638us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9672 - val_mse: 0.9672\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 0s 626us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9653 - val_mse: 0.9653\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 0s 646us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9661 - val_mse: 0.9661\n",
      "Epoch 1/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.8035 - mse: 2.8035 - val_loss: 1.9513 - val_mse: 1.9513\n",
      "Epoch 2/15\n",
      "63/63 [==============================] - 0s 560us/step - loss: 1.6079 - mse: 1.6079 - val_loss: 1.3940 - val_mse: 1.3940\n",
      "Epoch 3/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2205 - mse: 1.2205 - val_loss: 1.1536 - val_mse: 1.1536\n",
      "Epoch 4/15\n",
      "63/63 [==============================] - 0s 546us/step - loss: 1.0666 - mse: 1.0666 - val_loss: 1.0492 - val_mse: 1.0492\n",
      "Epoch 5/15\n",
      "63/63 [==============================] - 0s 531us/step - loss: 1.0048 - mse: 1.0048 - val_loss: 0.9987 - val_mse: 0.9987\n",
      "Epoch 6/15\n",
      "63/63 [==============================] - 0s 546us/step - loss: 0.9784 - mse: 0.9784 - val_loss: 0.9760 - val_mse: 0.9760\n",
      "Epoch 7/15\n",
      "63/63 [==============================] - 0s 561us/step - loss: 0.9678 - mse: 0.9678 - val_loss: 0.9646 - val_mse: 0.9646\n",
      "Epoch 8/15\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.9633 - mse: 0.9633 - val_loss: 0.9586 - val_mse: 0.9586\n",
      "Epoch 9/15\n",
      "63/63 [==============================] - 0s 536us/step - loss: 0.9613 - mse: 0.9613 - val_loss: 0.9551 - val_mse: 0.9551\n",
      "Epoch 10/15\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9608 - mse: 0.9608 - val_loss: 0.9534 - val_mse: 0.9534\n",
      "Epoch 11/15\n",
      "63/63 [==============================] - 0s 548us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9521 - val_mse: 0.9521\n",
      "Epoch 12/15\n",
      "63/63 [==============================] - 0s 551us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9518 - val_mse: 0.9518\n",
      "Epoch 13/15\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9512 - val_mse: 0.9512\n",
      "Epoch 14/15\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9511 - val_mse: 0.9511\n",
      "Epoch 15/15\n",
      "63/63 [==============================] - 0s 547us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9505 - val_mse: 0.9505\n",
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8296 - mse: 1.8296 - val_loss: 2.2302 - val_mse: 2.2302\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4987 - mse: 1.4987 - val_loss: 1.8555 - val_mse: 1.8555\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3110 - mse: 1.3110 - val_loss: 1.6135 - val_mse: 1.6135\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2003 - mse: 1.2003 - val_loss: 1.4574 - val_mse: 1.4574\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1333 - mse: 1.1333 - val_loss: 1.3602 - val_mse: 1.3602\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0915 - mse: 1.0915 - val_loss: 1.2907 - val_mse: 1.2907\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0630 - mse: 1.0630 - val_loss: 1.2362 - val_mse: 1.2362\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0422 - mse: 1.0422 - val_loss: 1.1993 - val_mse: 1.1993\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0280 - mse: 1.0280 - val_loss: 1.1738 - val_mse: 1.1738\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0171 - mse: 1.0171 - val_loss: 1.1545 - val_mse: 1.1545\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0091 - mse: 1.0091 - val_loss: 1.1437 - val_mse: 1.1437\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0022 - mse: 1.0022 - val_loss: 1.1373 - val_mse: 1.1373\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9980 - mse: 0.9980 - val_loss: 1.1334 - val_mse: 1.1334\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9940 - mse: 0.9940 - val_loss: 1.1292 - val_mse: 1.1292\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9912 - mse: 0.9912 - val_loss: 1.1220 - val_mse: 1.1220\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9885 - mse: 0.9885 - val_loss: 1.1206 - val_mse: 1.1206\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9865 - mse: 0.9865 - val_loss: 1.1174 - val_mse: 1.1174\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9852 - mse: 0.9852 - val_loss: 1.1165 - val_mse: 1.1165\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9836 - mse: 0.9836 - val_loss: 1.1167 - val_mse: 1.1167\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9829 - mse: 0.9829 - val_loss: 1.1158 - val_mse: 1.1158\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9821 - mse: 0.9821 - val_loss: 1.1093 - val_mse: 1.1093\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9808 - mse: 0.9808 - val_loss: 1.1100 - val_mse: 1.1100\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9804 - mse: 0.9804 - val_loss: 1.1087 - val_mse: 1.1087\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9800 - mse: 0.9800 - val_loss: 1.1099 - val_mse: 1.1099\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9797 - mse: 0.9797 - val_loss: 1.1129 - val_mse: 1.1129\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9795 - mse: 0.9795 - val_loss: 1.1145 - val_mse: 1.1145\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9793 - mse: 0.9793 - val_loss: 1.1153 - val_mse: 1.1153\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9795 - mse: 0.9795 - val_loss: 1.1154 - val_mse: 1.1154\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9794 - mse: 0.9794 - val_loss: 1.1159 - val_mse: 1.1159\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9792 - mse: 0.9792 - val_loss: 1.1140 - val_mse: 1.1140\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.1410 - mse: 3.1410 - val_loss: 2.6395 - val_mse: 2.6395\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 800us/step - loss: 2.1442 - mse: 2.1442 - val_loss: 1.9954 - val_mse: 1.9954\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 782us/step - loss: 1.6562 - mse: 1.6562 - val_loss: 1.6343 - val_mse: 1.6343\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 805us/step - loss: 1.3893 - mse: 1.3893 - val_loss: 1.4056 - val_mse: 1.4056\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 768us/step - loss: 1.2307 - mse: 1.2307 - val_loss: 1.2440 - val_mse: 1.2440\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 781us/step - loss: 1.1297 - mse: 1.1297 - val_loss: 1.1367 - val_mse: 1.1367\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 754us/step - loss: 1.0641 - mse: 1.0641 - val_loss: 1.0528 - val_mse: 1.0528\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0216 - mse: 1.0216 - val_loss: 0.9942 - val_mse: 0.9942\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.9947 - mse: 0.9947 - val_loss: 0.9559 - val_mse: 0.9559\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.9781 - mse: 0.9781 - val_loss: 0.9273 - val_mse: 0.9273\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.9661 - mse: 0.9661 - val_loss: 0.9057 - val_mse: 0.9057\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.9585 - mse: 0.9585 - val_loss: 0.8972 - val_mse: 0.8972\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.9537 - mse: 0.9537 - val_loss: 0.8787 - val_mse: 0.8787\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.9503 - mse: 0.9503 - val_loss: 0.8677 - val_mse: 0.8677\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9484 - mse: 0.9484 - val_loss: 0.8635 - val_mse: 0.8635\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9475 - mse: 0.9475 - val_loss: 0.8575 - val_mse: 0.8575\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.9466 - mse: 0.9466 - val_loss: 0.8551 - val_mse: 0.8551\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.9459 - mse: 0.9459 - val_loss: 0.8574 - val_mse: 0.8574\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.9458 - mse: 0.9458 - val_loss: 0.8498 - val_mse: 0.8498\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.9459 - mse: 0.9459 - val_loss: 0.8449 - val_mse: 0.8449\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8473 - val_mse: 0.8473\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8432 - val_mse: 0.8432\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8418 - val_mse: 0.8418\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.8454 - val_mse: 0.8454\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8424 - val_mse: 0.8424\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8410 - val_mse: 0.8410\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8440 - val_mse: 0.8440\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8461 - val_mse: 0.8461\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8433 - val_mse: 0.8433\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8454 - val_mse: 0.8454\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.4428 - mse: 1.4428 - val_loss: 1.1091 - val_mse: 1.1091\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 0s 666us/step - loss: 1.0420 - mse: 1.0420 - val_loss: 0.9930 - val_mse: 0.9930\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 0s 660us/step - loss: 0.9695 - mse: 0.9695 - val_loss: 0.9774 - val_mse: 0.9774\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 0s 635us/step - loss: 0.9538 - mse: 0.9538 - val_loss: 0.9752 - val_mse: 0.9752\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 0s 707us/step - loss: 0.9493 - mse: 0.9493 - val_loss: 0.9713 - val_mse: 0.9713\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 0s 640us/step - loss: 0.9475 - mse: 0.9475 - val_loss: 0.9683 - val_mse: 0.9683\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 0s 623us/step - loss: 0.9464 - mse: 0.9464 - val_loss: 0.9683 - val_mse: 0.9683\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 0s 623us/step - loss: 0.9460 - mse: 0.9460 - val_loss: 0.9671 - val_mse: 0.9671\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.9691 - val_mse: 0.9691\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 0s 630us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9675 - val_mse: 0.9675\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 0s 657us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9663 - val_mse: 0.9663\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 0s 628us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9680 - val_mse: 0.9680\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 0s 609us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9691 - val_mse: 0.9691\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 0s 679us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9685 - val_mse: 0.9685\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9676 - val_mse: 0.9676\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 0s 686us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9677 - val_mse: 0.9677\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 0s 650us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9665 - val_mse: 0.9665\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 0s 633us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9663 - val_mse: 0.9663\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 0s 638us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9645 - val_mse: 0.9645\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 0s 632us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9649 - val_mse: 0.9649\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 0s 619us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9646 - val_mse: 0.9646\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 0s 607us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9649 - val_mse: 0.9649\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 0s 639us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9645 - val_mse: 0.9645\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9662 - val_mse: 0.9662\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 0s 669us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9675 - val_mse: 0.9675\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 0s 618us/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9655 - val_mse: 0.9655\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 0s 655us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9656 - val_mse: 0.9656\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 212s 5s/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9673 - val_mse: 0.9673\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 0s 874us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9678 - val_mse: 0.9678\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 0s 701us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9666 - val_mse: 0.9666\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.7100 - mse: 1.7100 - val_loss: 1.2807 - val_mse: 1.2807\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 0s 633us/step - loss: 1.1503 - mse: 1.1503 - val_loss: 1.0866 - val_mse: 1.0866\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 0s 540us/step - loss: 1.0292 - mse: 1.0292 - val_loss: 1.0167 - val_mse: 1.0167\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 0s 553us/step - loss: 0.9882 - mse: 0.9882 - val_loss: 0.9849 - val_mse: 0.9849\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 0s 592us/step - loss: 0.9718 - mse: 0.9718 - val_loss: 0.9692 - val_mse: 0.9692\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 0s 562us/step - loss: 0.9650 - mse: 0.9650 - val_loss: 0.9607 - val_mse: 0.9607\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 0s 614us/step - loss: 0.9623 - mse: 0.9623 - val_loss: 0.9568 - val_mse: 0.9568\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9609 - mse: 0.9609 - val_loss: 0.9538 - val_mse: 0.9538\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 0s 545us/step - loss: 0.9605 - mse: 0.9605 - val_loss: 0.9528 - val_mse: 0.9528\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 0s 561us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9519 - val_mse: 0.9519\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 0s 553us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9515 - val_mse: 0.9515\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 0s 556us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 0s 559us/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 0s 542us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 0s 535us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9505 - val_mse: 0.9505\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 0s 540us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.9597 - mse: 0.9597 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 0s 560us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 0s 595us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 0s 585us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9505 - val_mse: 0.9505\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 0s 565us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 0s 561us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9502 - val_mse: 0.9502\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 0s 559us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 0s 634us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 0s 654us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 0s 575us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9502 - val_mse: 0.9502\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9500 - val_mse: 0.9500\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9170 - mse: 1.9170 - val_loss: 2.2848 - val_mse: 2.2848\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5690 - mse: 1.5690 - val_loss: 1.8886 - val_mse: 1.8886\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3650 - mse: 1.3650 - val_loss: 1.6384 - val_mse: 1.6384\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2445 - mse: 1.2445 - val_loss: 1.4831 - val_mse: 1.4831\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1709 - mse: 1.1709 - val_loss: 1.3795 - val_mse: 1.3795\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1224 - mse: 1.1224 - val_loss: 1.2999 - val_mse: 1.2999\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0874 - mse: 1.0874 - val_loss: 1.2469 - val_mse: 1.2469\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0642 - mse: 1.0642 - val_loss: 1.2059 - val_mse: 1.2059\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0438 - mse: 1.0438 - val_loss: 1.1778 - val_mse: 1.1778\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0308 - mse: 1.0308 - val_loss: 1.1592 - val_mse: 1.1592\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0195 - mse: 1.0195 - val_loss: 1.1455 - val_mse: 1.1455\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0115 - mse: 1.0115 - val_loss: 1.1373 - val_mse: 1.1373\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0047 - mse: 1.0047 - val_loss: 1.1279 - val_mse: 1.1279\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 1.1236 - val_mse: 1.1236\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9957 - mse: 0.9957 - val_loss: 1.1201 - val_mse: 1.1201\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9918 - mse: 0.9918 - val_loss: 1.1172 - val_mse: 1.1172\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9897 - mse: 0.9897 - val_loss: 1.1135 - val_mse: 1.1135\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9871 - mse: 0.9871 - val_loss: 1.1084 - val_mse: 1.1084\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9858 - mse: 0.9858 - val_loss: 1.1092 - val_mse: 1.1092\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9841 - mse: 0.9841 - val_loss: 1.1055 - val_mse: 1.1055\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9831 - mse: 0.9831 - val_loss: 1.1060 - val_mse: 1.1060\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9821 - mse: 0.9821 - val_loss: 1.1093 - val_mse: 1.1093\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9818 - mse: 0.9818 - val_loss: 1.1139 - val_mse: 1.1139\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9806 - mse: 0.9806 - val_loss: 1.1118 - val_mse: 1.1118\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9803 - mse: 0.9803 - val_loss: 1.1096 - val_mse: 1.1096\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9805 - mse: 0.9805 - val_loss: 1.1094 - val_mse: 1.1094\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9799 - mse: 0.9799 - val_loss: 1.1084 - val_mse: 1.1084\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9796 - mse: 0.9796 - val_loss: 1.1094 - val_mse: 1.1094\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9793 - mse: 0.9793 - val_loss: 1.1090 - val_mse: 1.1090\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9789 - mse: 0.9789 - val_loss: 1.1125 - val_mse: 1.1125\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9788 - mse: 0.9788 - val_loss: 1.1128 - val_mse: 1.1128\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9789 - mse: 0.9789 - val_loss: 1.1110 - val_mse: 1.1110\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 1.1134 - val_mse: 1.1134\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9788 - mse: 0.9788 - val_loss: 1.1131 - val_mse: 1.1131\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9787 - mse: 0.9787 - val_loss: 1.1141 - val_mse: 1.1141\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9787 - mse: 0.9787 - val_loss: 1.1165 - val_mse: 1.1165\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9790 - mse: 0.9790 - val_loss: 1.1186 - val_mse: 1.1186\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9786 - mse: 0.9786 - val_loss: 1.1188 - val_mse: 1.1188\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9786 - mse: 0.9786 - val_loss: 1.1197 - val_mse: 1.1197\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9784 - mse: 0.9784 - val_loss: 1.1217 - val_mse: 1.1217\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 1.1195 - val_mse: 1.1195\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9789 - mse: 0.9789 - val_loss: 1.1198 - val_mse: 1.1198\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9784 - mse: 0.9784 - val_loss: 1.1195 - val_mse: 1.1195\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9783 - mse: 0.9783 - val_loss: 1.1190 - val_mse: 1.1190\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9786 - mse: 0.9786 - val_loss: 1.1200 - val_mse: 1.1200\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 1.1177 - val_mse: 1.1177\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9785 - mse: 0.9785 - val_loss: 1.1182 - val_mse: 1.1182\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9787 - mse: 0.9787 - val_loss: 1.1175 - val_mse: 1.1175\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9786 - mse: 0.9786 - val_loss: 1.1165 - val_mse: 1.1165\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9788 - mse: 0.9788 - val_loss: 1.1163 - val_mse: 1.1163\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.9206 - mse: 1.9206 - val_loss: 1.4191 - val_mse: 1.4191\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 786us/step - loss: 1.3473 - mse: 1.3473 - val_loss: 1.1743 - val_mse: 1.1743\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 776us/step - loss: 1.1427 - mse: 1.1427 - val_loss: 1.0739 - val_mse: 1.0739\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 751us/step - loss: 1.0584 - mse: 1.0584 - val_loss: 1.0122 - val_mse: 1.0122\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 773us/step - loss: 1.0150 - mse: 1.0150 - val_loss: 0.9737 - val_mse: 0.9737\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9895 - mse: 0.9895 - val_loss: 0.9446 - val_mse: 0.9446\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.9739 - mse: 0.9739 - val_loss: 0.9191 - val_mse: 0.9191\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.9638 - mse: 0.9638 - val_loss: 0.8975 - val_mse: 0.8975\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.9573 - mse: 0.9573 - val_loss: 0.8857 - val_mse: 0.8857\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.9537 - mse: 0.9537 - val_loss: 0.8761 - val_mse: 0.8761\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9500 - mse: 0.9500 - val_loss: 0.8670 - val_mse: 0.8670\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.9489 - mse: 0.9489 - val_loss: 0.8607 - val_mse: 0.8607\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.9477 - mse: 0.9477 - val_loss: 0.8592 - val_mse: 0.8592\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.9468 - mse: 0.9468 - val_loss: 0.8573 - val_mse: 0.8573\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.9463 - mse: 0.9463 - val_loss: 0.8525 - val_mse: 0.8525\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.9458 - mse: 0.9458 - val_loss: 0.8505 - val_mse: 0.8505\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8500 - val_mse: 0.8500\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8469 - val_mse: 0.8469\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8465 - val_mse: 0.8465\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8448 - val_mse: 0.8448\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8464 - val_mse: 0.8464\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8448 - val_mse: 0.8448\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8427 - val_mse: 0.8427\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8411 - val_mse: 0.8411\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8428 - val_mse: 0.8428\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8419 - val_mse: 0.8419\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8447 - val_mse: 0.8447\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.8460 - val_mse: 0.8460\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8462 - val_mse: 0.8462\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8443 - val_mse: 0.8443\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8431 - val_mse: 0.8431\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8425 - val_mse: 0.8425\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.8424 - val_mse: 0.8424\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8429 - val_mse: 0.8429\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.8397 - val_mse: 0.8397\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8404 - val_mse: 0.8404\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8394 - val_mse: 0.8394\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8373 - val_mse: 0.8373\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8412 - val_mse: 0.8412\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8449 - val_mse: 0.8449\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.8420 - val_mse: 0.8420\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8404 - val_mse: 0.8404\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8414 - val_mse: 0.8414\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8429 - val_mse: 0.8429\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.8446 - val_mse: 0.8446\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8390 - val_mse: 0.8390\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.8404 - val_mse: 0.8404\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.8379 - val_mse: 0.8379\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.8371 - val_mse: 0.8371\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.8409 - val_mse: 0.8409\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.2677 - mse: 3.2677 - val_loss: 2.6063 - val_mse: 2.6063\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 1.9857 - mse: 1.9857 - val_loss: 1.7449 - val_mse: 1.7449\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 626us/step - loss: 1.4600 - mse: 1.4600 - val_loss: 1.3703 - val_mse: 1.3703\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 623us/step - loss: 1.2093 - mse: 1.2093 - val_loss: 1.1874 - val_mse: 1.1874\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 616us/step - loss: 1.0825 - mse: 1.0825 - val_loss: 1.0912 - val_mse: 1.0912\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 621us/step - loss: 1.0168 - mse: 1.0168 - val_loss: 1.0381 - val_mse: 1.0381\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9823 - mse: 0.9823 - val_loss: 1.0095 - val_mse: 1.0095\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 654us/step - loss: 0.9645 - mse: 0.9645 - val_loss: 0.9928 - val_mse: 0.9928\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 618us/step - loss: 0.9552 - mse: 0.9552 - val_loss: 0.9833 - val_mse: 0.9833\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 625us/step - loss: 0.9503 - mse: 0.9503 - val_loss: 0.9773 - val_mse: 0.9773\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 682us/step - loss: 0.9478 - mse: 0.9478 - val_loss: 0.9721 - val_mse: 0.9721\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 601us/step - loss: 0.9467 - mse: 0.9467 - val_loss: 0.9708 - val_mse: 0.9708\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 606us/step - loss: 0.9459 - mse: 0.9459 - val_loss: 0.9684 - val_mse: 0.9684\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.9457 - mse: 0.9457 - val_loss: 0.9696 - val_mse: 0.9696\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 735us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9690 - val_mse: 0.9690\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 612us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9655 - val_mse: 0.9655\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 623us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9638 - val_mse: 0.9638\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 618us/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.9641 - val_mse: 0.9641\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 614us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9658 - val_mse: 0.9658\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9660 - val_mse: 0.9660\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 598us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9647 - val_mse: 0.9647\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 607us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9639 - val_mse: 0.9639\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 666us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9647 - val_mse: 0.9647\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 616us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9641 - val_mse: 0.9641\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 611us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9643 - val_mse: 0.9643\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 670us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9658 - val_mse: 0.9658\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9657 - val_mse: 0.9657\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 614us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9669 - val_mse: 0.9669\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 669us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9675 - val_mse: 0.9675\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 611us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9659 - val_mse: 0.9659\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 615us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9648 - val_mse: 0.9648\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 666us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9648 - val_mse: 0.9648\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 635us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9659 - val_mse: 0.9659\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9637 - val_mse: 0.9637\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 684us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9641 - val_mse: 0.9641\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 613us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9641 - val_mse: 0.9641\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 612us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9666 - val_mse: 0.9666\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 678us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9657 - val_mse: 0.9657\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 614us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9664 - val_mse: 0.9664\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 608us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9649 - val_mse: 0.9649\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9450 - mse: 0.9450 - val_loss: 0.9672 - val_mse: 0.9672\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 632us/step - loss: 0.9456 - mse: 0.9456 - val_loss: 0.9685 - val_mse: 0.9685\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 604us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9686 - val_mse: 0.9686\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 664us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9688 - val_mse: 0.9688\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 600us/step - loss: 0.9454 - mse: 0.9454 - val_loss: 0.9675 - val_mse: 0.9675\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 592us/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9662 - val_mse: 0.9662\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 653us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9672 - val_mse: 0.9672\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.9451 - mse: 0.9451 - val_loss: 0.9679 - val_mse: 0.9679\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 591us/step - loss: 0.9452 - mse: 0.9452 - val_loss: 0.9650 - val_mse: 0.9650\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 656us/step - loss: 0.9453 - mse: 0.9453 - val_loss: 0.9658 - val_mse: 0.9658\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 2.9565 - mse: 2.9565 - val_loss: 2.0332 - val_mse: 2.0332\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 545us/step - loss: 1.6612 - mse: 1.6612 - val_loss: 1.4234 - val_mse: 1.4234\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 582us/step - loss: 1.2390 - mse: 1.2390 - val_loss: 1.1684 - val_mse: 1.1684\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 534us/step - loss: 1.0759 - mse: 1.0759 - val_loss: 1.0539 - val_mse: 1.0539\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0084 - mse: 1.0084 - val_loss: 1.0021 - val_mse: 1.0021\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 589us/step - loss: 0.9800 - mse: 0.9800 - val_loss: 0.9770 - val_mse: 0.9770\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.9680 - mse: 0.9680 - val_loss: 0.9645 - val_mse: 0.9645\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.9633 - mse: 0.9633 - val_loss: 0.9588 - val_mse: 0.9588\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 536us/step - loss: 0.9614 - mse: 0.9614 - val_loss: 0.9551 - val_mse: 0.9551\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 574us/step - loss: 0.9604 - mse: 0.9604 - val_loss: 0.9538 - val_mse: 0.9538\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9604 - mse: 0.9604 - val_loss: 0.9527 - val_mse: 0.9527\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 516us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9523 - val_mse: 0.9523\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 568us/step - loss: 0.9605 - mse: 0.9605 - val_loss: 0.9514 - val_mse: 0.9514\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 529us/step - loss: 0.9598 - mse: 0.9598 - val_loss: 0.9513 - val_mse: 0.9513\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9510 - val_mse: 0.9510\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9510 - val_mse: 0.9510\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 539us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 523us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 514us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 519us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 585us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 530us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 587us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 574us/step - loss: 0.9603 - mse: 0.9603 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9509 - val_mse: 0.9509\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 541us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 524us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9507 - val_mse: 0.9507\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 531us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9502 - val_mse: 0.9502\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 580us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9502 - val_mse: 0.9502\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 535us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9504 - val_mse: 0.9504\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 576us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9502 - val_mse: 0.9502\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 532us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 526us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9502 - val_mse: 0.9502\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9505 - val_mse: 0.9505\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 530us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9506 - val_mse: 0.9506\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 529us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 527us/step - loss: 0.9599 - mse: 0.9599 - val_loss: 0.9500 - val_mse: 0.9500\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9501 - val_mse: 0.9501\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 543us/step - loss: 0.9602 - mse: 0.9602 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 525us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9503 - val_mse: 0.9503\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 574us/step - loss: 0.9601 - mse: 0.9601 - val_loss: 0.9508 - val_mse: 0.9508\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 521us/step - loss: 0.9600 - mse: 0.9600 - val_loss: 0.9509 - val_mse: 0.9509\n"
     ]
    }
   ],
   "source": [
    "# Iterate model over all combinations of parameters\n",
    "param_combinations = list(itertools.product(_sigma, _n_epochs, _n_train))\n",
    "\n",
    "loss = []\n",
    "\n",
    "for combination in param_combinations:\n",
    "\tloss.append(run_model (combination[0], combination[1], combination[2], N_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally now that we have the loss array, we are going to visualize the data obtained. I am using heatmaps to visualize the loss obtained from the model as a function of the number of epochs, the number of training data and the noise $\\sigma$. With fixed number of `N_train`, each heatmap gives the values of the loss with respect to the number of epochs (on the x-axis) and the noise $\\sigma$ (on the y-axis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot heatmaps\n",
    "def plot_heatmaps(loss, param_combinations, sigma_values, n_epochs_values, n_train_values):\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    gs = GridSpec(1, len(n_train_values), width_ratios=[1]*len(n_train_values), wspace=0.05)\n",
    "    \n",
    "    # Calculate the min and max of the loss values\n",
    "    vmin = min(loss)\n",
    "    vmax = max(loss)\n",
    "    \n",
    "    axes = []\n",
    "    for i, n_train in enumerate(n_train_values):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        axes.append(ax)\n",
    "        \n",
    "        # Filter the loss values for the current n_train\n",
    "        filtered_loss = [loss[j] for j in range(len(loss)) if param_combinations[j][2] == n_train]\n",
    "        \n",
    "        # Reshape the filtered loss into a matrix\n",
    "        loss_matrix = np.array(filtered_loss).reshape(len(sigma_values), len(n_epochs_values))\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sns.heatmap(\n",
    "            loss_matrix, annot=True, fmt='.2f', ax=ax, cmap='viridis', vmin=vmin, vmax=vmax,\n",
    "            cbar=False,  # Disable individual colorbars\n",
    "            xticklabels=n_epochs_values, yticklabels=sigma_values\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f'# of training data = {n_train}', fontsize=14)\n",
    "        ax.set_xlabel('Epochs', fontsize=12)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Sigma $\\sigma$', fontsize=12)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "            ax.tick_params(labelleft=False)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.05, right=0.9, top=0.9, bottom=0.1, wspace=0.2)\n",
    "    cbar_ax = fig.add_axes([0.91, 0.15, 0.02, 0.7])\n",
    "    plt.colorbar(axes[0].collections[0], cax=cbar_ax).set_label('Loss')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plot the heatmaps\n",
    "plot_heatmaps(loss, param_combinations, _sigma, _n_epochs, _n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite being not too easy to read as a data visualization method, these heatmaps actually contain a lot of information about the performance of the model.\n",
    "\n",
    "First off, looking at the difference of the same point in the heatmaps (fixed sigma and epochs) throughout the difference plots, i.e. different number of traning data, we can see how the loss function did not decrease directly with the increase of training data: it saw an improvement when going from $500$ to $1000$, but after that the loss got worse. We can interpret this as an overfitting of the model which with more training data got worse in predicting the test data.\n",
    "\n",
    "The second observation is that with fixed sigma and number of training data, the loss did not vary significantly with the number of epochs (horizontally within a heatmap). This shows how number of epochs does not affect the loss function significantly, and that the model saturates after a certain number of epochs. This number can be seen varying with training data, but we can affirm that after $15$ epochs, the loss does not get much better.\n",
    "\n",
    "Finally, we can see that the loss function increases with the noise $\\sigma$, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend - original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHLCAYAAAA0kLlRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4qElEQVR4nO3deVhU1f8H8PfMsO8CIiAIIqjIpoK5r7nnvqdf0zLNStNc0rJSS80yK1ssTdI2K3Frca9ccEtzwQVRXBAQcEX2ZZg5vz/mx8TAsM8wMLxfz+ODc+fOnc+5s/Dm3HvPkQghBIiIiIiMhNTQBRARERHpEsMNERERGRWGGyIiIjIqDDdERERkVBhuiIiIyKgw3BAREZFRYbghIiIio8JwQ0REREaF4YaIiIiMCsMNVUuPHj0gkUhw6NAhjeVLliyBRCLBkiVLKrW9Q4cOQSKRoEePHjqrsTyltaEuMYY21Dbe3t6QSCSIi4szdClGKy4uDuPGjYOLiwukUikkEgk2bdpk6LJ0hu8hw2G4MSLjx4+HRCLBhAkTKrT+Rx99BIlEgoCAAD1XZjiHDh3CkiVL+Eu/kpYsWVLpYErAzp07sWTJEpw/f97Qpehdddual5eHXr164ZdffgEAtG/fHp07d0ajRo10WKX+1KfXui4yMXQBpDvPPPMMfvrpJ+zcuROZmZmwsbEpc/0ffvgBADBx4kSd1+Ls7IwWLVrA2dlZ59uujEOHDmHp0qUAUGpvUJMmTdCiRQtYWVnVYGW1W+E+Y8CpnJ07d+Lbb7+Ft7c3Wrdubehy9Kq6bd23bx9u3bqFsLAwHD16FObm5rovUo8q0v5mzZrBwsICpqamNVscMdwYkz59+sDV1RUpKSnYsWNHmaHlypUrOHfuXKV6eipjxowZmDFjhs63qw/fffedoUsgqndiYmIAAL169apzwaai/vrrL0OXUG/xsJQRkclkePrppwEAP/74Y5nrfv/99wBUvRmenp56r42IqKicnBwAgKWlpYErIaMkyKicPXtWABAymUykpKRoXUepVAovLy8BQHzzzTdCCCGys7PF5s2bxdixY0Xz5s2FtbW1sLa2FiEhIeLdd98VmZmZWrfVvXt3AUAcPHhQY/nixYsFALF48WKtj9u+fbvo2LGjsLKyEo6OjuKpp54Sp0+fFgcPHhQARPfu3Us8Zv/+/eLll18WwcHBokGDBsLc3Fz4+PiI6dOni9u3b5dYH0Cp/yZNmlRuGwr31ffffy+6desm7O3thYWFhWjRooV47bXXxMOHD7W2rfA5hBBi9+7domvXrsLGxkbY2dmJ/v37i7Nnz2p9XHnu378vXnzxReHu7i7Mzc1F8+bNxTvvvCPy8/NLbUNycrL49NNPRd++fYWXl5cwNzcXDg4Oolu3buK7774r8RyFr1tp/27duiWEEKKgoEDs3LlTPPvss6JVq1bCzs5OWFpaipYtW4r58+eL+/fvV7p9qampYsOGDWLIkCGiWbNmwsLCQtjZ2YknnnhCrFmzRsjlcq2Pq87+jouLExMmTBANGzYUlpaWIigoSHz++ecan5HCNpfl1q1bZe63op+Dixcvirffflt06NBBuLq6ClNTU+Hq6iqGDx8ujh07pnX7GzduVL9vMzMzxeuvvy78/PyEubm5xmdFqVSKL7/8UgQHBwsLCwvh4uIinn76aXHjxg2NbWiTkJAgZs6cKfz8/ISFhYWwt7cXPXr0EBEREVVua1lt0fbPy8tL4zkKb2tT9HUvbXll3w9yuVysX79e9OjRQzg6Ogpzc3PRtGlTMWLECLFz585Kt7+s91B+fr749NNPRbt27YStra2wsrISwcHBYtmyZSIrK6vE+sX3yffffy9CQ0OFpaWlaNCggRg1apS4ceNGqW2rbxhujFBgYKAAID7++GOt9x8+fFgAEJaWliItLU0IIURkZKQAIExMTISHh4cICwsTfn5+wsTERAAQbdu2FdnZ2SW2VZVw8/7776u/CNzc3ERoaKiwsbER5ubm4t133y013MhkMiGRSISLi4to3bq1CAwMFNbW1gKAcHJyEpcvX9ZYv3PnzsLT01MAEJ6enqJz587qf8uXLy+3DUqlUowfP15dq4+Pj2jbtq0wMzNTf8lo+zIpXP/LL78UEolEuLm5ibZt26prtbGxEVeuXNH62pQmOTlZ+Pj4qF+j1q1bCz8/PwFADBo0SHTr1k1rGwr3p6WlpWjWrJkICwsTTZo0Udc4ffp0jfXDw8NF586d1fcX3WedO3cWycnJQgjVL0IAQiqVqtvXsmVLYWFhIQAIb2/vUsN1ab7//nsBQJiZmQkvLy/Rrl074ePjI6RSqQAgnnrqKaFQKHS2v6Ojo4WTk5MAICwsLERoaKh637z00kuVCjfJycmic+fOwsXFRQAQfn5+GvstPDxcve6TTz4pAAgHBwfh7+8v2rZtK5ydndV/lPz4448ltl8YCMaMGSPatm0rJBKJ8Pf3F23atBF9+/ZVr/fcc8+p90fTpk1FaGiosLCwEA0aNBBvvvlmqeHm0KFDwt7eXv1eCQoKUn92AIi5c+dWqa3a7N69u9TP5qhRo4QQugk3lX0/PHr0SOO97+XlJcLCwtTtLKylMu0v7T2UnZ0tevXqpX4uf39/ERwcrH6vt27dWjx48EDjMUX3ycKFC9X/DwkJEebm5urv06r8YWGMGG6MUGF4CAsL03r/1KlTBQAxbtw49bK4uDixZcsWkZGRobFucnKyGDVqlAAglixZUmJblQ03Z8+eVYeUwr+QhRAiIyNDjB07VpiampYabtatWyfu3LmjsSw7O1ssX75cABA9evQo8ZjyepDKasNnn30mAAhbW1uxf/9+jX1S+CXYvn37Etsr/MKysrISGzduVC9PT09X/2IbO3ZsqfVoM3z4cHXIjI+PVy//66+/hK2trXq/FW9DZGSk+Pvvv0VBQYHG8qioKOHv7y8AiEOHDpXahtI8fvxYbNq0qUTvVWpqqpgxY4YAICZPnlypNkZFRYk//vhD5Obmaiy/ceOGOrxt2rSp1Fors7+VSqVo27atACD69eun0Y6ffvpJmJqaqoN9RcJNoUmTJgkAGnUUFxERIS5cuFCinp07d6p7GNLT0zXuLww3MplMNG/eXERHR6vvy8nJUW8XgDA3N1f3MgghxMOHD0Xfvn3V75Hi4ebOnTvC0dFRSCQSsWLFCo39f+zYMdG4cWMBQPz++++VbmtZyvps6iLcVPbzN2zYMAFANGvWTJw8eVLjvtjYWPHBBx9oLKtI+0sLN3PnzhUAhLu7uzhz5ozG87Rs2VIdZIsq3CcmJibCzs5O7N69W31fcnKyCA4OFgDEggULSq2nPmG4MUKJiYnqvwBiYmI07svLyxMNGjQQAMSuXbsqtL3s7GxhZmYm/Pz8StxX2XDzv//9TwAQo0ePLrGtnJwc9V9D2sJNWbp06SIAiMTExArVUV4blEql+i9LbT1giYmJ6h6cv/76S+O+wi/XmTNnlnjchQsXBABhb29f4bbFxsYKiUQiAIhLly6VuP+jjz5SP6e2Q2ul+fPPPwUAMXXq1BL3lRduyuPp6SmsrKxKPZRUWdevXxcARJ8+fUrcV5X9Xdh2S0tLrX/pvvLKK+rt6jrclKWwd6V4703RQzlFfxkW1aFDBwFALFu2rMR9jx49Eg4ODlrDzZw5cwQA8eqrr2rd7u+//y4AiF69emksr+3hpjLvh1OnTqmD4bVr1ypUf1XDTVpamrCyshIAxI4dO0o8prAWiUQirl+/rl5e9HDY6tWrSzzut99+EwBEcHBwheo3drxaygg1btwYPXv2xF9//YUffvgB7777rvq+P/74A6mpqXBxcUHfvn01HqdUKvH7779j//79uHnzJjIzMyGEAABIJBLExsYiOzu7WpdM79+/HwDw4osvlrjPwsICzz33HFauXFnq4//9919s3boV0dHRSEtLg0KhAADExsYCAC5cuIDGjRtXub5CV65cQUJCAiwsLDB16tQS9zdu3BgjR47ETz/9hP3796NXr14l1nn++edLLAsKCoKFhQXS0tLw8OFDODk5lVvL/v37IYRAt27dtI5J9Pzzz2PhwoXIz8/X+viMjAz8/PPPOHr0KJKTk5GTkwMhBPLy8gAAUVFR5dZQmr///hu///47rl27hoyMDCiVSgBAWloasrOzERsbC39//wpvLy8vD9u2bcPBgwcRHx+P7Oxs9XuwvFors7/37dsHABg9erTW4QpeeuklfPrppxWuu7Li4+OxefNmnD17Fg8ePFC/dvfu3QOgauf48eNLPC4gIABt27YtsTwjIwP//PMPAODZZ58tcX+DBg0wbNgwrQPkbd++HYD2/QcA/fv3h5mZGY4fP46CggKYmNSNXxuVeT/8+uuvAIDhw4fDz89Pr3UdPXoU2dnZaNKkCYYOHVri/nbt2qFjx444ceIEDhw4gGbNmpVYZ8qUKVofBwA3b97UfdF1UN14l1KlTZw4EX/99Rc2b96sEW4Kx7Z5+umnNb6kHj9+jIEDB+LEiRNlbjc1NbXK4ebx48fqL+/SfuGVtlwIgRkzZmDt2rVlPsejR4+qVFtx165dA6AaA8fa2lrrOoVBo3Dd4rR9KQFAw4YNkZCQgMzMzAqFm8Ltl7ZvbG1t0bhxY9y6davEfefOncOgQYOQlJRU6varss/y8/MxduxY7Ny5s8z1KrPt+Ph49O3bF1evXq3S9iqzv8vbp35+fjAxMUFBQUFFy6+wb7/9FtOnT0dubm6p65TWztLqvX79OoQQcHJygru7u9Z1goODSyzLzMxUj547bdq0MuvOzc3Fw4cP68wge5V5P1y5cgUA0KFDB73XVfjea9myJSQSidZ1AgICcOLECa3fLc7OzrC3ty+x3MXFBYDqNSVeCm60Ro4cCSsrK9y8eRPHjx8HoAoXu3fvBlBy4L45c+bgxIkTaNGiBbZt24Y7d+4gLy8PQnXoUt0bIpfLq1xT0Q9dw4YNta5T2hfn999/j7Vr18La2hpr165V9yIV1lc4Vk916tNWa+EXRlm1ZmRkaL2/tFAklao+dkV7JCpSS2n7rGgtRSkUCowZMwZJSUkYOHAgDh8+jAcPHqCgoABCCHVvV1X22cqVK7Fz5064urriu+++Q1xcHHJzc9WvR+fOnSu97cmTJ+Pq1ato37499u7di5SUFOTn50MIod5OWWGjMvu7vH0qlUr1MgDljRs3MHXqVOTm5mLu3Lk4d+4c0tPToVQqIYTA119/DaD0/VZaG7OysgCogm5ptN2Xlpam/v+xY8dK/VfYs1R4+XZdUJn3Q3p6OgDAwcFB73VV97ulvHaRCntujJSNjQ2GDRuGzZs344cffkCnTp2wZcsW5OXlwd/fH6Ghoep1CwoKsGXLFgCq7tkWLVpobKugoAApKSk6qanQ/fv34erqWmKdwp6d4grH7Vm9ejVeeOGFEvcnJCRUu76iCmstrR4AuHv3LoCyf6Hospb79++Xuo62Ok+dOoXr16/Dy8sL27dvLzFQWnX2WeHrsWnTJvTr16/E/ZXddlJSEg4ePAgrKyvs3r0bjo6OOqtVm/L2qVKpxMOHD3X6nACwZcsWyOVyjBs3Dh9++GGJ+6vazsJfeGX91a7tF2XRz2R+fn6tGUm3sEejtD8ACsOcrhR+hh8/fqzT7WpTm75bjBmjnhF75plnAPz3hVradAv3799HVlYWHB0dSwQbALh06ZL63JbqcHBwUP+1Ujg6aXGF3cPFFXadd+rUqcR9crm81MeV1u1bnubNmwNQHSop7RfG5cuXNdbVl8Ltl7bPMjMzkZiYWGJ54T4LDQ3VOgJsdc61Kev1ePjwIe7cuVOp7d2+fRuAqqu+eLABqlerNuXt0+vXr1epR6u891tZ+w2oejt9fX0hlUrx4MEDJCcna13n4sWLJZbZ29urD2MVvp8rqqqfrYooDGulhc/r16/r9PkKDzGfPHmywo+p7nfLlStXSg1vNfXdYswYboxY79694erqiocPH2LdunU4evSo1ukWCkcITU9P19rt/MEHH+ispj59+gAAvvrqqxL35eXl4ZtvvtH6uMIaC/+iKWrjxo2lfgkWPq6y3en+/v5o0qQJcnNzsWHDhhL3JyUlYdu2bQCgtedClwpP/D5y5Aiio6NL3L9hwwatJxOXtc/kcjk++eSTUp+zvP1W1rZXr15d6TBcuL179+5p/cLX5XsQ+G+fRkREaO2hKe/crtJUZ7/FxMTg999/r9Lz2traon379gCg9aThtLS0Us+PGjFiBACU+X7QpqqfrYpwcnKCvb09cnJytIYubZ/J6hg2bBgA1XxRN27cqNBjqtr+Ll26wMrKCgkJCeoTmYv6999/ceLECUgkEvX3JVUew40Rk8lk6isu5s+fDyEEunfvjiZNmmis5+DggICAABQUFODVV19V/6JUKBR4//338csvv8DMzEwnNb366quQSqXYsmULvvrqK/UvsqysLDz33HOlnkjZpUsXAMCbb76pEWT27t2L+fPnw8LCQuvjfHx8AEB9pUdFSSQSzJ8/HwCwePFijTli7t69i3HjxiE/Px8dOnRAz549K7zdqvD19cXQoUMhhMCkSZM0emkKZz3XdjihQ4cOMDExwbFjxzTmz0pLS8OECRO0/oItVLjfDh8+rPX+wtdj7ty56p4tIQS+++47fPjhh6W+HqUJCAhAgwYNkJiYiOXLl6vfF7m5uZg1axbOnTtXqe2V58knn0SbNm2QnZ2NiRMnIjU1VX3fli1b8OWXX1bpqqDC/XbkyBGtIa1wv61du1ZjNulr165h9OjR1fqczZkzBwDw7rvvaoSk1NRUjBs3rtQeyAULFsDR0RHffvst5syZU+LQzKNHj/DNN99g2bJlGsvLa2t1SCQS9R8Nc+bM0aj922+/LfWPoKoKDQ3F8OHDkZubiwEDBuD06dMa91+/fr3EYcSqtt/Ozk59teiMGTM03ts3btzApEmTAABjxowp9aRoqoAaueCcDObcuXPqsREAlDp66G+//aYeS8XR0VGEhYWpR0196623Sh2MqiojFK9YsUJdj7u7uwgLCxO2trZljlB8+/Zt4ejoqB6bpHXr1sLb21sAED179hQTJkzQOuZEWlqaelwfNzc30blzZ9G9e3fx3nvvlduG4iMU+/r6aoxQ3KRJkzJHKC5NZUa+LXTnzh11e01NTUWbNm1E8+bNBaAaube0EYrnzZunrqdJkybq4dpNTU3Fl19+WepYIu+884560Lg2bdqI7t27i+7du6tHKP7333/Vo6La2dmJ0NBQ4e7uLgCIiRMnljmlRWk+//xzda2urq4iLCxM2NnZCYlEIr7++utyxzUpTWn7+9KlSxrvqbCwMPW6lR2huND169c1RrDu2rWr6N69u/p9KZfL1ePRyGQy4e/vLwIDA9Uj6S5btkzrWDTlTZ1QqOgIxT4+PiIsLEw9PP+iRYsEAPHcc8+VeNzRo0fVn3dTU1MRFBQk2rdvL3x8fNTfC8UHviuvreUpbwyqK1euCBsbGwFAWFtbi7Zt2wo3NzcBQP3e1eX74dGjR6Jjx47qx3t7e4uwsDDRqFEjrZ+TirS/rBGKe/bsqX6uVq1aiZCQECGTyQQAERISUuYIxaUpr+31CfdCPRAUFCQA1RDzhdMtaLN3717RqVMnYWlpKWxtbUWHDh3EDz/8IIQo/UNa1bmltm7dKtq3b6/+4h04cGC5c0tdvXpVjBgxQj3HU8uWLcXSpUtFXl5emQNqnT59WgwYMEA4OjqqBzeszNxS3333nejatauws7MT5ubmws/PT8yfP7/El08hfYQbIYS4d++emD59unBzc1PXUd7cUkqlUnzyySeiZcuWwszMTDg7O4vBgweLkydPlvllmZ+fLxYvXixatGihDjHFa/7nn39Enz59hI2NjbC2thatW7cWn376qVAqlVUKN0II8cMPP4jWrVsLMzMz4eDgIHr16iX27NkjhKjYXELalLW/b968KcaPHy+cnJyEhYWFCAoKEp999lml55Yqat++faJ79+7qYFb8c5CWliZmzpwp3N3dhampqfDw8BDPP/+8SEpKKjXEVDTcKBQKsXbtWhEUFCTMzc1Fw4YNxZgxY0RsbKw6PM6aNUvrY+/duycWLVokQkJChI2NjbC0tBS+vr5iwIABYu3atVqn0yivrWWpyACbZ8+eFf379xe2trbC2tpadOrUST1Ssj7eD/n5+eKLL74QnTt3Vn/PNG3aVIwaNarECM1ClN/+8p5rzZo1IiwsTFhbW6unvajo3FLaMNz8RyKEjvsTiYio1pk5cyY+//xzfPzxx5g9e7ahyyHSK55zQ0Rk5DIzM7F161YAUI9BRGTMGG6IiIzEJ598onGiMgDcuXMHI0eOREpKCtq2basepp/ImPGwFBGRkejRowcOHz4Me3t7+Pj4IC8vDzExMVAqlXB2dsbBgwcRGBho6DKJ9I4jFBMRGYlZs2ahQYMGOHv2LGJiYiCEQLNmzTBgwAC89tprOplUlqguYM8NERERGRWec0NERERGpV4ellIqlUhKSoKtra1e50chIiIi3RFCICMjA+7u7mXOhF4vw01SUhI8PT0NXQYRERFVQUJCAjw8PEq9v16Gm8Jp5BMSEmBnZ1fl7cjlcuzfvx99+/bVOrePMWAbjQPbaDzqQzvZRuOgjzamp6fD09NT/Xu8NPUy3BQeirKzs6t2uLGysoKdnZ1RvznZxrqPbTQe9aGdbKNx0GcbyzulhCcUExERkVFhuCEiIiKjwnBDRERERqVennNTUQqFAnK5vNT75XI5TExMkJubC4VCUYOV1Ry20TiU1kZTU1PIZDIDVkZEpHsMN1oIIZCSkoLHjx+Xu56rqysSEhKMdrwcttE4lNVGBwcHuLq6Gm3biaj+YbjRojDYuLi4wMrKqtQvfaVSiczMTNjY2JQ5mFBdxjYaB21tFEIgOzsb9+7dAwC4ubkZskQiIp1huClGoVCog42Tk1OZ6yqVSuTn58PCwsKofymyjXVfaW20tLQEANy7dw8uLi48REVERsE4v8mrofAcGysrKwNXQlQzCt/rZZ1fRkRUlzDclILnH1B9wfc6ERkbhhsiIiIyKgw3REREZFQYboiIiKh0iYnAwYOqn3UEww3VGV988QW8vb1hYmKC+fPn4+HDh3BxcUFcXFyFtzFq1Ch89NFH+iuSiMiYhIcDXl5Ar16qn+Hhhq6oQhhujIREIinz3+TJkw1dInr06IHZs2dX6bGXLl3C7Nmz8cUXXyAhIQFLly7Fe++9h8GDB8Pb27vC23n77bexfPlypKenV6mO0rz33nto164dbG1t4eLigmHDhuHq1as6fY6KOHLkCAYPHgx3d3dIJBLs3LmzxmsgIiORmAhMmwYolarbSiXwwgt1ogeH4cZIJCcnq/998sknsLOz01i2Zs2aSm8zPz9fD5VWzW+//YbQ0FA89dRTcHNzg0QiQXh4OJ5//vlKbSc4OBje3t748ccfdVrf4cOH8fLLL+PkyZM4cOAACgoK0LdvX2RlZelk+z169MCmTZvKXS8rKwshISH4/PPPdfK8RFSPxcb+F2wKKRTA9euGqacSGG6MhKurq/qfvb09JBJJiWV79+5Fly5d4ODgACcnJwwaNAg3btxQb6NHjx6YMWMG5syZA2dnZ/Tp0wcAkJGRgf/973+wtraGm5sbPv744xK9MEIIfPDBB/Dx8YGlpSVCQkKwdetW9f2TJ0/G4cOHsWbNGnVvUkUPJzVr1gyLFi3CP//8A4lEgokTJ2LPnj0wMTFBx44d1ev99NNPsLCwwJ07d9TLnn/+eQQHByMtLU29bMiQIfjpp58qu4vLtHfvXkyePBkBAQEICQnBxo0bER8fjzNnzlS6vuoYMGAAli1bhhEjRuhke0RUj/n5AcUHNpXJAF9fw9RTCQw35RBCIDu/oNR/OfmKMu+vzj8hhE7bkpWVhTlz5uD06dP466+/IJVKMXz4cCiLJPNvv/0WJiYmOHbsGNatWwcAePPNN3H8+HH89ttvOHDgACIjI3H27FmNbb/55pvYuHEjvvzyS1y+fBmvvvoq/ve//+Hw4cMAgDVr1qBjx46YOnWqujfJ09MTmzZtKneclRMnTsDHxwerVq1CcnIy1q5diyNHjiAsLExjvXHjxqFFixZ47733AABLly7Fvn37sGfPHtjb26vXe+KJJ3Dq1Cnk5eWVeK4VK1bAxsamzH+RkZHl7uvCsOLo6Fjp+oiIagUPD2D9elWgAVQ/161TLa/lOP1COXLkCrR6e59Bnjv6nX6wMtPdSzRy5EiN2+Hh4XBxcUF0dDQCAwMBAL6+vvjggw/U66SlpeGnn37CDz/8gCeffBIAsHHjRri7u6vXycrKwkcffYS///5b3ZPi4+ODo0ePYt26dejevTvs7e1hZmYGKysruLq6qh9rb2+PFi1alFm3jY0N4uLi0KVLF/Vj4+LiNGoAVOcdLV++HKNGjYK7uzvWrFmDyMhING7cWGO9xo0bIy8vDykpKfDy8tK4b/r06RgzZkyZ9RTfXnFCCMyZMwddunRR79fK1EdEVGtMmQL066c6FOXrWyeCDcBwU6/cuHEDb731Fk6ePIkHDx6oe2zi4+PVv4SL94bcvHkTcrkcTzzxhHpZ8UASHR2N3Nxc9WGsQvn5+WjTpk2ZNQ0fPhzDhw8vc50LFy4AAIKCgtTLcnJyYGFhUWLdQYMGoVWrVli6dCn279+PgICAEusUzqeUnZ1d4j5HR0eN3paqmDFjBi5cuICjR49WqT5A1YO0YsUK9e2cnBycPHkSM2bMUC/bs2cPunbtWq1aiYjK5eFRuVCTmKg6X8fHR381lYPhphyWpjJEv9NP631KpRIZ6RmwtbPVy4SLlqa6ncRw8ODB8PT0xNdffw13d3colUoEBgZqnDhsbW2t8ZjCQ2PFDx0VPWRWGJJ27dpVohfC3Ny82nWfP38evr6+GrU5OzsjNTW1xLr79u1DTEwMFAoFGjVqpHV7jx49AgA0bNiwxH3FQ4U2ZYWKmTNn4rfffsORI0fgoeXLoCL1ASV7kCZMmICRI0dqnEvDHh8iqnXCw/+7wsraGtDxxRsVxXBTDolEUuqhIaVSiQIzGazMTGr9bNIPHz7ElStXsG7dOvUvZm09C8U1a9YMpqamOHXqlPoQTnp6OmJjY9G9e3cAQKtWrWBubo74+Hj1Mm3MzMygUCgqXfv58+cREhKisaxNmzb44YcfNJadPXsWo0ePxrp16/Dzzz/jrbfeQkRERIntXbp0CR4eHnB2di5xX1UPSwkhMHPmTOzYsQOHDh1C06ZNS6xT0fqAkj1IlpaWcHFxgW8dOJGPiOopbZeOA0BSkmqMnBrEcFNPNGjQAE5OTli/fj3c3NwQHx+PhQsXlvs4W1tbPP3001iwYAGcnZ3h4uKCxYsXQyqVqntzbG1tMW/ePLz66qtQKpXo0qUL0tPTcfz4cdjY2GDSpEkAAG9vb/zzzz+Ii4uDjY0NHB0d8euvv+L1119HTExMqTWcP38eQ4YM0VjWr18/vP7660hNTUWDBg0QFxeHp556CgsXLsTEiRPRqlUrtGvXDmfOnEFoaKjGYyMjI9G3b1+tz1XVw1Ivv/wyNm/ejF9//RW2trZISUkBoDqEZ2lpWan6qiMzMxPXi1ymeevWLZw/fx4ODg5wcHDQ2fMQEZWg7dJxALh5s8bDTe3ubtDiyy+/RHBwMOzs7GBnZ4eOHTtiz549hi6r1pNKpfj5559x5swZBAYG4tVXX8WqVasq9Nhly5ahQ4cOGDRoEHr37o3OnTvD399f45yXd999F2+//Tbee+89+Pv7o1+/fvj99981ejDmzZsHmUyGVq1aoWHDhoiPj0daWlqZg90plUpcvHixRM9NUFAQwsLCsGXLFjx69AgDBgzAkCFD8MYbbwAAQkNDMXjwYCxatEjjcbm5udixYwemTp1aobZX1Jdffom0tDT06NEDbm5u6n+//PJLpeqrrn///Rdt2rRRn+s0Z84ctGnTBosXL9bp8xARlaDt0nHAMOfeiDrmt99+E7t27RJXr14VV69eFW+88YYwNTUVly5dqvA20tLSBACRlpZW4r6cnBwRHR0tcnJyyt2OQqEQqampQqFQVKoNdYm2NmZmZgp7e3uxYcMGA1YmxK5du4S/v3+l9v/nn38u+vTpo7Gsvr6OhSrznq/N8vPzxc6dO0V+fr6hS9Gr+tBOtrEO27BBCJlMCEDk29jovI1l/f4uqs4dlho8eLDG7eXLl+PLL7/EyZMnS73yhKrnwoULSEhIQIcOHZCWloZ33nkHADB06FCD1jVw4EDExsbizp078PT0rNBjTE1N8dlnn+m5MiKieqropeNNmwLnzxukjDoXbopSKBSIiIhAVlaWxki1xeXl5WkM2FY4r5BcLodcLtdYVy6XQwgBpVKpMbidNuL/rxgqXN8YFbbxo48+wtWrV2FmZoa2bdvi8OHDcHR0NHi7Z86cCQAVrqNwuoai69en11FbG5VKJYQQkMvlkMl0e4VeTSr8LBf/TBub+tBOtrGOa9QIaNRIL22s6LYkQuh4GNwacPHiRXTs2BG5ubmwsbHB5s2bMXDgwFLXX7JkCZYuXVpi+ebNm2FlZaWxzMTEBK6urvD09ISZmZnOayeqbfLz85GQkICUlBQUFBQYuhwiquOSsoAT96QY4a1EOQPQV1p2djbGjx+PtLQ02NnZlbpenQw3+fn5iI+Px+PHj7Ft2zZs2LABhw8fRqtWrbSur63nxtPTEw8ePCixc3Jzc5GQkABvb2+tg8QVJYRARkYGbG1ty51CoK5iG41DWW3Mzc1FXFwcPD09y33P12ZyuRwHDhxAnz59YGpqauhy9KY+tJNtrJsKFEp8fTQOnx28AblCYMlTLdDg0WWdtjE9PR3Ozs7lhps6eVjKzMxMPd5HWFgYTp8+jTVr1qjnQirO3Nxc62BypqamJXa4QqGARCKBVCotd+yawu79wvWNEdtoHMpqY+Fl/do+D3WRsbSjPPWhnWxj3XH9XgbmbolCVKJqXr3e/o3QN8AVpyMv67SNFd1OnQw3xQkhtE6CSERERPqjUApsiLyJ1QeuIb9ACTsLEywZEoDhbRob9DB3nQs3b7zxBgYMGABPT09kZGTg559/xqFDh7B3715Dl0ZERFRv3LyfiXkRUTgb/xgA0KNFQ6wcEQxXe8Mf3q5z4ebu3buYOHEikpOTYW9vj+DgYOzdu7fEpI1ERESke0qlwMbjcfhgbwzyCpSwMTfB24NaYXSYR605b7HOhZvw8HBDl0BERFQv3X6YhfkRF3AqTjUBcVc/Z6wcGYzGDpYGrkxTnQs3REREVLOUSoEf/rmN93bHIEeugJWZDIue8sf4J5rUmt6aohhuiIiI6pPERNUkl35+gIdHuasnPMrGgm0XcPzGQwBARx8nfDAqGJ6OVuU80nCM87pXqpIePXpg9uzZ6tve3t5Ys2ZNmY+RSCTYuXNntZ9bV9uprCVLlqBt27Y1/rxERAYRHq6aobtXL9XPMk71EELgx39uo/8nR3D8xkNYmsqwdEgAfny+fa0ONgDDjVEYPHgwevfurfW+EydOQCKR4OzZs5Xe7unTp3U+e/aSJUvQunXrEsuTk5MxYMAAnT6XvhgqiBERVUtiIjBtGlA4BYtSCbzwgmp5MXce5+CZb05h0Y5LyMpXoJ13A+yZ1RWTOnlDKq19h6GK42EpIzBlyhSMGDECt2/fhpeXl8Z933zzDVq3bl2l3omGDRtCqVSq5+LSJ1dXV70/BxFRvRYb+1+wKaRQqCa5/P/7ha8vIlKAd/+IRkZeAcxNpHitf0tM7uQNWR0INYXYc2MEBg0aBBcXF2zatEljeXZ2Nn755RdMmTIFDx8+xNNPPw0PDw9YWVkhKCgIP/30U5nbLX5YKjY2Ft26dYOFhQVatWqFAwcOlHjMggUL0Lx5c1hZWcHHxwdvvfWWeqKzTZs2YenSpYiKioJEIoFEIlHXXLw35OLFi+jVqxcsLS3h5OSEadOmITMzU33/5MmTMWzYMHz44Ydwc3ODk5MTXn755XInVVu5ciUaNWoEW1tbTJkyBbm5uRr3nz59Gn369IGzszPs7e3RvXt3jV4vb29vAMDw4cMhkUjUt2/cuIGhQ4eiUaNGsLGxQbt27fDnn3+WWQsRUY3y8wOKj8IulQI//wx4eSFlyGg8Nyccr227gIy8ArRt4oDds7piSpemdSrYAAw3+pWYCBw8qLXLT5dMTEzwzDPPYNOmTSg6VVhERATy8/MxYcIE5ObmIjQ0FH/88QcuXbqEadOmYeLEifjnn38q9BxKpRIjRoyATCbDyZMn8dVXX2HBggUl1rO1tcWmTZsQHR2NNWvW4Ouvv8bHH38MABg7dizmzp2LgIAAJCcnIzk5GWPHji2xjezsbPTv3x8NGjTA6dOnERERgT///BMzZszQWO/gwYO4ceMGDh48iG+//RabNm0qEfCK2rJlCxYvXozly5fj33//hZubG9auXauxTkZGBiZNmoTIyEicPHkSfn5+GDhwIDIyMgCowg8AbNy4EcnJyerbmZmZGDhwIP7880+cO3cO/fr1w+DBgxEfH1+h/UtEpHceHsD69YBMprotkQBKJcS6ddju3x19p3yBg83awawgH693ckPE9E5o1tDGsDVXlaiH0tLSBACRlpZW4r6cnBwRHR0tcnJyyt2OQqEQqampQqFQlLxzwwYhpFIhANXPDRt0UXqprly5IgCIv//+W72sW7du4umnny71MQMHDhRz585V3+7evbuYNWuW+raXl5f46KOPRGpqqtizZ4+QyWQiISFBff+ePXsEALFjx45Sn+ODDz4QoaGh6tuLFy8WISEhJdYrup3169eLBg0aiMzMTPX9u3btElKpVKSkpAghhJg0aZLw8vISBQUF6nVGjx4txo4dW2otHTt2FNOnT9dY1r59exESElLq61hQUCBsbW3F77//rrXWsrRq1Up89tln5a5XE8p6r1bmPV+b5efni507d4r8/HxDl6JX9aGdbKOeJSQIsWWLEFKpuGvtIJ4fvkh4LfhDeC34QwyZ+JG45uQpxMGD1X4afbSxrN/fRbHnRh8qcdKWrrRs2RKdOnXCN998A0B1mCQyMhLPPfccANWEoMuXL0dwcDCcnJxgY2OD/fv3V7hnISYmBk2aNIFHkcsGO3bsWGK9rVu3okuXLnB1dYWNjQ3eeuutSvdeXLlyBSEhIbC2tlYv69y5M5RKJa5evapeFhAQAFnhXyAA3NzccO/evTK3W7zm4rfv3buH6dOno3nz5rC3t4e9vT0yMzPLbUNWVhZee+01tGrVCg4ODrCxsUFMTAx7boio9vHwgHBywm8tuqDvlLU40LwjTBVyzD/8Lbb9MA9+j5MAX98aO/qgDww3+lDeSVt6MmXKFGzbtg3p6enYuHEjvLy88OSTTwIAVq9ejY8//hivvfYa/v77b5w/fx79+vVDfn5+hbYtihzuKlR84KaTJ09i3LhxGDBgAP744w+cO3cOixYtqvBzFH2u0gaFKrq8+OywEolEPft1VU2ePBlnzpzBJ598guPHj+P8+fNwcnIqtw3z58/Htm3bsHz5ckRGRuL8+fMICgqqdNuJiPTtQWYeXrphhleGvIbHlnYISLmO3zfNxssnI2AilQDr1gH79lX4kvHaiOFGH7SdtCWTqZKwHo0ZMwYymQybN2/Gt99+i2effVYdBiIjIzF06FD873//Q0hICHx8fBAbG1vhbfv7+yM+Ph5JSUnqZSdOnNBY59ixY/Dy8sKiRYsQFhYGPz8/3L59W2MdMzMzKBSKMp+rVatWOH/+PLKysjS2LZVK0bx58wrXrK0NJ0+e1FhW/HZkZCReeeUVDBw4EAEBATA3N8eDBw801jE1NS3RhsjISEyePBnDhw9HUFAQXF1dERcXV+VaiYj0YffFZPT9+Aj23EiDCQRmHf8JO7+fi5aPEoB584C4OKBfvxo/+qBrDDf6UPykLZlMlYQrMBJkddjY2GDs2LF44403kJSUhMmTJ6vv8/X1xYEDB3D8+HFcuXIFL7zwAlJSUiq87d69e6NFixZ45plnEBUVhcjISCxatEhjHV9fX8THx+Pnn3/GjRs38Omnn2LHjh0a63h7e+PWrVs4f/48Hjx4gLy8vBLPNWHCBFhYWGDSpEm4dOkSDh48iJkzZ2LixIlo1KhR5XZKEbNmzcI333yDb775BteuXcPixYtx+fLlEm34/vvvceXKFfzzzz+YMGECLC0150zx9vbGX3/9hZSUFKSmpqoft337dpw/fx5RUVEYP358tXuRiKgOqeWHcFKz8jHzp3N46cezeJSVj5auttg5syte3bwSpn/9Cdy+Daxapfo9ZaCjD7rEcKMvU6aoEvDBg6qfU6bU0NNOQWpqKnr37o0mTZqol7/11lto27Yt+vXrhx49esDV1RXDhg2r8HalUil27NiBvLw8PPHEE3j++eexfPlyjXWGDh2KV199FTNmzEDr1q1x/PhxvPXWWxrrjBw5Ev3790fPnj3RsGFDrZejW1lZYd++fXj06BHatWuHUaNG4cknn8Tnn39euZ1RzNixY/H2229jwYIFCA0Nxe3bt/Hiiy9qrPPNN98gNTUVbdq0wcSJE/HKK6/AxcVFY53Vq1fjwIED8PT0RJs2bQAAH3/8MRo0aIBOnTph8ODB6NevH0c+JqovKjHqryHsv5yCPh8fwe9RSZBJJZjR0xe/zeiCwMb2qjDTo4fmH98GOvqgSxKh7WQKI5eeng57e3ukpaXBzs5O477c3FzcunULTZs2hYWFRZnbKRzgzs7ODtLibwQjwTYah7LaWJn3fG0ml8uxe/duDBw4sMT5WMakPrSzTrUxMVEVaIr2dMhkqj9qy+itr4k2pmXLsfT3y9h+7g4AwM/FBh+ODkGIp0P5Dw4PVx2KUij+O/pQyT/S9dHGsn5/F8URiomIiKqqrEM4ej4VoSx/x9zF69sv4m56HqQSYFq3Zpjd2w8WprLyHwyogky/fqp2+PoatC1VwXBDRERUVYWHcIr33BjoEE56rhzv/h6NiDOqc398nK2xanQIQr0aVH5jHh51LtQUYrghIiKqqsILSIofwjFAKDhy7T4WbLuA5LRcSCTAlM5NMa9fi4r31hgRhhsiIqLqMPAhnMy8AizfdQU/nVINGurlZIVVo0LwRFPHGq2jNmG4KUU9PM+a6im+14l0wECHcI5ff4D5Wy/gzuMcAMDkTt54rX8LWJnV71/v9bv1WhSe0Z2dnV1ifBMiY5SdnQ2g5IjPRFR7ZeUV4P29MfjuhGqgVI8Gllg1KgQdmzkZuLLageGmGJlMBgcHB/UcRVZWVqVOBaBUKpGfn4/c3FyjvoSYbaz7tLVRCIHs7Gzcu3cPDg4OGvN0EVHtderWI8yLiEL8I9UfJhPaN8HrA/1hY85f6YW4J7RwdXUFgDInYQRUvxxycnJgaWlZagCq69hG41BWGx0cHNTveSKqvXLyFVi17yo2Hr8FIQB3ewu8PyoYXf0aGrq0WofhRguJRAI3Nze4uLhALpeXup5cLseRI0fQrVs3o+3SZxuNQ2ltNDU1ZY8NUR1w5vYjzIu4gFsPVHPujQ3zxKJB/rCzMM7vrOpiuCmDTCYr84tfJpOhoKAAFhYWRvtLkW00DvWhjUTGKFeuwMcHruHryJtQCqCRnTlWjgxGzxYu5T+4HmO4ISIiqoXOJzzGvIgoXL+XCQAY0bYxFg8KgL0V/0ApD8MNERFRLZJXoMCnf8Xiy0M3oBRAQ1tzrBgehD6tGhm6tDqD4YaIiKiWuHQnDXO3ROHq3QwAwNDW7lgyOAANrM0MXFndwnBDRERkYPkFSnx+8Dq+OHgdCqWAk7UZlg8PRP9AN0OXVicx3BARERlQdFI65kVEITo5HQAwMMgV7w4NhJONuYErq7sYboiIiAxAIYAvDt3EF4duQK4QaGBlineHBWJQsLuhS6vzGG6IiIhqWOzdTHx8UYaErOsAgL6tGmH58CA0tGVvjS4w3BAREdWQAoUSX0fewkcHrkKukMDOwgRLhwZgWOvGRjtCuiEw3BAREdWAG/czMXdLFM4nPAYAtHJQYv3UTvBwsjVsYUaI4YaIiEiPFEqBjcduYdW+q8grUMLW3ASLBraARXIUGtlZGLo8o8RwQ0REpCuJiUBsLODnB3h4IO5BFuZvjcLpuFQAQLfmDbFyRBAaWptg9+4oAxdrvBhuiIiIdCE8HJg2DVAqoZTK8N0H32PlYwfkypWwNpPhzUGtMK6dJyQSyX+TMiclATdvqsMQ6QbDDRERUXUlJqqDTYJ9I8wfMAsn79sBUKJTMyd8MCoYHg2sSj4uIADIygKkUmD9emDKlBov3Rgx3BAREVVXbCyEUokfWw/Aip7PIdvMEpb5uXijtR0m/K89pNJiV0IlJal+KpX//XzhBaBfP/bg6ADDDRERUTXdcfXCgrHLcNS7NQDgifiL+HDfZ2gy5x+geLABgBs3Si5TKIDr1xludIDhhoiIqIqEENjybwLe/SMWmd6tYSHPw2uHv8Xk87shXfdV6UGlWTPg/HnNZTIZ4Our95rrA4YbIiKiKkhJy8XC7Rdw6Op9AECoVwOs6tIIPoNfBXy/KLsHxt1dFW5kMtVtmQxYt469NjrCcENERFQJQghsP3sHS36/jIzcApiZSDG/bws816UpZFIJgGYV39ilS8CtW6oeGwYbnWG4ISIiqqB7Gbl4Y/tF/HnlHgAgxNMBq0eHwNfFpmobdHcHvLx0WCEBDDdERETlEkLgt6gkLP7tMh5ny2Emk2J2Hz9M6+oDE5nU0OVRMQw3REREZXiQmYc3d1zC3sspAIDAxnZYPbo1WrhyTqjaiuGGiIioFLsuJOOtXy/hUVY+TGUSvNLLD9N7NIMpe2tqNYYbIiKiYh5l5ePtXy/hjwvJAAB/NzusHh2CVu52Bq6MKoLhhoiIqIh9l1OwaMdFPMjMh0wqwcs9mmFGLz+YmbC3pq5guCEiIgLwODsfS3+Pxo5zdwAAzRvZYPXo1gjysDdwZVRZDDdERFTv/R1zFwu3XcS9jDxIJcD07s0wq7cfzE1khi6NqoDhhoiI6q20HDmW/RGNiDOJAACfhtZYPToEbZo0MHBlVB0MN0REVC8dvnYfC7ddQHJaLiQSYGpXH8zp0xwWpuytqesYboiIqF7JyJVjxe4r+OlUAgDA28kKH44OQZi3o4ErI11huCEionrj2PUHeG3rBdx5nAMAeLazN17r1xKWZuytMSYMN0REZPSy8gqwck8Mvj95GwDg6WiJVaNC0MHHycCVkT4w3BARkVH75+ZDzN96AfGPsgEAEzt4YeGAlrA2569AY8VXloiI6r7ERCA2FvDzAzw8AAA5+Qp8sC8GG4/FAQAaO1jig1HB6OzrbMBCqSYw3BARUd0WHg5MmwYolYBUCqxfj3+fHI75Wy/g1oMsAMDTT3jijYH+sLUwNXCxVBMYboiIqO5KTPwv2ADIlZpg9eYT2BDrCgHA1c4C748KRvfmDQ1bJ9UohhsiIqq7YmPVweacW3PMe+pV3HDyBACMCvXAW4Nawd6SvTX1DcMNERHVXX5+yDM1wycdn8a69iOglMrQMPMRVo4NxZNdWxm6OjIQhhsiIqqzLsIWcxf+gmv5qt6ZodGHsXRQSzgw2NRrDDdERFTn5Bco8fnfsfji0A0olKZwtjTBspYy9J/xivpqKaq/GG6IiKhOiU5Kx9yIKFxJTgcADAp2wztDA+FobWbgyqi2YLghIqI6Qa5Q4stDN/DpX7EoUAo0sDLFsmFBeCrYzdClUS3DcENERLXe1ZQMzIuIwsU7aQCAfgGNsGxYEBramhu4MqqNpIYuoLLee+89tGvXDra2tnBxccGwYcNw9epVQ5dFRER6UKBQYu2h6xj82VFcvJMGe0tTrBnXGl/9L5TBhkpV58LN4cOH8fLLL+PkyZM4cOAACgoK0LdvX2RlZRm6NCIi0qEb97Mw6qsT+GDvVeQrlHiypQsOvNoNQ1s3hkQiMXR5VIvVucNSe/fu1bi9ceNGuLi44MyZM+jWrZuBqiIiIl1RKAX+TpJg/toTyC9QwtbCBEsGB2BEW4Yaqpg6F26KS0tTHX91dHQsdZ28vDzk5eWpb6enq86wl8vlkMvlVX7uwsdWZxu1HdtoHNhG42Hs7Yx7mIUF2y7hbIIMgBLd/JywbGgA3OwtUFBQYOjydMbYX0dAP22s6LYkQgihs2etYUIIDB06FKmpqYiMjCx1vSVLlmDp0qUllm/evBlWVlb6LJGIiCpAKYDIFAl+j5dCrpTAXCYw3EuJDi4C7KyhQtnZ2Rg/fjzS0tJgZ2dX6np1Oty8/PLL2LVrF44ePQqPMgZt0tZz4+npiQcPHpS5c8ojl8tx4MAB9OnTB6amxjl3CdtoHNhG42GM7Yx/lI2FOy7jdFwqAKBj0wbo2+A+xg4ynjYWZ4yvY3H6aGN6ejqcnZ3LDTd19rDUzJkz8dtvv+HIkSNlBhsAMDc3h7l5ybPqTU1NdbLDdbWd2oxtNA5so/EwhnYqlQI/norHe7uvIDtfASszGd4Y6I8xbd2wZ88eo2hjedjGym+rIupcuBFCYObMmdixYwcOHTqEpk2bGrokIiKqpMTUbCzYdgHHrj8EAHTwccSqUSHwdLQy6vNQqGbUuXDz8ssvY/Pmzfj1119ha2uLlJQUAIC9vT0sLS0NXB0REZVFCIGfTydg+a4ryMwrgIWpFAv7t8QzHb0hlfLkGtKNOhduvvzySwBAjx49NJZv3LgRkydPrvmCiIioQpIe52Dh9os4cu0+ACDMqwFWjQ5BU2drA1dGxqbOhZs6fP4zEVG9JITA1jOJeOf3aGTkFcDMRIrX+rXAs52bQsbeGtKDOhduiIiojkhMxN2LV/F6nCn+vp0BAGjt6YAPR4fA18XGwMWRMatz0y8QEVHtJzaEY8eASeiz7wH+vp0BM4nAgo5u2NoyD775jw1dHhk59twQEZFO3b92C4v23ML+p+YAAIKSY7F69ydo/kECoFQCUimwfj0wZYqBKyVjxXBDREQ683tUEt7eGo1Uv44wVcgx8/gvePFkBEyViv9WUiqBF14A+vUDyhmnjKgqGG6IiKjaHmbm4e1fL2PXxWQAQKu7N/Hhro/R6v4t7Q9QKIDr1xluSC8YboiIjFliIhAbC/j56S1I7L2UjEU7LuFhVj5MpBK83NMXL99Ogdn38aoVpFJACNW/QjIZ4Ourl3qIGG6IiIxVeDgwbZreznNJzcrHkt8v49fzSQCAFo1ssXpMCAIb2wNoDvTvp+qd8fUF9u1THYpSKFTBZt069tqQ3jDcEBEZo8TE/4INoPPzXP6MvovXd1zE/Yw8SCXAiz2a4ZUn/WBuIvtvJQ+P/55ryhTVcxeGHQYb0iOGGyIiYxQb+1+wKaSD81zScuR45/dobDubCADwdbHB6tEhCPF0KP/BRcMOkR4x3BARGSM/P9WhqKIBp5rnuRy8eg8Lt13A3fQ8SCTAtK4+eLVPc1iYysp/MFEN4iB+RETGyMNDdY6N7P+DRzXOc8nIlWPB1gt4duNp3E3PQ1Nna2yd3hGvD/TXb7CJjFQdXiOqJPbcEBEZKx2c53I09gFe2xqFpLRcSCTAs52aYn6/FrA002Oo+f57wMkJGDQIyMvjgH9UaQw3RETGrIrnuWTlFWDF7iv48R/V5dxNHK2walQw2vs46bpCTYmJwCuvAD/+qLrNAf+oChhuiIhIw4kbDzF/axQSU3MAAJM6emHBgJawMquBXxl6OhGa6heGGyIiAgBk5xfgg71Xsel4HACgsYMlVo0KRidf55orovBE6KI44B9VEsMNERHhdNwjzI+IQtzDbADA+PZN8MZAf9iY1/CvCQ8P4NNP/7vNAf+oChhuiIjqsVy5Ah/uu4rwY7cgBOBmb4H3RwajW/OGhitq4kRg925g1y69ThtBxovhhoionjobn4p5W6Jw80EWAGBMmAfeHNQKdhamBq7s/3XpApjWklqoTmG4ISKqZ3LlCnzyZyzWH7kBpQAa2Zlj5Yhg9GzpYujSiHSC4YaIqB65kPgYc7dEIfZeJgBgRJvGWDw4APZW7CEh48FwQ0RUD+QXKPHZ37FYe+gGFEoBZxszrBgehL4BroYujUjnGG6IiOqSpKT/fnp5Veghl+6kYV5EFGJSMgAAg0PcsXRIABytzfRVJZFBcW4pIqK6IjwcCAhQ/T8gQHW7DHKFEmv+jMWwL44hJiUDjtZmWDuhLT57ug2DDRk19twQEdUFp08D06YB5uaq2+VMSxCTko65W6JwOSkdANA/wBXLhgfC2ca8JqsmMgiGGyKi2i48HJg6FRBCc7mWaQkKFEqsO3ITn/x5DXKFgIOVKd4ZGojBwW6QSCT6qzExUTV1AseloVqA4YaIqDZLTFT12BQPNkCJaQli72ZgbkQULiSmAQB6+zfCihGBcLG10G+N4eGqGpVK1dQJnMWbDIzhhoioNtM2kSSgChH/Py2BQimwIfImVh+4hvwCJewsTLBkSACGt2ms394a4L/wVVgjZ/GmWoDhhoioNiucSLJ4wPnrL6B9e9y4n4l5EVE4F/8YANCjRUOsHBEMV3s999YU4izeVAsx3BAR1WYeHqrDPC+8oAoNMhkAQNm6DTZE3sSqfVeRV6CEjbkJ3hrkjzFhnvrvrSlKW/jiLN5kYLwUnIiotpsyBYiLAw4eBC5dwv0cYMI3p7Fs1xXkFSjR1c8Z+17thrHtmtRssAH+C1//H7o4izfVBuy5ISKqCzw8oHRvjB+O38QHF2TIVz6GlZkMi57yx/gnDBBqipoyRXWOzfXrqh4bBhsyMIYbIqI6IOFRNl7begEnbj4EIEGHpg2wanRreDpaGbo0FQ8PhhqqNRhuiIhqMSEENp+Kx4pdV5CVr4ClqRQDG8uxYnIYzM05yjCRNgw3RES1VNLjHCzYdgGRsQ8AAO28G+C9YQG4/M8hSKUGPAxFVMsx3BAR1TJCCET8m4h3/4hGRl4BzE2keK1/S0zu5A2logCXDV0gUS3HcENEVIukpOXi9e0XcPDqfQBA2yYOWDU6BM0a2gAAlApDVkdUNzDcEBHVAkII7Dh3B0t+u4z03AKYmUgxt09zPN/VBzIegiKqFIYbIiIDu5eRi0U7LuFA9F0AQIiHPT4cHQK/RrYV3wgnriRSY7ghIjIQIQR+v5CMt3+9hMfZcpjKJJjduzle6OYDE1klxljlxJVEGhhuiIgM4GFmHt769RJ2X0wBAAS42+HD0SHwd7Or3IY4cSVRCQw3REQ1bM/FZLy58xIeZuXDRCrBjF6+eLmnL0wr01tTiBNXEpXAcENEVENSs/Kx+LfL+C0qCQDQ0tUWH44OQWBj+6pvlBNXEpXAcENEVAMORN/F69sv4kFmHmRSCV7s3gwzn/SFuYmsehvWNms4J66keo7hhohIj9Ky5Vj6+2VsP3cHAOBrLcHqgb4ICW2uuyfhxJVEGhhuiIj05GDMPSyMOIe7WQWQQmDaP9swO/JHWCxR6P6KJk5cSaTGcENEpGPpuXK8+3s0Is4kAgB8HiZi1e5PEJoU899KvKKJSG8YboiIdOjItftYsO0CktNyIRFKTDn9K+ZFfg+LgnzNFXlFE5HeMNwQEelAZl4Blu+6gp9OxQMAvCwl+PDrhWh3J1r7A3hFE5HeMNwQEVXT8esPMH/rBdx5nAMAmNzJG68F2cDqnRjtD+AVTUR6xXBDRFRFWXkFeH9vDL47cRsA4NHAEqtGhaBjMyfVCsUv0X7vPaBdO17RRKRnDDdERFVw6tYjzIuIQvyjbADAhPZN8MZAf1ibF/la5SXaRAbBcENE9VMVZ9HOyVdg1b6r2Hj8FoQA3O0t8P6oYHT1a6j9AbxEm6jGMdwQUf1TxVm0z9x+hHkRF3DrQRYAYFw7Tyx6yh+2Fqb6rpiIKoHhhojqlyrMop0rV+DjA9fwdeRNKAXgameB90YGoWcLlxosnIgqiuGGiOqXSs6ifT7hMeZuOY8b91W9NSPbeuDtwa1gb8neGqLaiuGGiOqXCs6inVegwJo/Y/HV4RtQCqChrTlWDA9Cn1aNarhgIqoshhsiql8qMIv2pTtpmLslClfvZgAAhrZ2x5LBAWhgbWaoqomoEhhuiKj+KeUS7fwCJT4/eB1fHLwOhVLAydoMy4cHon+gm4ELJqLKYLghovqp2CXa0UnpmBcRhejkdADAU0FueGdoAJxszA1VIRFVEcMNEdVrcoUSXx26gU//joVcIdDAyhTvDgvEoGB3Q5dGRFXEcENE9da1uxmYuyUKF++kAQD6tmqE5cOD0NCWvTVEdVm1wo1cLkdKSgqys7PRsGFDODo66qouIiK9KVAo8XXkLXx84BryFUrYW5pi6ZAADG3tDolEYujyiKiaKh1uMjMz8eOPP+Knn37CqVOnkJeXp77Pw8MDffv2xbRp09CuXTudFkpEpAs37mdi7pYonE94DADo1dIF740IQiM7C8MWRkQ6U6lw8/HHH2P58uXw9vbGkCFDsHDhQjRu3BiWlpZ49OgRLl26hMjISPTp0wcdOnTAZ599Bj8/P33VTkRUYQqlwMZjt7Bq31XkFShha26Ctwe3wqhQD/bWEBmZSoWb48eP4+DBgwgKCtJ6/xNPPIHnnnsOX331FcLDw3H48GGGGyIyuLgHWZi/NQqn41IBAF39nPH+yGC4O1gauDIi0odKhZuIiAj1/zMyMmBra6t1PXNzc7z00kvVq4yI6pYqzrKtT0qlwHcn4rBybwxy5UpYm8nw5qBWGNfO07C9NbVwXxEZE2lVH9i1a1ekpKTospYKO3LkCAYPHgx3d9XJfzt37jRIHUT0/8LDAS8voFcv1c/wcENXhIRH2Ri/4SSW/B6NXLkSnZo5Ye/sbnj6iSaGDTa1cF8RGZsqh5uwsDC0b98eMTExGsvPnTuHgQMHVruwsmRlZSEkJASff/65Xp+HiCqgtFm2ExMNUo4QAj+cvI1+nxzByZuPYGkqw7tDA/DDlPbwdLQySE1qtWxfERmrKl8KvmHDBixduhRdunTBzp074eLigjfffBPbtm3DkCFDdFljCQMGDMCAAQP0+hxEVEGVnGVbnx7lAZO/PYPjNx4BAJ5o6ogPR4WgiZOBQ02hWrSviIxZtca5Wbx4MczMzNCnTx8oFAr069cPp0+fRtu2bXVVn07k5eVpXLKenq4aXl0ul0Mul1d5u4WPrc42aju20TjotY0+PoC1dclZtps2BWponwoh8MvpeKyMkiFP8QgWplLM7eOHZ9o3gVQqqT2vrQ72Fd+vxoFtrN42yyMRQoiqPEFycjLee+89bNiwAf7+/oiJicH69esxYcKEqmyuyiQSCXbs2IFhw4aVus6SJUuwdOnSEss3b94MK6ta8hcdEVXJ4zzg55tSXHmsOsre1FZgfDMFXHghFJHRyc7Oxvjx45GWlgY7O7tS16tyz42Pjw9atmyJiIgIPPXUU9i3bx/GjBmDxMRELFiwoKqb1YvXX38dc+bMUd9OT0+Hp6cn+vbtW+bOKY9cLseBAwfQp08fmJqa6qLUWodtNA410sakJODmTVXvhLv+52USQmDH+SR8uPsqMnILYCaTYoCHHMsmPgkLczO9P3+1VGNf8f1qHNjGqik88lKeKoebjRs3Yty4cerb/fr1w8GDBzFo0CDcvn0ba9eureqmdc7c3Bzm5iXnijE1NdXJDtfVdmozttE46LWNXl6qfzXgXnou3thxEX9euQcACPGwx8rhAbj27xFYmJvV/tdRB/uK71fjwDZWflsVUeVwUzTYFGrbti2OHz+u96uliKh+EkLgt6gkvP3rZaTlyGEmk2J2Hz9M6+oDoVTgmqELJKJaQeezgnt7e+PYsWO63qyGzMxMXL9+XX371q1bOH/+PBwdHdGkSRO9PjcRGcaDzDy8ueMS9l5Wja8V2NgOq0e3RgtX1WCicqXCkOURUS1SqXATHx9fofDQoEEDAMCdO3fQuHHjqlVWhn///Rc9e/ZU3y48n2bSpEnYtGmTzp+PiAxr14VkvPXrJTzKyoeJVIKZvfzwUs9mMJVVeaguIjJilfpmaNeuHaZOnYpTp06Vuk5aWhq+/vprBAYGYvv27dUuUJsePXpACFHiH4MNkXFJzcrHjM1n8fLms3iUlY+Wrrb4dUZnzOrtB9PkJODgwcoPgJeYWLXHEVGdUamem6FDh8LW1hb9+/eHqakpwsLC4O7uDgsLC6SmpiI6OhqXL19GWFgYVq1axYH2iKjK9l1OwaIdl/AgMw8yqQQv92iGGb38YGYiVU1ZUDjSr1QKrF8PPPNM+RvV9rgpU/TfGCKqUZUKN5s2bUJCQgKWLVuGRo0awc3NDQ8ePEBOTg6cnZ0xYcIE9OvXD4GBgfqql4iMXFq2HIt/PoWd1x4DAPxcbLB6TAiCPRxUKyQmAlOnAoVDdCmVqsDSu3fZGy5t6oN+/Tg6MJGRqVS4ady4Mc6dO4f+/fsjMzMTK1asgIuLi75qIyJjV2x27L9j7mLh9//gnkIGqVKBF05tx+x2LjBHMwAOqsccP/5fsCmkVAKnTgFmZYxvw6kPiOqNSoWbefPmYciQIQgLC4NEIsGPP/6ILl26IDAwEJaWHA6UiCqhyCGiNEtbLHszHBHpVgBk8HmYgNW7Pkab5GvAYQAfra7+ISQ/P9WhqOJTH/j6VrclRFTLVOqE4pdffhnnzp3DoEGDIITAF198gY4dO8LOzg7+/v4YN24cVq5ciT179uirXiIyBkUOER1u2hb9J3+KiHQrSCAw7Z9t2L1plirYFCo6e3anToBEork9iQR44omyn9PDQxWQZDLVbZkMWLeOvTZERqjS11EGBATgjTfegI+PD06ePImMjAwcPXoUs2fPRoMGDfDrr79izJgx+qiViIxFbCwyTMzxer8ZmDTmHSTbNYT3oyREtMjDG0e+hUVBfsnHFD2E9PXXql4YQPXz668rNo3BlClAXJzqaqm4OJ5MTGSkqjyIX9FB9Nq3b4/27durb1dxLk4iqieOWbjitee+wB171Tl7z/77K147+gMs376m6l0peuJvoaKHkKZMUZ0IfP26apmHR8VnIPfwYG8NkZHT+QjFgGqmbiKi4rLyCvDeniv44WQ8YO8Cz8cpWLX7E3RIuvLfIaLC4LJmDfDxx6oeG22HkBhSiKgUegk3RETFnbz5EPO3RiHhUQ4AYGIHLywMDoT1uGb/9b4U8vAAVq0CZs3S7J0hIqoAhhsi0qucfAXe3xuDTcfjAACNHSzx/shgdPFzVq3gU8bs2OydIaIqYLghIr35N+4R5kVEIe5hNgDg6Sc88cZAf9hamBq4MiIyZgw3RKRzuXIFVu+/ig1Hb0EIwNXOAu+PCkb35g0NXRoR1QMMN0SkU+fiUzEvIgo37mcBAEaFeuCtQa1gb8neGiKqGQw3RKQTeQUKfPJnLNYdvgGlABramuO94UHo3aqRoUsjonqG4YaIqu1iYhrmRpzHtbuZAIBhrd2xZEgAHKzKmOupIorNPUVEVBEMN0RUZfkFSnz+dyy+OHQDCqWAk7UZlg8PQv9A1+pvvMjcU5BKqz+3FBHVGww3RFQll5PSMHdLFGJSMgAATwW74Z0hAXCyMa/+xovMPQXgv7ml+vVjDw4RlYvhhogq5v8PEcl9fPHl9Vx8+lcsCpQCDaxM8e6wQAwKrsDcThUVG1ty+oWic0sREZWB4YaIyvf/h4iuOnpi7lOv4pKrao6nfgGNsGxYEBra6qC3pig/P9WhqKIBp+jcUkREZaj0rOBEVM8kJqLghelY224EBk/6BJdcfWGfk4E1fZrgq/+F6j7YAKremfXrVYEG0D63FBFRKdhzQ0Rlun7uKuaOfx9R7i0AAE9eP4X39n4Gl+HbAX1Okqtt5m8iogpguCEirRRKgW+O3sKqk3nId28B29xMLP5rPUZe+huSmjpExLmliKgKGG6IqIRbD7IwLyIKZ26nAgC6W+Vh5VevwC3tHg8REVGtx3BDRGpKpcCm43H4YF8McuVK2Jib4K1B/hgT5gnJc0/wEBER1QkMN0QEAIh/mI15W6Nw6tYjAEBnXye8PzIYHg2sVCvwEBER1REMN0T1nFIp8OM/t/Henhhk5ytgZSbDGwP9MaF9E0j0ecIwEZGeMNwQ1WOJqdlYsO0Cjl1/CABo39QRq0aFoImTlYErIyKqOoYbonpICIGfTydg2R/RyMpXwMJUioX9W+KZjt6QStlbQ0R1G8MNUT2TnJaDBdsu4si1+wCAMK8G+HB0CLydrQ1cGRGRbjDcENUTQgDbzt7B8j1XkZFbADMTKV7r1wLPdm4KGXtriMiIMNwQ1QN303Px9VUpLp+8DABo7emAD0eHwNfFxsCVERHpHsMNkRETQuDX80lY/NslpOVIYSqTYE6fFpjatSlMZJxajoiME8MNkZG6n5GHRTsuYn/0XQCAp7XAumc7oZVHAwNXRkSkXww3REbojwtJeGvnJaRmy2Eqk+DlHs3QJDMGfo14GIqIjB/DDZEReZiZh7d/vYxdF5MBAP5udlg9OgR+DS2xe3eMgasjIqoZDDdERmLvpWQs2nEJD7PyIZNK8HJPX8zo6QszEynkcrmhyyMiqjEMN0R1VWIiEBuLx55NsfjfVPx6PgkA0KKRLT4cHYIgD3sDF0hEZBgMN0R1UXg4MG0a/mwahtf7z8B9G0dIJcD07s0wq7cfzE1khq6QiMhgGG6I6prERKTNfBXv9H8F24J6AwCaPUzA6um90Dq0uYGLIyIyPA50QVTHHDweg37PfoZtQb0hEUpM+2cbdm18Ba0zkgxdGhFRrcCeG6I6IiNXjmV/XMEvZ/MAW2c0fXQHH+7+GKF3YgCZDPD1NXSJRES1AsMNUR1wNPYBXtsahaS0XEgkwLP2WZj/yWxY5uWogs26dYCHh6HLJCKqFRhuiGqxrLwCvLfnCn44GQ8AaOJohVWjgtHexwn4Xyfg+nVVjw2DDRGRGsMNUS114sZDzN8ahcTUHADAMx29sKB/S1ib///H1sODoYaISAuGG6JaJju/AB/svYpNx+MAAI0dLLFqVDA6+TobtjAiojqC4YaoFjkd9wjzI6IQ9zAbAPD0E03wxsCWsLUwNXBlRER1B8MNUS2QK1fgw31XEX7sFoQA3Owt8P7IYHRr3tDQpRER1TkMN0QGdjY+FfMionDzfhYAYEyYB94c1Ap27K0hIqoShhsiA8mVK/DJn7FYf+QGlAJwsTXHypFB6NWykaFLIyKq0xhuiAzgQuJjzN0Shdh7mQCAEW0aY/HgANhbsbeGiKi6GG6IalB+gRKf/R2LtYduQKEUcLYxw4rhQegb4Gro0oiIjAbDDVENuXQnDfMiohCTkgEAGBzijqVDAuBobWbgyoiIjAvDDZGeyRVKfHHwOj7/+zoKlAKO1mZYNiwQA4PcDF0aEZFRYrghKpSUBNy8Cfj56Wzk35iUdMzdEoXLSekAgAGBrnh3WCCcbcx1sn0iIiqJ4YaoUEAAkJUFSKXA+vXAlClV3lSBQol1R27ikz+vQa4QcLAyxTtDAzE42A0SiUSHRRMRUXEMN0RJSaqfSuV/P194AejXr0o9OLF3MzAvIgpRiWkAgN7+jbBiRCBcbC10VTEREZWB4Yboxo2SyxQK1YzblQg3CqXAhsibWH3gGvILlLCzMMGSIQEY3qYxe2uIiGoQww1Rs2bA+fOay2QywNe3wpu4eT8T8yKicDb+MQCgZ4uGeG9EMFzt2VtDRFTTGG6I3N1V4UYmU92WyYB16yrUa6NUCnxz7BZW7buKvAIlbM1N8NbgVhgd6sHeGiIiA2G4ISp06RJw65aqx6YCwSbuQRZe23oBp+IeAQC6+jlj5chgNHaw1HelRERUBoYbokLu7oCXV7mrKZUC35+8jZV7YpAjV8DaTIZFT7XC0094sreGiKgWYLghqoSER9l4besFnLj5EADQ0ccJH4wKhqejlYErIyKiQgw3RBUghMDmU/FYsesKsvIVsDSVYeGAlpjYwQtSKXtriIhqE4YbonIkPc7Bgm0XEBn7AADQzrsBVo0KgbeztYErIyIibRhuqGL0MDVBbSeEQMS/iXj3j2hk5BXA3ESK1/q3xLOdvNlbQ0RUizHcUMXocGqCuuBuei4WbruAg1fvAwDaNHHAh6ND0KyhjYErIyKi8kgNXUBVrV27Fk2bNoWFhQVCQ0MRGRlp6JKMU2lTEyQmGq4mPRJCYMe5RPT56DAOXr0PMxMpFg5oia3TOzHYEBHVEXUy3Pzyyy+YPXs2Fi1ahHPnzqFr164YMGAA4uPjDV2a8SlragIj8yAzD9O+P4NXf4lCem4BQjzssWuMH6Yr4yFLumPo8oiIqILqZLj56KOPMGXKFDz//PPw9/fHJ598Ak9PT3z55ZeGLs34NGtWclklpyao7YQQOPtAgoGfHceB6LswlUkwv18LbLO4Cr82LYBevVTj34SHG7pUIiKqgDp3zk1+fj7OnDmDhQsXaizv27cvjh8/rvUxeXl5yMvLU99OT08HAMjlcsjl8irXUvjY6myjtpM3bKj6afP/h2RkMmDNGqBRI8AI2v0wKx9v/3oZ+2NlAORo5WaLD0YEooUyA2LwLMjNzf9befZsoHdv1WB/upKUpOoda9ZMt9stpl68V+tBG4H60U620Tjoo40V3ZZECCF09qw1ICkpCY0bN8axY8fQqVMn9fIVK1bg22+/xdWrV0s8ZsmSJVi6dGmJ5Zs3b4aVFQdfq6/OP5Qg4qYUmQUSSCUC/Ror0aexgKxO9mcSERm/7OxsjB8/HmlpabCzsyt1vTrXc1Oo+DD3QohSh75//fXXMWfOHPXt9PR0eHp6om/fvmXunPLI5XIcOHAAffr0gampaZW3U5sZYxtTs/Pxzh8x+ONaCgCguYs1hrqm4dlhRdqYlKS6QqzwRGpA1Wt16VLJHpbvvwdeeUW1rlQKfPopMHFi2UVUZvs6YIyvY3H1oY1A/Wgn22gc9NHGwiMv5alz4cbZ2RkymQwpKSkay+/du4dGjRppfYy5uTnMix5e+H+mpqY62eG62k5tZixtPBB9F69vv4gHmXmQSSV4sXszvNjNG3/u36vZRi8v1eG3F15QnUBdOFN48bmnEhOBqVM1Q8q0aUDfvmWPB3TzpurS+uJu3arQ/FZVZSyvY1nqQxuB+tFOttE46LKNFd1OneuANzMzQ2hoKA4cOKCx/MCBAxqHqYiKSsuWY84v5zH1u3/xIDMPfo7m2P6EGeYFWMPMpJSPwZQpQFwccPCg6qe2sX1iYzWDDVCxq8n8/FS9PEUZ2YnaRESGUud6bgBgzpw5mDhxIsLCwtCxY0esX78e8fHxmD59uqFLo1ro7xhVb83d9DxIJcA0h0zMfnMkLOR5qoDx9deAk5P2B3t4lN0DUxhSih9eKi+keHioBkMs3jNUT0Z/JiLSpzoZbsaOHYuHDx/inXfeQXJyMgIDA7F792546bE7n+qe9Fw5lv0RjS3/qgYc9HG2xqrubgjt0EpzUMJZs4Affqjak1QnpEyZAvTrp+rl8fVlsCEi0pE6GW4A4KWXXsJLL71k6DKoljpy7T4WbLuA5LRcSCTAlM5NMa9fC1gcPaL9MFJ1VCeklNczRERElVZnww2RNpl5BVix+wo2/6MardrLyQqrRoXgiaaOqhVKO4xUXQwpRES1BsMNGY3j1x9g/tYLuPM4BwAwqaMXFgxoCSuzIm9zbYeR1qwxUMVERKQPDDdU52XnF2Dlnhh8d+I2AMCjgSVWjQpBx2alnCRc/DBSo0bA7t01WDEREekTww3VaaduPcK8iCjEP8oGAExo3wSvD/SHjXk5b+2ih5GMePhzIqL6iOGG6qScfAVW7buKjcdvQQjA3d4C748KRle/hoYujYiIDIzhhuqcM7dTMT8iCjcfqEb4HRvmiUWD/GFnYdyjfBIRUcUw3FCdkStX4OMD1/B15E0oBdDIzhwrRwajZwuXim0gMVE1orCfH69sIiIyYgw3VCdEJTzG3IgoXL+XCQAY0bYxFg8KgL1VBXtrwsNVcz4VTm65fr326RSIiKjOY7ihWi2vQIFP/4rFV4dvQqEUaGhrjhXDg9CnlfZJUrVKTPwv2ACqny+8oLpiij04RERGh+GGaq1Ld9IwLyIKMSkZAIChrd2xZHAAGlibVW5DZU1uyXBDRGR0GG6o1skvUOKLg9fxxcHrKFAKOFmbYdmwQAwIcqvYBoqfW1PVyS2JiKhOkhq6AKKiriSnY9gXx7Dmr1gUKAUGBrli/6vdKh5swsMBLy+gVy/Vz/Dw/0YlLpxmgTNwExEZNfbcUK1QoFDiq8M3sOavWMgVAg5Wpnh3aCAGh7hXfCNlnVvDGbiJiOoNhhsyuNi7GZgbEYULiWkAgD6tGmH58EC42FpUckPlnFvDyS2JiOoFhhsyGIVS4OvIm/ho/zXkK5SwszDBO0MDMbS1OyQSSeU3yHNriIgIDDdkIDfuZ2JeRBTOxT8GAPRs0RArRwajkV0le2uK0jbjN8+tISKqdxhuqEYplAIbj93Cqn1XkVeghK25Cd4e3AqjQj2q1ltTHM+tISKq9xhuqMbEPcjC/K1ROB2XCgDo6ueM90cGw93BUrdPxHNriIjqNYYb0julUuC7E3FYuTcGuXIlrM1keHNQK4xr56mb3hoiIqIiGG5IrxIeZWP+1iicvPkIANCpmRM+GBUMjwZWBq6MiIiMFcMN6YUQAj/+E48Vu68gO18BS1MZ3hjYEhPae0EqZW8NERHpD8MN6dydxzlYsPUCjl5/AAB4oqkjVo0KhpeTtYErIyKi+oDhhnRGCIEt/ybg3T+uIDOvABamUrzWryUmd/Jmbw0REdUYhhvSieS0HCzcdhGHr90HAIR6NcCqUcHwaWhj4MqIiKi+YbihahFCYNvZO1j6+2Vk5BbAzESKeX2bY0oXH8jYW0NERAbAcENVdi89F2/suIg/r9wDAIR4OmD16GD4utgauDIiIqrPGG6o0oQQ+C0qCW//ehlpOXKYyaSY3ccP07r6wEQmNXR5RERUzzHcUKU8yMzDmzsuYe/lFABAYGM7fDg6BC1d7QxcGRERkQrDDVXYrgvJeOvXS3iUlQ8TqQQze/nhpZ7NYMreGiIiqkUYbqhcmXJg9i8XsOuSqrempastVo8JQYC7vYErIyIiKonhhsp0IPoe3ouSIVOeAplUgpd7NMOMXn4wM9FTb01iIhAbC/j5cfJLIiKqEoYb0upxdj6W/HYZO88nAZDAt6E1PhrbGsEeDvp70vBwYNo0QKkEpFJg/XpgyhT9PR8RERklhhsq4e+Yu1i47SLuZeRBKgF6uSnxydSOsLE019+TJib+F2wA1c8XXgD69WMPDhERVQrDDaml5cix7I9oRJxJBAD4NLTG+8MDkHTxOMz1dRiqUGzsf8GmkEIBXL/OcENERJXCcEMAgMPX7mPhtgtITsuFRAI836Up5vZtARmUSLpYAwX4+akORRUNODIZ4OtbA09ORETGhOGmnsvMK8DyXdH46VQCAMDbyQofjg5BmLcjAEAuV5b1cN2dAOzhoTrH5oUXVD02Mhmwbh17bYiIqNIYbuqxY9cf4LWtF3DncQ4AYHInbyzo3xKWZrKKbUDXJwBPmaI6x+b6dVWPDYMNERFVAcNNPZSVV4CVe2Lw/cnbAABPR0usGhWCDj5OFd+Ivk4A9vBgqCEiomphuKln/rn5EPO3XkD8o2wAwMQOXlg4oCWszSv5VuAJwEREVEsx3NQmehzALidfgQ/2xWDjsTgAQGMHS7w/Mhhd/JyrtkGeAExERLUUJwWqLcLDAS8voFcv1c/wcJ1t+t+4Rxj4aaQ62Dz9hCf2zu5a9WAD/HcCsOz/z8/hCcBERFRLsOemNtDT+Su5cgVW77+KDUdvQQjA1c4C748KRvfmDXVTN08AJiKiWojhpjbQw/kr5+JTMS8iCjfuZwEARoV64K1BrWBvaVrdajXxBGAiIqplGG5qAx2ev5JXoMAnf8Zi3eEbUAqgoa05Vo4IwpP+jXRYMBERUe3FcFMb6GgAu4uJaZgbcR7X7mYCAIa1dseSIQFwsDLTR9VERES1EsNNbVGN81fyC5T4/O9YfHHoBhRKAWcbMywbFoT+ga56LJiIiKh2YripTapw/kp0UjrmRkThSnI6AOCpYDe8OzQQjtYV7K3R4+XnREREhsBwU0fJFUp8eegGPv0rFgVKgQZWpnh3WCAGBbtXfCO6nj6BiIioFmC4qYOupmRgbsR5XLqj6q3pF9AIy4YFoaGtecU3oq/pE4iIiAyM4UbfdHjYp0ChxLojN7Hmz1jkK5SwtzTFO0MDMCTEHRKJpHIb4/QJRERkpBhu9EmHh32u38vA3IgLiEp4DAB4sqUL3hsRBBc7i6rVVtnLzyMjgebNGXyIiKjW4/QL+lLaYZ/ExEptRqEU+PrITQz89CiiEh7D1sIEH44OwYZJYVUPNkDFp0/4/nvVz0GDdD4tBBERkT4w3OhLWYd9KujWgyyMWXcCy3dfQX6BEt2aN8T+V7thVKhH5Q9DaTNlChAXBxw8qPpZvFcpMRF45ZX/blcxoBEREdUkHpbSl2qMOqxUCmw6HocP9sUgV66EjbkJ3nzKH2Pbeeom1BRV1uXnPC+HiIjqIIYbfaniqMPxD7Mxb2sUTt16BADo7OuE90cGw6OBVU1UrakwoBVVxWkhiIiIagrDjT5VYtRhpVLgx1PxeG/3FWTnK2BlJsMbA/0xoX0T3ffWVJSHB/Dpp//druK0EERERDWJ4UbfKjDqcGJqNhZsu4Bj1x8CANo3dcSqUSFo4mSA3priJk4Edu8Gdu3iKMZERFQnMNwYkBACP59OwPJdV5CZVwALUykW9G+JSR29IZWW01tT09MmdOkCmJrq/3mIiIiqieHGQJLTcrBg20UcuXYfABDm1QAfjg6Bt7N1+Q/mtAlERESlYripYUIIbD2TiHf+iEZGbgHMTaSY368Fnu3cFLLyemsATptARERUDoabGnQ3PRdvbL+Iv2LuAQBaezrgw9Eh8HWxqfhGeHk2ERFRmRhuaoAQAr+eT8Li3y4jLUcOM5kUs/v4YVpXH5jIKjmOYjXGzyEiIqoPOEKxnt3PyMML35/B7F/OIy1HjqDG9vh9jC9eEgkwSU6q/AYrOm0CERFRPcWeGz3640IS3tp5CanZcpjKJHillx+m3zoC07bdq3cycCXGzyEiIqpvGG704FFWPt7aeQm7LiYDAPzd7LB6dAhaKdOBvjo6GbgC4+cQERHVRww3Orb3Ugre3HkRDzLzYSKV4OWevni5py/MTKTAwTM8GZiIiEjP6ly4Wb58OXbt2oXz58/DzMwMjx8/NnRJAAC5Qol5EVH49bzqPJoWjWyxekwIAhvb/7cSTwYmIiLSuzp3QnF+fj5Gjx6NF1980dClaDCVSSEBIJUAL/Voht9mdtYMNgBPBiYiIqoBda7nZunSpQCATZs2GbYQLZYMCcDkzk3R2tOh9JV4MjAREZFe1blwUxV5eXnIy8tT305PTwcAyOVyyOXyKm+38LGFP61NJQhwtS5/m40aqf6pHlzl568JxdtojNhG41Af2gjUj3ayjcZBH22s6LYkQgihs2etQZs2bcLs2bMrdM7NkiVL1D0+RW3evBlWVrVg5m0iIiIqV3Z2NsaPH4+0tDTY2dmVul6t6LkpLXwUdfr0aYSFhVVp+6+//jrmzJmjvp2eng5PT0/07du3zJ1THrlcjgMHDqBPnz4w/fln4JVX/hu/5tNPgYkTq7zt2kKjjUY6KzjbaBzqQxuB+tFOttE46KONhUdeylMrws2MGTMwbty4Mtfx9vau8vbNzc1hbm5eYrmpqalOdrjp/fswnTpV8yqoadOAvn2N5pwaXe2r2oxtNA71oY1A/Wgn22gcdNnGim6nVoQbZ2dnODs7G7qMqrtxg+PXEBER1RK1ItxURnx8PB49eoT4+HgoFAqcP38eAODr6wsbm0rMrq1LzZpx/BoiIqJaos6Nc/P222+jTZs2WLx4MTIzM9GmTRu0adMG//77r+GKcnfn+DVERES1RJ3rudm0aVOtHOOG49cQERHVDnUu3NRqnMySiIjI4OrcYSkiIiKisjDcEBERkVFhuCEiIiKjwnBDRERERoXhhoiIiIwKw01NSUwEDh5U/SQiIiK9YbipCeHhgJcX0KuX6md4uKErIiIiMloMN/qWmKiaRLNwagalEnjhBfbgEBER6QnDjb7FxpY+qSYRERHpHMONvvn5qSbVLIqTahIREekNw42+eXhwUk0iIqIaxLmlagIn1SQiIqoxDDc1hZNqEhER1QgeliIiIiKjwnBDRERERoXhhoiIiIwKww0REREZFYYbIiIiMioMN0RERGRUGG6IiIjIqDDcEBERkVFhuCEiIiKjwnBDRERERoXhhoiIiIxKvZxbSggBAEhPT6/WduRyObKzs5Geng5TU1NdlFbrsI3GgW00HvWhnWyjcdBHGwt/bxf+Hi9NvQw3GRkZAABPT08DV0JERESVlZGRAXt7+1Lvl4jy4o8RUiqVSEpKgq2tLSQSSZW3k56eDk9PTyQkJMDOzk6HFdYebKNxYBuNR31oJ9toHPTRRiEEMjIy4O7uDqm09DNr6mXPjVQqhYeHh862Z2dnZ7RvzkJso3FgG41HfWgn22gcdN3GsnpsCvGEYiIiIjIqDDdERERkVBhuqsHc3ByLFy+Gubm5oUvRG7bROLCNxqM+tJNtNA6GbGO9PKGYiIiIjBd7boiIiMioMNwQERGRUWG4ISIiIqPCcENERERGheGmDMuXL0enTp1gZWUFBweHCj1GCIElS5bA3d0dlpaW6NGjBy5fvqyxTl5eHmbOnAlnZ2dYW1tjyJAhSExM1EMLypeamoqJEyfC3t4e9vb2mDhxIh4/flzmYyQSidZ/q1atUq/To0ePEvePGzdOz63RriptnDx5con6O3TooLFOXX4d5XI5FixYgKCgIFhbW8Pd3R3PPPMMkpKSNNYz9Ou4du1aNG3aFBYWFggNDUVkZGSZ6x8+fBihoaGwsLCAj48PvvrqqxLrbNu2Da1atYK5uTlatWqFHTt26Kv8CqlMG7dv344+ffqgYcOGsLOzQ8eOHbFv3z6NdTZt2qT185mbm6vvppSqMm08dOiQ1vpjYmI01qvLr6O27xeJRIKAgAD1OrXtdTxy5AgGDx4Md3d3SCQS7Ny5s9zHGPTzKKhUb7/9tvjoo4/EnDlzhL29fYUes3LlSmFrayu2bdsmLl68KMaOHSvc3NxEenq6ep3p06eLxo0biwMHDoizZ8+Knj17ipCQEFFQUKCnlpSuf//+IjAwUBw/flwcP35cBAYGikGDBpX5mOTkZI1/33zzjZBIJOLGjRvqdbp37y6mTp2qsd7jx4/13RytqtLGSZMmif79+2vU//DhQ4116vLr+PjxY9G7d2/xyy+/iJiYGHHixAnRvn17ERoaqrGeIV/Hn3/+WZiamoqvv/5aREdHi1mzZglra2tx+/ZtrevfvHlTWFlZiVmzZono6Gjx9ddfC1NTU7F161b1OsePHxcymUysWLFCXLlyRaxYsUKYmJiIkydP1kibiqtsG2fNmiXef/99cerUKXHt2jXx+uuvC1NTU3H27Fn1Ohs3bhR2dnYlPqeGUtk2Hjx4UAAQV69e1ai/6Oeqrr+Ojx8/1mhbQkKCcHR0FIsXL1avU9tex927d4tFixaJbdu2CQBix44dZa5v6M8jw00FbNy4sULhRqlUCldXV7Fy5Ur1stzcXGFvby+++uorIYTqTW1qaip+/vln9Tp37twRUqlU7N27V+e1lyU6OloA0HgjnThxQgAQMTExFd7O0KFDRa9evTSWde/eXcyaNUtXpVZZVds4adIkMXTo0FLvN8bX8dSpUwKAxheyIV/HJ554QkyfPl1jWcuWLcXChQu1rv/aa6+Jli1baix74YUXRIcOHdS3x4wZI/r376+xTr9+/cS4ceN0VHXlVLaN2rRq1UosXbpUfbui31c1pbJtLAw3qamppW7T2F7HHTt2CIlEIuLi4tTLatvrWFRFwo2hP488LKVDt27dQkpKCvr27ateZm5uju7du+P48eMAgDNnzkAul2us4+7ujsDAQPU6NeXEiROwt7dH+/bt1cs6dOgAe3v7Ctdy9+5d7Nq1C1OmTClx348//ghnZ2cEBARg3rx56tnYa1J12njo0CG4uLigefPmmDp1Ku7du6e+z9heRwBIS0uDRCIpcQjWEK9jfn4+zpw5o7F/AaBv376ltunEiRMl1u/Xrx/+/fdfyOXyMtep6dcMqFobi1MqlcjIyICjo6PG8szMTHh5ecHDwwODBg3CuXPndFZ3ZVSnjW3atIGbmxuefPJJHDx4UOM+Y3sdw8PD0bt3b3h5eWksry2vY1UY+vNYLyfO1JeUlBQAQKNGjTSWN2rUCLdv31avY2ZmhgYNGpRYp/DxNSUlJQUuLi4llru4uFS4lm+//Ra2trYYMWKExvIJEyagadOmcHV1xaVLl/D6668jKioKBw4c0EntFVXVNg4YMACjR4+Gl5cXbt26hbfeegu9evXCmTNnYG5ubnSvY25uLhYuXIjx48drTHBnqNfxwYMHUCgUWj9LpbUpJSVF6/oFBQV48OAB3NzcSl2npl8zoGptLG716tXIysrCmDFj1MtatmyJTZs2ISgoCOnp6VizZg06d+6MqKgo+Pn56bQN5alKG93c3LB+/XqEhoYiLy8P33//PZ588kkcOnQI3bp1A1D6a10XX8fk5GTs2bMHmzdv1lhem17HqjD057HehZslS5Zg6dKlZa5z+vRphIWFVfk5JBKJxm0hRIllxVVknYqqaBuBkrVWtpZvvvkGEyZMgIWFhcbyqVOnqv8fGBgIPz8/hIWF4ezZs2jbtm2Ftl0Wfbdx7Nix6v8HBgYiLCwMXl5e2LVrV4kgV5ntVkZNvY5yuRzjxo2DUqnE2rVrNe7T9+tYnsp+lrStX3x5VT6f+lTVen766ScsWbIEv/76q0a47dChg8bJ7507d0bbtm3x2Wef4dNPP9Vd4ZVQmTa2aNECLVq0UN/u2LEjEhIS8OGHH6rDTWW3WROqWs+mTZvg4OCAYcOGaSyvja9jZRny81jvws2MGTPKvdrD29u7Stt2dXUFoEqsbm5u6uX37t1Tp1NXV1fk5+cjNTVV46/+e/fuoVOnTlV63uIq2sYLFy7g7t27Je67f/9+iTStTWRkJK5evYpffvml3HXbtm0LU1NTxMbG6uSXYk21sZCbmxu8vLwQGxsLwHheR7lcjjFjxuDWrVv4+++/NXpttNH161gaZ2dnyGSyEn/BFf0sFefq6qp1fRMTEzg5OZW5TmXeC7pSlTYW+uWXXzBlyhRERESgd+/eZa4rlUrRrl079Xu3JlWnjUV16NABP/zwg/q2sbyOQgh88803mDhxIszMzMpc15CvY1UY/PNY7bN26oHKnlD8/vvvq5fl5eVpPaH4l19+Ua+TlJRk0BNR//nnH/WykydPVvhE1EmTJpW4uqY0Fy9eFADE4cOHq1xvVVS3jYUePHggzM3NxbfffiuEMI7XMT8/XwwbNkwEBASIe/fuVei5avJ1fOKJJ8SLL76osczf37/ME4r9/f01lk2fPr3ECYwDBgzQWKd///4GPRG1Mm0UQojNmzcLCwuLck/oLKRUKkVYWJh49tlnq1NqlVWljcWNHDlS9OzZU33bGF5HIf47efrixYvlPoehX8eiUMETig35eWS4KcPt27fFuXPnxNKlS4WNjY04d+6cOHfunMjIyFCv06JFC7F9+3b17ZUrVwp7e3uxfft2cfHiRfH0009rvRTcw8ND/Pnnn+Ls2bOiV69eBr2EODg4WJw4cUKcOHFCBAUFlbiEuHgbhRAiLS1NWFlZiS+//LLENq9fvy6WLl0qTp8+LW7duiV27dolWrZsKdq0aVMn2piRkSHmzp0rjh8/Lm7duiUOHjwoOnbsKBo3bmw0r6NcLhdDhgwRHh4e4vz58xqXmubl5QkhDP86Fl5eGx4eLqKjo8Xs2bOFtbW1+oqShQsXiokTJ6rXL7z09NVXXxXR0dEiPDy8xKWnx44dEzKZTKxcuVJcuXJFrFy5slZcQlzRNm7evFmYmJiIL774otTL85csWSL27t0rbty4Ic6dOyeeffZZYWJiohF+a1Jl2/jxxx+LHTt2iGvXrolLly6JhQsXCgBi27Zt6nXq+utY6H//+59o37691m3WttcxIyND/TsQgPjoo4/EuXPn1FdX1rbPI8NNGSZNmiQAlPh38OBB9ToAxMaNG9W3lUqlWLx4sXB1dRXm5uaiW7duJVJ5Tk6OmDFjhnB0dBSWlpZi0KBBIj4+voZapenhw4diwoQJwtbWVtja2ooJEyaUuASzeBuFEGLdunXC0tJS65gn8fHxolu3bsLR0VGYmZmJZs2aiVdeeaXEODE1pbJtzM7OFn379hUNGzYUpqamokmTJmLSpEklXqO6/DreunVL63u76Pu7NryOX3zxhfDy8hJmZmaibdu2Gj1GkyZNEt27d9dY/9ChQ6JNmzbCzMxMeHt7aw3fERERokWLFsLU1FS0bNlS45emIVSmjd27d9f6mk2aNEm9zuzZs0WTJk2EmZmZaNiwoejbt684fvx4DbaopMq08f333xfNmjUTFhYWokGDBqJLly5i165dJbZZl19HIVS9v5aWlmL9+vVat1fbXsfCXqbS3nu17fMoEeL/z/AhIiIiMgIc54aIiIiMCsMNERERGRWGGyIiIjIqDDdERERkVBhuiIiIyKgw3BAREZFRYbghIiIio8JwQ0REREaF4YaIiIiMCsMNERERGRWGGyKq83766SdYWFjgzp076mXPP/88goODkZaWZsDKiMgQOLcUEdV5Qgi0bt0aXbt2xeeff46lS5diw4YNOHnyJBo3bmzo8oiohpkYugAiouqSSCRYvnw5Ro0aBXd3d6xZswaRkZEMNkT1FHtuiMhotG3bFpcvX8b+/fvRvXt3Q5dDRAbCc26IyCjs27cPMTExUCgUaNSokaHLISIDYs8NEdV5Z8+eRY8ePfDFF1/g559/hpWVFSIiIgxdFhEZCM+5IaI6LS4uDk899RQWLlyIiRMnolWrVmjXrh3OnDmD0NBQQ5dHRAbAnhsiqrMePXqEzp07o1u3bli3bp16+dChQ5GXl4e9e/casDoiMhSGGyIiIjIqPKGYiIiIjArDDRERERkVhhsiIiIyKgw3REREZFQYboiIiMioMNwQERGRUWG4ISIiIqPCcENERERGheGGiIiIjArDDRERERkVhhsiIiIyKgw3REREZFT+D5JkX0fIEvFTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate training parameters\n",
    "N_epochs = 30\n",
    "N_train = 1000 # <<< train\n",
    "N_valid = 50 # <<< test\n",
    "sigma = 0.2\n",
    "bach_size = 32\n",
    "\n",
    "# generate training inputs\n",
    "np.random.seed(0)\n",
    "x_train = np.random.uniform(-1, 1, N_train)\n",
    "x_valid = np.random.uniform(-1, 1, N_valid)\n",
    "x_valid.sort()\n",
    "y_target = m * x_valid + q # ideal (target) linear function\n",
    "\n",
    "# actual measures from which we want to guess regression parameters\n",
    "y_train = np.random.normal(m * x_train + q, sigma) \n",
    "y_valid = np.random.normal(m * x_valid + q, sigma)\n",
    "\n",
    "# plot validation and target dataset\n",
    "plt.plot(x_valid, y_target, label = 'Target: $f(x)= 2x +1$')\n",
    "plt.scatter(x_valid, y_valid, color = 'r', marker = '.', label = 'Validation data')\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$f(x)$\")\n",
    "plt.title(\"Validation data and target function\", fontsize = 16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.9973 - mse: 3.9973 - val_loss: 3.1475 - val_mse: 3.1475\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 783us/step - loss: 2.3927 - mse: 2.3927 - val_loss: 2.0029 - val_mse: 2.0029\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 744us/step - loss: 1.5125 - mse: 1.5125 - val_loss: 1.3213 - val_mse: 1.3213\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.9876 - mse: 0.9876 - val_loss: 0.8745 - val_mse: 0.8745\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.6460 - mse: 0.6460 - val_loss: 0.5932 - val_mse: 0.5932\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 699us/step - loss: 0.4337 - mse: 0.4337 - val_loss: 0.4062 - val_mse: 0.4062\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2951 - mse: 0.2951 - val_loss: 0.2832 - val_mse: 0.2832\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.2052 - mse: 0.2052 - val_loss: 0.2006 - val_mse: 0.2006\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.1462 - mse: 0.1462 - val_loss: 0.1467 - val_mse: 0.1467\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.1082 - mse: 0.1082 - val_loss: 0.1106 - val_mse: 0.1106\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0869 - val_mse: 0.0869\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 705us/step - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0595 - val_mse: 0.0595\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0518 - val_mse: 0.0518\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 706us/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 704us/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 691us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 694us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0339 - val_mse: 0.0339\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# INITIALIZE Neural Network (Sequential) model:\n",
    "# a single neuron can make the fitting job, so\n",
    "# i use only one layer on one neuron.\n",
    "# ==============================================\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(1, input_shape = (1,)))\n",
    "\n",
    "# compile the model choosing optimizer, loss and metrics objects\n",
    "model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['mse'])\n",
    "\n",
    "# ==============================================\n",
    "# TRAIN THE MODEL \n",
    "# I feed the neuron with the set of (x,y) training \n",
    "# pairs. The optimizer finds the best weights \n",
    "# minimizing the Mean Square Error loss function \n",
    "# ==============================================\n",
    "\n",
    "history = model.fit(x = x_train, y = y_train, batch_size = 32, epochs = N_epochs,\n",
    "                    shuffle = True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Slope   m = 1.9882325\n",
      "Interc. q = 1.0062877\n",
      "\n",
      "\n",
      "TEST DATA evaluation\n",
      "Test loss:  0.03386206179857254\n",
      "\n",
      "EXACT CURVE evaluation\n",
      "Test loss:  9.404189768247306e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Results\")\n",
    "w,b = model.get_weights()\n",
    "print(\"Slope   m = \" + str(w[0][0]))\n",
    "print(\"Interc. q = \" + str(b[0]))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# evaluate with TEST data\n",
    "print(\"TEST DATA evaluation\")\n",
    "score = model.evaluate(x_valid, y_valid, batch_size = 32, verbose = 0)\n",
    "print('Test loss: ', score[0])\n",
    "print()\n",
    "\n",
    "#evaluate with the EXACT CURVE with m = 2 and q = 1\n",
    "print(\"EXACT CURVE evaluation\")\n",
    "score = model.evaluate(x_valid, y_target, batch_size = 32, verbose = 0)\n",
    "print('Test loss: ', score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 577us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 5))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss', fontsize = '16')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('N_epochs')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.grid()\n",
    "\n",
    "# ==============================================\n",
    "# COMPARE MODEL predictions with TARGET FUNCTION\n",
    "# ==============================================\n",
    "\n",
    "# generate predictions\n",
    "x_predicted = np.random.uniform(-1, 1, 100) \n",
    "y_predicted = model.predict(x_predicted)\n",
    "\n",
    "# plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_predicted, y_predicted, color='r', label = \"Model prediction\")\n",
    "plt.plot(x_valid, y_target, label = \"Target function\\n $f(x) = 2x+1$\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.title(\"Model predictions and Target function\", fontsize = 16)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           0.03945993259549141,
           0.014337940141558647,
           0.010259142145514488,
           0.009620142169296741,
           0.1402379274368286,
           0.009365476667881012,
           0.00985492579638958,
           0.009536894969642162,
           0.015350277535617352,
           0.008510014042258263,
           0.009658165276050568,
           0.009501088410615921,
           0.011162311770021915,
           0.008425332605838776,
           0.009675457142293453,
           0.009502509608864784,
           0.465322345495224,
           0.05151011794805527,
           0.04193757846951485,
           0.03869154304265976,
           0.048626627773046494,
           0.046511925756931305,
           0.03909594565629959,
           0.038045283406972885,
           0.0478634275496006,
           0.033691879361867905,
           0.0386146679520607,
           0.038037560880184174,
           0.044568996876478195,
           0.033557791262865067,
           0.03859744220972061,
           0.03802476078271866,
           0.3022347688674927,
           0.22134512662887573,
           0.2495303899049759,
           0.2381657212972641,
           0.3057687282562256,
           0.22674746811389923,
           0.24283134937286377,
           0.2378118336200714,
           0.27843227982521057,
           0.21150082349777222,
           0.24194152653217316,
           0.23765462636947632,
           0.27836811542510986,
           0.2097042202949524,
           0.24095802009105682,
           0.23765282332897186,
           1.1782411336898804,
           0.9821128845214844,
           0.9684074521064758,
           0.9532440304756165,
           1.1247440576553345,
           0.8788458108901978,
           0.9661140441894531,
           0.9505408406257629,
           1.1140152215957642,
           0.845366358757019,
           0.9665963649749756,
           0.9500280618667603,
           1.1162984371185303,
           0.840889573097229,
           0.9657875299453735,
           0.950888991355896
          ],
          "colorbar": {
           "title": {
            "text": "Log(Loss)"
           }
          },
          "colorscale": [
           [
            0,
            "#440154"
           ],
           [
            0.1111111111111111,
            "#482878"
           ],
           [
            0.2222222222222222,
            "#3e4989"
           ],
           [
            0.3333333333333333,
            "#31688e"
           ],
           [
            0.4444444444444444,
            "#26828e"
           ],
           [
            0.5555555555555556,
            "#1f9e89"
           ],
           [
            0.6666666666666666,
            "#35b779"
           ],
           [
            0.7777777777777778,
            "#6ece58"
           ],
           [
            0.8888888888888888,
            "#b5de2b"
           ],
           [
            1,
            "#fde725"
           ]
          ],
          "opacity": 0.9,
          "size": 4
         },
         "mode": "markers",
         "text": [
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 500<br>Loss: 0.0395",
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.0143",
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.0103",
          "Sigma: 0.1<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.0096",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 500<br>Loss: 0.1402",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.0094",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.0099",
          "Sigma: 0.1<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.0095",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 500<br>Loss: 0.0154",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.0085",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.0097",
          "Sigma: 0.1<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.0095",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 500<br>Loss: 0.0112",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.0084",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.0097",
          "Sigma: 0.1<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.0095",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 500<br>Loss: 0.4653",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.0515",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.0419",
          "Sigma: 0.2<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.0387",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 500<br>Loss: 0.0486",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.0465",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.0391",
          "Sigma: 0.2<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.0380",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 500<br>Loss: 0.0479",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.0337",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.0386",
          "Sigma: 0.2<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.0380",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 500<br>Loss: 0.0446",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.0336",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.0386",
          "Sigma: 0.2<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.0380",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 500<br>Loss: 0.3022",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.2213",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.2495",
          "Sigma: 0.5<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.2382",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 500<br>Loss: 0.3058",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.2267",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.2428",
          "Sigma: 0.5<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.2378",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 500<br>Loss: 0.2784",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.2115",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.2419",
          "Sigma: 0.5<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.2377",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 500<br>Loss: 0.2784",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.2097",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.2410",
          "Sigma: 0.5<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.2377",
          "Sigma: 1<br>Train data: 10<br>Epochs: 500<br>Loss: 1.1782",
          "Sigma: 1<br>Train data: 10<br>Epochs: 1000<br>Loss: 0.9821",
          "Sigma: 1<br>Train data: 10<br>Epochs: 1500<br>Loss: 0.9684",
          "Sigma: 1<br>Train data: 10<br>Epochs: 2000<br>Loss: 0.9532",
          "Sigma: 1<br>Train data: 15<br>Epochs: 500<br>Loss: 1.1247",
          "Sigma: 1<br>Train data: 15<br>Epochs: 1000<br>Loss: 0.8788",
          "Sigma: 1<br>Train data: 15<br>Epochs: 1500<br>Loss: 0.9661",
          "Sigma: 1<br>Train data: 15<br>Epochs: 2000<br>Loss: 0.9505",
          "Sigma: 1<br>Train data: 30<br>Epochs: 500<br>Loss: 1.1140",
          "Sigma: 1<br>Train data: 30<br>Epochs: 1000<br>Loss: 0.8454",
          "Sigma: 1<br>Train data: 30<br>Epochs: 1500<br>Loss: 0.9666",
          "Sigma: 1<br>Train data: 30<br>Epochs: 2000<br>Loss: 0.9500",
          "Sigma: 1<br>Train data: 50<br>Epochs: 500<br>Loss: 1.1163",
          "Sigma: 1<br>Train data: 50<br>Epochs: 1000<br>Loss: 0.8409",
          "Sigma: 1<br>Train data: 50<br>Epochs: 1500<br>Loss: 0.9658",
          "Sigma: 1<br>Train data: 50<br>Epochs: 2000<br>Loss: 0.9509"
         ],
         "type": "scatter3d",
         "x": [
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          0.5,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50,
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50,
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50,
          10,
          10,
          10,
          10,
          15,
          15,
          15,
          15,
          30,
          30,
          30,
          30,
          50,
          50,
          50,
          50
         ],
         "z": [
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000,
          500,
          1000,
          1500,
          2000
         ]
        }
       ],
       "layout": {
        "height": 700,
        "scene": {
         "xaxis": {
          "title": {
           "font": {
            "size": 12
           },
           "text": "sigma"
          }
         },
         "yaxis": {
          "title": {
           "font": {
            "size": 12
           },
           "text": "train data"
          }
         },
         "zaxis": {
          "title": {
           "font": {
            "size": 12
           },
           "text": "epochs"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Scatter Plot of Loss with Different Parameters"
        },
        "width": 900
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate the parameters and losses into individual arrays\n",
    "sigma, n_train, n_epochs = zip(*param_combinations)\n",
    "loss = np.array(loss)\n",
    "\n",
    "# Create a trace for the 3D plot\n",
    "trace = go.Scatter3d(\n",
    "    x=sigma,\n",
    "    y=n_train,\n",
    "    z=n_epochs,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=loss,  # Use the log-transformed loss for coloring\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Log(Loss)'),\n",
    "        opacity=0.9\n",
    "    ),\n",
    "    text=[f'Sigma: {s}<br>Train data: {t}<br>Epochs: {e}<br>Loss: {l:.4f}'\n",
    "          for s, t, e, l in zip(sigma, n_train, n_epochs, loss)],\n",
    "    hoverinfo='text'\n",
    ")\n",
    "\n",
    "# Create the layout\n",
    "layout = go.Layout(\n",
    "    title='3D Scatter Plot of Loss with Different Parameters',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=f'sigma', titlefont=dict(size=12)),\n",
    "        yaxis=dict(title='train data', titlefont=dict(size=12)),\n",
    "        zaxis=dict(title='epochs', titlefont=dict(size=12))\n",
    "    ),\n",
    "    width=900,  # Increase the width of the plot\n",
    "    height=700,  # Increase the height of the plot\n",
    ")\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
